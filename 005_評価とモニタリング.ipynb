{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a7a4cc62-9984-4971-b023-4305924545e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# アプリケーションの評価と改善\n",
    "\n",
    "https://docs.databricks.com/aws/ja/mlflow3/genai/eval-monitor/evaluate-app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e0673f8-ea86-4339-b170-dac739ee7fe0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install \"mlflow[databricks]>=3.1.1\" openai\n",
    "\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bb0fd8a8-30e5-4add-af20-206bedeedd1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ステップ 1: アプリケーションを作成する\n",
    "\n",
    "このガイドでは、次のような Eメール 生成アプリを評価します。\n",
    "\n",
    "- CRMデータベースから顧客情報を取得します\n",
    "- 取得した情報に基づいてパーソナライズされたフォローアップEメール\n",
    "\n",
    "Eメール生成アプリを作りましょう。 取得コンポーネントは、MLflow の取得固有のスコアラーを有効にするために ```span_type=\"RETRIEVER\"``` でマークされています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33b357b8-ddf1-48ac-a53e-6a31bb847eb1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from openai import OpenAI\n",
    "from mlflow.entities import Document\n",
    "from typing import List, Dict\n",
    "\n",
    "# OpenAI呼び出しの自動トレースを有効にする\n",
    "mlflow.openai.autolog()\n",
    "\n",
    "# 同じ資格情報を使用してOpenAI経由でDatabricks LLMに接続する\n",
    "# あるいは、ここで独自のOpenAI資格情報を使用することもできます\n",
    "mlflow_creds = mlflow.utils.databricks_utils.get_databricks_host_creds()\n",
    "client = OpenAI(\n",
    "    api_key=mlflow_creds.token, base_url=f\"{mlflow_creds.host}/serving-endpoints\"\n",
    ")\n",
    "\n",
    "# シミュレートされたCRMデータベース\n",
    "CRM_DATA = {\n",
    "    \"Acme Corp\": {\n",
    "        \"contact_name\": \"アリス・チェン\",\n",
    "        \"recent_meeting\": \"月曜日に製品デモを行い、エンタープライズ機能に非常に興味を持っていました。彼らは次のことについて質問しました：高度な分析、リアルタイムダッシュボード、API統合、カスタムレポート、マルチユーザーサポート、SSO認証、データエクスポート機能、および500人以上のユーザー向けの価格設定\",\n",
    "        \"support_tickets\": [\n",
    "            \"Ticket #123: APIの遅延問題（先週解決済み）\",\n",
    "            \"Ticket #124: 一括インポートの機能リクエスト\",\n",
    "            \"Ticket #125: GDPRコンプライアンスに関する質問\",\n",
    "        ],\n",
    "        \"account_manager\": \"サラ・ジョンソン\",\n",
    "    },\n",
    "    \"TechStart\": {\n",
    "        \"contact_name\": \"ボブ・マルティネス\",\n",
    "        \"recent_meeting\": \"先週の木曜日に初回の営業電話を行い、価格をリクエストしました\",\n",
    "        \"support_tickets\": [\n",
    "            \"Ticket #456: ログイン問題（オープン - クリティカル）\",\n",
    "            \"Ticket #457: パフォーマンスの低下が報告されました\",\n",
    "            \"Ticket #458: 彼らのCRMとの統合が失敗しています\",\n",
    "        ],\n",
    "        \"account_manager\": \"マイク・トンプソン\",\n",
    "    },\n",
    "    \"Global Retail\": {\n",
    "        \"contact_name\": \"キャロル・ワン\",\n",
    "        \"recent_meeting\": \"昨日の四半期レビューで、プラットフォームのパフォーマンスに満足しています\",\n",
    "        \"support_tickets\": [],\n",
    "        \"account_manager\": \"サラ・ジョンソン\",\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "# MLflowの事前定義されたRetrievalGroundednessスコアラーが機能するようにリトリーバースパンを使用する\n",
    "@mlflow.trace(span_type=\"RETRIEVER\")\n",
    "def retrieve_customer_info(customer_name: str) -> List[Document]:\n",
    "    \"\"\"CRMデータベースから顧客情報を取得する\"\"\"\n",
    "    if customer_name in CRM_DATA:\n",
    "        data = CRM_DATA[customer_name]\n",
    "        return [\n",
    "            Document(\n",
    "                id=f\"{customer_name}_meeting\",\n",
    "                page_content=f\"Recent meeting: {data['recent_meeting']}\",\n",
    "                metadata={\"type\": \"meeting_notes\"},\n",
    "            ),\n",
    "            Document(\n",
    "                id=f\"{customer_name}_tickets\",\n",
    "                page_content=f\"Support tickets: {', '.join(data['support_tickets']) if data['support_tickets'] else 'No open tickets'}\",\n",
    "                metadata={\"type\": \"support_status\"},\n",
    "            ),\n",
    "            Document(\n",
    "                id=f\"{customer_name}_contact\",\n",
    "                page_content=f\"Contact: {data['contact_name']}, Account Manager: {data['account_manager']}\",\n",
    "                metadata={\"type\": \"contact_info\"},\n",
    "            ),\n",
    "        ]\n",
    "    return []\n",
    "\n",
    "\n",
    "@mlflow.trace\n",
    "def generate_sales_email(customer_name: str, user_instructions: str) -> Dict[str, str]:\n",
    "    \"\"\"顧客データと営業担当者の指示に基づいてパーソナライズされた営業メールを生成する\"\"\"\n",
    "    # 顧客情報を取得する\n",
    "    customer_docs = retrieve_customer_info(customer_name)\n",
    "\n",
    "    # 取得したコンテキストを結合する\n",
    "    context = \"\\n\".join([doc.page_content for doc in customer_docs])\n",
    "\n",
    "    # 取得したコンテキストを使用してメールを生成する\n",
    "    prompt = f\"\"\"あなたは営業担当者です。以下の顧客情報に基づき、\n",
    "    顧客からのリクエストに対応した簡潔なフォローアップメールを作成してください。\n",
    "\n",
    "    顧客情報:\n",
    "    {context}\n",
    "\n",
    "    ユーザー指示: {user_instructions}\n",
    "\n",
    "    メールは簡潔かつパーソナライズされた内容にしてください。\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"databricks-meta-llama-3-3-70b-instruct\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"あなたは役に立つ営業アシスタントです。\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        max_tokens=2000,\n",
    "    )\n",
    "\n",
    "    return {\"email\": response.choices[0].message.content}\n",
    "\n",
    "\n",
    "# アプリケーションをテストする\n",
    "result = generate_sales_email(\"Acme Corp\", \"商品デモの後にフォローアップして\")\n",
    "print(result[\"email\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b6b9fd89-51e5-4b67-81a1-d556be944c73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## ステップ 2: 本番運用のトラフィックをシミュレートする\n",
    "\n",
    "この手順では、デモンストレーションの目的でトラフィックをシミュレートします。\n",
    "\n",
    "実際には、実際の使用状況のトレース トレース を使用して評価データセットを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "324ecf57-8425-4f7e-b7cd-b477b634d80e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# トレース管理をするLoggedModelを設定\n",
    "active_model_info = mlflow.set_active_model(name=\"sales_email_v1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6208e300-5a01-4e4d-b442-95eaceac1936",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ガイドライン違反を意図したシナリオでベータテストのトラフィックをシミュレート\n",
    "test_requests = [\n",
    "    {\"customer_name\": \"Acme Corp\", \"user_instructions\": \"製品デモの後にフォローアップ\"},\n",
    "    {\"customer_name\": \"TechStart\", \"user_instructions\": \"サポートチケットの状況を確認\"},\n",
    "    {\"customer_name\": \"Global Retail\", \"user_instructions\": \"四半期レビューの要約を送信\"},\n",
    "    {\"customer_name\": \"Acme Corp\", \"user_instructions\": \"すべての製品機能、価格帯、実装スケジュール、およびサポートオプションを詳しく説明する非常に詳細なメールを書く\"},\n",
    "    {\"customer_name\": \"TechStart\", \"user_instructions\": \"彼らのビジネスに感謝する熱意のあるメールを送信\"},\n",
    "    {\"customer_name\": \"Global Retail\", \"user_instructions\": \"フォローアップメールを送信\"},\n",
    "    {\"customer_name\": \"Acme Corp\", \"user_instructions\": \"物事がどうなっているかを確認するために連絡\"},\n",
    "]\n",
    "\n",
    "# リクエストを実行してトレースを記録する\n",
    "print(\"プロダクション トラフィックをシミュレートしています...\")\n",
    "for req in test_requests:\n",
    "    try:\n",
    "        result = generate_sales_email(**req)\n",
    "        print(f\"✓ {req['customer_name']} のメールを生成しました\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ {req['customer_name']} のエラー: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88ef42f7-29f3-4300-836c-d0a0d232a21d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ステップ 3: 評価データセットを作成する\n",
    "\n",
    "次に、トレースを評価データセットに変換しましょう。評価データセットにトレースを保存すると、評価結果をデータセットにリンクして、データセットの経時的な変更を追跡し、このデータセットを使用して生成されたすべての評価結果を確認できます。\n",
    "\n",
    "評価データセットをプログラムで作成するには、トレースを検索し、それらをデータセットに追加します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a20b341-d285-4f68-96cc-5562022b2879",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.get_active_model_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae57904f-5f16-497c-812d-341054c996c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.genai.datasets\n",
    "import time\n",
    "\n",
    "# 1. 評価データセットを作成\n",
    "\n",
    "uc_schema = \"workspace.default\"\n",
    "evaluation_dataset_table_name = \"email_generation_eval\"\n",
    "\n",
    "# すでにデータセットがある場合は削除\n",
    "try:\n",
    "    mlflow.genai.datasets.delete_dataset(\n",
    "        uc_table_name=f\"{uc_schema}.{evaluation_dataset_table_name}\",\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"評価データセットは存在しません: {e}\")\n",
    "\n",
    "# データセットを作成\n",
    "eval_dataset = mlflow.genai.datasets.create_dataset(\n",
    "    uc_table_name=f\"{uc_schema}.{evaluation_dataset_table_name}\",\n",
    ")\n",
    "print(f\"評価データセットを作成しました: {uc_schema}.{evaluation_dataset_table_name}\")\n",
    "\n",
    "# 2. sales_email_v1のトレースを全権取得\n",
    "traces = mlflow.search_traces(\n",
    "    model_id=mlflow.get_active_model_id(),\n",
    "    order_by=[\"attributes.timestamp_ms DESC\"],\n",
    ")\n",
    "\n",
    "print(f\"エクスペリメントから {len(traces)} 件の成功したトレースが見つかりました\")\n",
    "\n",
    "# 3. トレースを評価データセットに追加\n",
    "eval_dataset.merge_records(traces)\n",
    "print(f\"{len(traces)} 件のレコードを評価データセットに追加しました\")\n",
    "# データセットのプレビュー\n",
    "df = eval_dataset.to_df()\n",
    "print(f\"\\nデータセットのプレビュー:\")\n",
    "print(f\"総レコード数: {len(df)}\")\n",
    "print(\"\\nサンプルレコード:\")\n",
    "sample = df.iloc[0]\n",
    "print(f\"Inputs: {sample['inputs']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc0fd775-1792-4a56-a2f9-a2989009ae91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "eval_dataset = mlflow.genai.datasets.get_dataset(\n    uc_table_name=f\"{uc_schema}.{evaluation_dataset_table_name}\",\n)\n\ndisplay(eval_dataset.to_df())",
       "commandTitle": "可視化 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "DETAILS"
         },
         {
          "key": "options",
          "value": {
           "columns": [
            {
             "name": "dataset_record_id",
             "title": "dataset_record_id",
             "type": "string"
            },
            {
             "name": "inputs",
             "title": "inputs",
             "type": "string"
            },
            {
             "name": "expectations",
             "title": "expectations",
             "type": "string"
            },
            {
             "name": "source",
             "title": "source",
             "type": "string"
            },
            {
             "name": "tags",
             "title": "tags",
             "type": "string"
            },
            {
             "name": "create_time",
             "title": "create_time",
             "type": "string"
            },
            {
             "name": "last_update_time",
             "title": "last_update_time",
             "type": "string"
            },
            {
             "name": "created_by",
             "title": "created_by",
             "type": "string"
            },
            {
             "name": "last_updated_by",
             "title": "last_updated_by",
             "type": "string"
            }
           ],
           "version": 1
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {},
       "nuid": "17ea5ce6-2e3f-4404-91cd-c223090ab6de",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 4.53125,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {},
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_dataset = mlflow.genai.datasets.get_dataset(\n",
    "    uc_table_name=f\"{uc_schema}.{evaluation_dataset_table_name}\",\n",
    ")\n",
    "\n",
    "display(eval_dataset.to_df())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56bac03f-6e25-41c2-a0e7-fb2cedb8a04f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## ステップ4:事前定義されたスコアラーで評価を実行する[​](#ステップ4事前定義されたスコアラーで評価を実行�する \"ステップ4事前定義されたスコアラーで評価を実行する への直接リンク\")\n",
    "\n",
    "次に、MLflow に用意されている [定義済みのスコアラー](/aws/ja/mlflow3/genai/eval-monitor/concepts/judges/pre-built-judges-scorers) を使用して、生成AI アプリケーションの品質のさまざまな側面を自動的に評価してみましょう。詳細については、 [LLM ベースのスコアラー](/aws/ja/mlflow3/genai/eval-monitor/concepts/judges/) と [コードベースのスコアラー](/aws/ja/mlflow3/genai/eval-monitor/concepts/scorers) のリファレンスページを参照してください。\n",
    "\n",
    "注記\n",
    "\n",
    "必要に応じて、MLflow を使用してアプリケーションとプロンプトのバージョンを追跡できます。詳細については、 [トラック アプリとプロンプト バージョンの](/aws/ja/mlflow3/genai/prompt-version-mgmt/prompt-registry/track-prompts-app-versions) ガイドをご覧ください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8df34725-96db-43e1-aaf7-01ea02449d24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.genai.scorers import (\n",
    "    RetrievalGroundedness,\n",
    "    RelevanceToQuery,\n",
    "    Safety,\n",
    "    Guidelines,\n",
    ")\n",
    "\n",
    "# スコアラーを変数として保存し、ステップ7で再利用できるようにします\n",
    "\n",
    "email_scorers = [\n",
    "    RetrievalGroundedness(),  # メール内容が取得したデータに基づいているかをチェック\n",
    "    Guidelines(\n",
    "        name=\"follows_instructions\",\n",
    "        guidelines=\"生成されたメールは、リクエスト内のuser_instructions（ユーザー指示）に従っている必要があります。\",\n",
    "    ),\n",
    "    Guidelines(\n",
    "        name=\"concise_communication\",\n",
    "        guidelines=\"メールは必ず簡潔かつ要点を押さえている必要があります。重要な文脈を失うことなく、主要なメッセージを効率的に伝えるべきです。\",\n",
    "    ),\n",
    "    Guidelines(\n",
    "        name=\"mentions_contact_name\",\n",
    "        guidelines=\"メールの挨拶文で、顧客担当者のファーストネーム（例：Alice、Bob、Carol）を明示的に記載する必要があります。「Hello」や「Dear Customer」などの一般的な挨拶は不可とします。\",\n",
    "    ),\n",
    "    Guidelines(\n",
    "        name=\"professional_tone\",\n",
    "        guidelines=\"メールはプロフェッショナルな口調で書かれている必要があります。\",\n",
    "    ),\n",
    "    Guidelines(\n",
    "        name=\"includes_next_steps\",\n",
    "        guidelines=\"メールの最後に、具体的かつ実行可能な次のアクションと明確なタイムラインを必ず記載してください。\",\n",
    "    ),\n",
    "    RelevanceToQuery(),  # メールがユーザーのリクエストに対応しているかをチェック\n",
    "    Safety(),  # 有害または不適切な内容が含まれていないかをチェック\n",
    "]\n",
    "\n",
    "# 定義済みスコアラーで評価を実行\n",
    "eval_results = mlflow.genai.evaluate(\n",
    "    data=eval_dataset,\n",
    "    predict_fn=generate_sales_email,\n",
    "    scorers=email_scorers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbd65cf2-f015-4508-b6c1-cc53812e3208",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "eval_results.tables[\"eval_results\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aa838419-6f8c-4147-bf30-387064532702",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ステップ 5: 結果の表示と解釈[​](#ステップ-5-結果の表示と解釈 \"ステップ-5-結果の表示と解釈 への直接リンク\")\n",
    "\n",
    "`mlflow.genai.evaluate()`を実行すると、評価データセット内のすべての行の[トレース](/aws/ja/mlflow3/genai/tracing/)と、各スコアラーからの[フィードバック](/aws/ja/mlflow3/genai/tracing/data-model#feedback)が関連付けられた評価ランが作成されます。\n",
    "\n",
    "評価ランを使用して、次のことを行います。\n",
    "\n",
    "* **集計メトリクスの参照** : それぞれのスコアラーのすべてのテストケースにおける平均パフォーマンス\n",
    "* **個々の障害ケースのデバッグ** : 障害が発生した理由を理解し、将来のバージョンで行うべき改善点を特定します\n",
    "* **故障解析** :採点者が課題を特定した具体例\n",
    "\n",
    "この評価では、いくつかの問題が見られます。\n",
    "\n",
    "1. **不適切な指示フォロー** - エージェントは、簡単なチェックインを求められたときに詳細な製品情報を送信したり、熱心なお礼のメッセージを求められたときにサポートチケットの更新を提供したりするなど、ユーザーのリクエストと一致しない応答を頻繁に提供します\n",
    "2. **簡潔さの欠如** - ほとんどのEメールは不必要に長く、重要なメッセージを薄めるほど詳細が多すぎて、Eメールを「簡潔でパーソナライズ」に保つように指示されているにもかかわらず、効率的にコミュニケーションをとることができません。\n",
    "3. **具体的な次のステップが欠けている** - Eメールの大部分は、必須要素として特定された具体的なタイムラインを含む、具体的で実行可能な次のステップで終わらない\n",
    "\n",
    "* Using the UI* Using the SDK\n",
    "\n",
    "MLflow UI の [評価] タブから評価結果にアクセスし、アプリケーションのパフォーマンスを理解します。\n",
    "\n",
    "![trace](https://assets.docs.databricks.com/_static/images/mlflow3-genai/new-images/eval-guide-results.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93223fca-9d70-4000-8169-b848047fb134",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 評価実行のトレースを取得\n",
    "eval_traces = mlflow.search_traces(run_id=eval_results.run_id)\n",
    "\n",
    "# eval_tracesは評価されたトレースを含むPandas DataFrameです。`assessments`列には各スコアラーのフィードバックが含まれます。\n",
    "print(eval_traces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "64f97a2c-1a40-4774-b1f8-1c650e0735cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ステップ 6: 改良版を作成する[​](#ステップ-6-改良版を作成する \"ステップ-6-改良版を作成する への直接リンク\")\n",
    "\n",
    "評価結果に基づいて、特定された問題に対処する改善バージョンを作成しましょう。\n",
    "\n",
    "注記\n",
    "\n",
    "新しいバージョンの `generate_sales_email()` 関数では、最初のステップから `retrieve_customer_info()` 取得した関数を使用します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9d19fcd-14dc-41cb-9a37-fb704b6556e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 新しいLoggedModelを作成・設定\n",
    "active_model_info = mlflow.set_active_model(name=\"sales_email_v2\")\n",
    "\n",
    "@mlflow.trace\n",
    "def generate_sales_email_v2(\n",
    "    customer_name: str, user_instructions: str\n",
    ") -> Dict[str, str]:\n",
    "    \"\"\"顧客データと営業担当者の指示に基づいてパーソナライズされた営業メールを生成します。\"\"\"\n",
    "    # 顧客情報を取得\n",
    "    customer_docs = retrieve_customer_info(customer_name)\n",
    "\n",
    "    if not customer_docs:\n",
    "        return {\"error\": f\"{customer_name}の顧客データが見つかりません\"}\n",
    "\n",
    "    # 取得したコンテキストを結合\n",
    "    context = \"\\n\".join([doc.page_content for doc in customer_docs])\n",
    "\n",
    "    # より良い指示に従ってメールを生成\n",
    "    prompt = f\"\"\"あなたは営業担当者です。メールを書いてください。\n",
    "\n",
    "最も重要なこと: 以下のユーザー指示に正確に従ってください:\n",
    "{user_instructions}\n",
    "\n",
    "顧客コンテキスト（指示に関連するもののみ使用してください）:\n",
    "{context}\n",
    "\n",
    "ガイドライン:\n",
    "1. ユーザー指示を最優先にしてください\n",
    "2. メールは簡潔に - ユーザーのリクエストに直接関連する情報のみを含めてください\n",
    "3. 具体的で実行可能な次のステップを明確なタイムラインと共にメールの最後に記載してください（例：「金曜日までに価格をフォローアップします」や「今週15分の電話をスケジュールしましょう」）\n",
    "4. ユーザーの指示に直接関連する場合のみ顧客情報を参照してください\n",
    "\n",
    "ユーザーの正確なリクエストを満たす簡潔で焦点を絞ったメールを書いてください。\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"databricks-meta-llama-3-3-70b-instruct\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"あなたは簡潔で指示に焦点を当てたメールを書く役立つ営業アシスタントです。\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        max_tokens=2000,\n",
    "    )\n",
    "\n",
    "    return {\"email\": response.choices[0].message.content}\n",
    "\n",
    "# アプリケーションをテスト\n",
    "result = generate_sales_email(\"Acme Corp\", \"製品デモの後にフォローアップしてください\")\n",
    "print(result[\"email\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "720a2de5-ff1c-47e3-8d36-b5a3791ed35a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "# 新しいバージョンの評価を、以前と同じスコアラーを使用して実行します\n",
    "# start_runを使用してUIで評価ランを名前付けします\n",
    "with mlflow.start_run(run_name=\"v2\"):\n",
    "    eval_results_v2 = mlflow.genai.evaluate(\n",
    "        data=eval_dataset, # 同じデータセット\n",
    "        predict_fn=generate_sales_email_v2, # 新しいアプリバージョンの関数\n",
    "        scorers=email_scorers, # 前回と同じスコアラーを利用\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "60569602-4f37-47c0-8c25-ef5978ef0e5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 比較する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e65ac2d5-ed2b-4c4f-a22f-cd7af716ab3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# mlflow.search_runsはINやOR演算子をサポートしていないため、個別にランを取得\n",
    "run_v1_df = mlflow.search_runs(filter_string=f\"run_id = '{eval_results.run_id}'\")\n",
    "run_v2_df = mlflow.search_runs(filter_string=f\"run_id = '{eval_results_v2.run_id}'\")\n",
    "\n",
    "# メトリクス列を抽出（.aggregate_scoreではなく/meanで終わるもの）\n",
    "# 品質比較のため、エージェント系メトリクス（latency, token counts）は除外\n",
    "metric_cols = [\n",
    "    col\n",
    "    for col in run_v1_df.columns\n",
    "    if col.startswith(\"metrics.\") and col.endswith(\"/mean\") and \"agent/\" not in col\n",
    "]\n",
    "\n",
    "# 比較テーブルを作成\n",
    "comparison_data = []\n",
    "for metric in metric_cols:\n",
    "    metric_name = metric.replace(\"metrics.\", \"\").replace(\"/mean\", \"\")\n",
    "    v1_score = run_v1_df[metric].iloc[0]\n",
    "    v2_score = run_v2_df[metric].iloc[0]\n",
    "    improvement = v2_score - v1_score\n",
    "\n",
    "    comparison_data.append(\n",
    "        {\n",
    "            \"Metric\": metric_name,\n",
    "            \"V1 Score\": f\"{v1_score:.3f}\",\n",
    "            \"V2 Score\": f\"{v2_score:.3f}\",\n",
    "            \"Improvement\": f\"{improvement:+.3f}\",\n",
    "            \"Improved\": \"✓\" if improvement >= 0 else \"✗\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\n=== バージョン比較結果 ===\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# 全体の平均改善度を計算（品質メトリクスのみ対象）\n",
    "avg_v1 = run_v1_df[metric_cols].mean(axis=1).iloc[0]\n",
    "avg_v2 = run_v2_df[metric_cols].mean(axis=1).iloc[0]\n",
    "print(\n",
    "    f\"\\n全体平均の改善度: {(avg_v2 - avg_v1):+.3f} ({((avg_v2/avg_v1 - 1) * 100):+.1f}%)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66c35d32-8efc-45c0-a74d-19074bbf0799",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# 両バージョンの詳細なトレースを取得\n",
    "traces_v1 = mlflow.search_traces(run_id=eval_results.run_id)\n",
    "traces_v2 = mlflow.search_traces(run_id=eval_results_v2.run_id)\n",
    "\n",
    "# 入力パラメータに基づいてマージキーを作成\n",
    "traces_v1['merge_key'] = traces_v1['request'].apply(\n",
    "    lambda x: f\"{x.get('customer_name', '')}|{x.get('user_instructions', '')}\"\n",
    ")\n",
    "traces_v2['merge_key'] = traces_v2['request'].apply(\n",
    "    lambda x: f\"{x.get('customer_name', '')}|{x.get('user_instructions', '')}\"\n",
    ")\n",
    "\n",
    "# 同じ入力データでマージして比較\n",
    "merged = traces_v1.merge(\n",
    "    traces_v2,\n",
    "    on='merge_key',\n",
    "    suffixes=('_v1', '_v2')\n",
    ")\n",
    "\n",
    "print(f\"v1とv2の間で{len(merged)}の一致する例が見つかりました\")\n",
    "\n",
    "# 特定のメトリクスが改善しなかった例を見つける\n",
    "regression_examples = []\n",
    "\n",
    "for idx, row in merged.iterrows():\n",
    "    v1_assessments = {a.name: a for a in row['assessments_v1']}\n",
    "    v2_assessments = {a.name: a for a in row['assessments_v2']}\n",
    "\n",
    "    # 各スコアラーについてリグレッションをチェック\n",
    "    for scorer_name in ['follows_instructions', 'concise_communication', 'includes_next_steps', 'retrieval_groundedness']:\n",
    "        v1_assessment = v1_assessments.get(scorer_name)\n",
    "        v2_assessment = v2_assessments.get(scorer_name)\n",
    "\n",
    "        if v1_assessment and v2_assessment:\n",
    "            v1_val = v1_assessment.feedback.value\n",
    "            v2_val = v2_assessment.feedback.value\n",
    "\n",
    "            # メトリクスが悪化したかどうかをチェック（yes -> no）\n",
    "            if v1_val == 'yes' and v2_val == 'no':\n",
    "                regression_examples.append({\n",
    "                    'index': idx,\n",
    "                    'customer': row['request_v1']['customer_name'],\n",
    "                    'instructions': row['request_v1']['user_instructions'],\n",
    "                    'metric': scorer_name,\n",
    "                    'v1_score': v1_val,\n",
    "                    'v2_score': v2_val,\n",
    "                    'v1_rationale': v1_assessment.rationale,\n",
    "                    'v2_rationale': v2_assessment.rationale,\n",
    "                    'v1_response': row['response_v1']['email'],\n",
    "                    'v2_response': row['response_v2']['email']\n",
    "                })\n",
    "\n",
    "# リグレッションの例を表示\n",
    "if regression_examples:\n",
    "    print(f\"\\n=== {len(regression_examples)}のメトリクスリグレッションが見つかりました ===\\n\")\n",
    "\n",
    "    # メトリクスごとにグループ化\n",
    "    by_metric = {}\n",
    "    for ex in regression_examples:\n",
    "        metric = ex['metric']\n",
    "        if metric not in by_metric:\n",
    "            by_metric[metric] = []\n",
    "        by_metric[metric].append(ex)\n",
    "\n",
    "    # リグレッションが発生したメトリクスごとの例を表示\n",
    "    for metric, examples in by_metric.items():\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"メトリクスリグレッション: {metric}\")\n",
    "        print(f\"{'='*80}\")\n",
    "\n",
    "        # このメトリクスの最初の例を表示\n",
    "        ex = examples[0]\n",
    "        print(f\"\\n顧客: {ex['customer']}\")\n",
    "        print(f\"指示: {ex['instructions']}\")\n",
    "        print(f\"\\nV1スコア: ✓ (合格)\")\n",
    "        print(f\"V1理由: {ex['v1_rationale']}\")\n",
    "        print(f\"\\nV2スコア: ✗ (不合格)\")\n",
    "        print(f\"V2理由: {ex['v2_rationale']}\")\n",
    "\n",
    "        if len(examples) > 1:\n",
    "            print(f\"\\n(+{len(examples)-1}の例が{metric}リグレッションを含む)\")\n",
    "else:\n",
    "    print(\"\\n✓ メトリクスリグレッションは見つかりませんでした - V2はすべてのメトリクスを改善または維持しました！\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "005_評価とモニタリング",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
