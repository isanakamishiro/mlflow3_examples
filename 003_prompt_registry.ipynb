{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cc122c1b-3852-46ca-948c-ef667403622d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# MLflow Prompt Registryを使う\n",
    "\n",
    "https://docs.databricks.com/aws/ja/mlflow3/genai/prompt-version-mgmt/prompt-registry/reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01bbf4ea-8445-4836-ba67-58a1fae9f7df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "> **MLflow Prompt Registry**は、生成AI（GenAI）アプリケーションにおけるプロンプトエンジニアリングと管理を効率化する強力なツールです。組織内でプロンプトをバージョン管理・追跡・再利用できるため、プロンプト開発における一貫性の維持やコラボレーションの向上に役立ちます。\n",
    "> \n",
    "> - **再利用性**：プロンプトを一元管理し、複数のアプリケーションで再利用\n",
    "> - **バージョン管理**：Git風のコミットベースのバージョン管理と、差分比較（diffハイライト）によるプロンプトバージョンの進化の追跡\n",
    "> - **エイリアス**：柔軟なデプロイパイプラインを構築し、プロンプトバージョンをアプリケーション本体から分離。A/Bテストやロールバックも容易\n",
    "> - **系譜（Lineage）**：MLflowの既存機能（モデル追跡や評価）とシームレスに連携し、GenAIライフサイクル全体を管理\n",
    "> - **コラボレーション**：組織全体でプロンプトを共有し、チーム間でのプロンプト開発を促進\n",
    "> \n",
    "> MLflow Prompt RegistryのDatabricks Unity Catalogとの連携は近日公開予定です。\n",
    "> \n",
    "> ---\n",
    "> \n",
    "> ## Unity Catalogとの統合\n",
    "> \n",
    "> Prompt Registryは、Databricks Unity Catalogのガバナンスフレームワークを活用し、以下の機能を提供します。\n",
    "> \n",
    "> - **一元化されたプロンプト管理**：プロンプトテンプレートを統制・検索可能なレジストリで管理\n",
    "> - **バージョン管理**：プロンプトの変更履歴を完全な系譜とロールバック機能で追跡\n",
    "> - **アクセス制御**：Unity Catalogの権限システムを利用し、プロンプトの閲覧・編集・利用を制御\n",
    "> - **コラボレーション**：チーム間でのプロンプト開発の共有と協働を可能に\n",
    "> - **ガバナンス**：分類やコンプライアンス要件を含むデータガバナンスポリシーをプロンプトテンプレートに適用\n",
    "> \n",
    "> ---\n",
    "> \n",
    "> ### 詳細なアクセス制御\n",
    "> \n",
    "> - **個別・チーム・組織単位でのアクセス制御**\n",
    "> - **データの系譜追跡**：プロンプトが異なるアプリケーションや実験でどのように利用されているかを追跡\n",
    "> - **監査証跡**：プロンプトへのアクセスや変更を監視\n",
    "> - **分類とタグ付け**：メタデータでプロンプトを整理し、ガバナンスポリシーを適用\n",
    "> - **ワークスペース間での安全な共有**\n",
    "> \n",
    "> ---\n",
    "> \n",
    "> ## 今後の機能\n",
    "> \n",
    "> 今後、Prompt Registryでは以下の機能がサポートされる予定です。\n",
    "> \n",
    "> - **テンプレート管理**：変数置換機能付きでプロンプトテンプレートを作成・編集・バージョン管理\n",
    "> - **テストと検証**：デプロイ前に評価データセットでプロンプトをテスト\n",
    "> - **A/Bテスト**：異なるプロンプトバージョンを比較し、パフォーマンスを最適化\n",
    "> - **MLflow Trackingとの連携**：プロンプトバージョンと実験・モデル実行を自動的に関連付け\n",
    "> - **APIアクセス**：自動化ワークフローでプロンプトをプログラムから利用\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0795fff5-1f3b-4012-9eaf-ab9235a4d4ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install -U -q \"mlflow[databricks]>=3.1.0\" databricks-langchain openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d8348542-4c6e-4e44-b7ee-87ff21089b6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Original Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d806c0ab-e4ff-4d42-8e02-63ab84c7f565",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### プロンプトの登録"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c30b34c-ac03-4458-b0b1-1826a5ab501f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Autolog and Register MLflow Chat Prompt"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "catalog = \"workspace\"\n",
    "schema = \"default\"\n",
    "prompt_name = \"sample_prompt\"\n",
    "uc_prompt_name = f\"{catalog}.{schema}.{prompt_name}\"\n",
    "\n",
    "# Register a prompt template\n",
    "prompt = mlflow.genai.register_prompt(\n",
    "    name=uc_prompt_name,\n",
    "    template=\"あなたは親切なアシスタントです。次の問いに答えてください: {{question}}\",\n",
    "    commit_message=\"Initial Commit\"\n",
    ")\n",
    "print(f\"Created version {prompt.version}\")  # \"Created version 1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "165c9661-2497-47f7-b2d6-6a467e517cca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### プロンプトの取得・検索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62d3e42a-5da8-467d-b2c5-6de388a1f312",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "PromptVersion(name=workspace.default.sample_prompt, version=1, template=\"\\u3042\\u306a\\u305f\\u306f\\u89a...)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = mlflow.genai.load_prompt(name_or_uri=f\"prompts:/{uc_prompt_name}/1\")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cd392d4-f13c-4a46-9def-4474885f8f52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<PromptInfo: name='workspace.default.sample_prompt', description='Initial Commit', tags={'PromptVersionCount': '1'}>]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts = mlflow.genai.search_prompts(filter_string=f\"catalog='{catalog}' and schema='{schema}'\")\n",
    "prompts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "35844827-d7f8-4d0f-830d-583d8d962d69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### プロンプトの利用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "850bdfc9-667e-4463-811e-964593d63716",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "OpenAIを利用するケース"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'You are a considerate assistant. The next question is: \\n\"Databricksとは何ですか?\" \\nDatabricksは、Apache Sparkを基盤とするデータ分析およびデータ処理プラットフォームです。データエンジニアリング、データサイエンス、データアナリティクスのための統合環境を提供し、ビッグデータの処理と分析を容易にします。 \\nDatabricksは、Sparkの創始者たちが設立した会社によって開発され、Sparkの強力なデータ処理能力をさらに拡張し、使いやすさを向上させています。主な特徴は以下の通りです： \\n1. **Apache Sparkの統合**：DatabricksはApache Sparkを基にしており、Sparkのデータ処理能力をフルに活用できます。 \\n2. **インタラクティブなワークスペース**：ユーザーはノートブック形式でコードを記述し、即座に実行結果を確認できます。これにより、データの探索や分析が迅速に行えます。 \\n3. **コラボレーション機能**：チームメンバー同士でノートブックや結果を共有し、共同作業を行うことができます。 \\n4. **スケーラビリティ**：クラウドベースで提供されるため、必要に応じてリソースをスケールアップまたはスケールダウンできます。 \\n5. **セキュリティと管理機能**：エンタープライズ向けのセキュリティ機能や、データガバナンスのための管理機能が備わっています。 \\nDatabricksは、データ駆動型の意思決定を支援し、データ分析のプロセスを効率化するために設計されています。'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "\"tr-0a82926ac287cfc0fe848e1f7b76867a\"",
      "text/plain": [
       "Trace(trace_id=tr-0a82926ac287cfc0fe848e1f7b76867a)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mlflow\n",
    "from openai import OpenAI\n",
    "\n",
    "# MLflowの自動ロギングを有効にして、アプリケーションにトレースを追加\n",
    "mlflow.openai.autolog()\n",
    "\n",
    "# 実行ノートブックと同じ資格情報を使用してOpenAIクライアント経由でDatabricks LLMに接続\n",
    "mlflow_creds = mlflow.utils.databricks_utils.get_databricks_host_creds()\n",
    "client = OpenAI(\n",
    "    api_key=mlflow_creds.token,\n",
    "    base_url=f\"{mlflow_creds.host}/serving-endpoints\"\n",
    ")\n",
    "\n",
    "# レジストリからプロンプトをロード\n",
    "prompt = mlflow.genai.load_prompt(f\"prompts:/{uc_prompt_name}/1\")\n",
    "formatted_prompt = prompt.format(question=\"Databricksとは何ですか?\")\n",
    "\n",
    "# LLMを呼び出す\n",
    "response = client.chat.completions.create(\n",
    "    model=\"databricks-llama-4-maverick\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": formatted_prompt,\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e13d1d53-f7ea-461c-a1b5-ce29067445c5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "LangChainを利用するケース"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "あなたは\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "AIMessage(content='Databricks（ダタブリックス）は、Apache Sparkを基盤としてビッグデータを処理・分析するためのプラットフォームです。主な特徴は以下の通りです：\\n\\n1. **Apache Sparkの統合**: DatabricksはApache Sparkを基盤としているため、Sparkの強力なデータ処理能力を活用できます。Sparkは、分散データ処理に優れており、大規模なデータセットを高速に処理できます。\\n\\n2. **クラウド対応**: Databricksは、Amazon Web Services（AWS）、Microsoft Azure、Google Cloud Platform（GCP）などの主要なクラウドプロバイダー上で動作します。これにより、クラウドのスケーラビリティと柔軟性を活用できます。\\n\\n3. **インタラクティブな分析**: Databricksは、ノートブック形式でのインタラクティブな分析をサポートしています。ユーザーは、Python、R、Scala、SQLなどの言語を使用して、データを探索し、分析し、可視化できます。\\n\\n4. **共同作業**: Databricksのノートブックは、チームメンバーと共有でき、リアルタイムでの共同作業が可能です。これにより、データサイエンティスト、エンジニア、ビジネスアナリスト間のコラボレーションが促進されます。\\n\\n5. **セキュリティと管理**: Databricksは、データのセキュリティとガバナンスを確保するための機能を提供します。例えば、データの暗号化、アクセス制御、監査ログなどの機能があります。\\n\\n6. **自動化とスケジューリング**: Databricksは、ジョブの自動化とスケジューリングをサポートしています。これにより、定期的なデータ処理やレポート生成を自動化できます。\\n\\n7. **機械学習の統合**: Databricksは、機械学習ライブラリ（MLlib）を含むSparkの機能を活用して、機械学習モデルの構築、トレーニング、デプロイをサポートします。\\n\\n8. **データの可視化**: Databricksは、データを可視化するためのツールと統合されており、データの洞察をより深く理解するのに役立ちます。\\n\\nこれらの特徴により、Databricksは、ビッグデータの分析、データサイエンス、機械学習のプロジェクトに適したプラットフォームとなっています。', additional_kwargs={}, response_metadata={'id': 'chatcmpl_3fb8301c-caf8-49e2-86e7-75b0dc3d4073', 'object': 'chat.completion', 'created': 1750499044, 'model': 'meta-llama-4-maverick-040225', 'usage': {'prompt_tokens': 37, 'completion_tokens': 448, 'total_tokens': 485}, 'model_name': 'meta-llama-4-maverick-040225'}, id='run--ca3b3248-1265-4676-b4b1-341fa4b3d701-0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "\"tr-0a64bbde0dafc974cbae7b24cdac1e30\"",
      "text/plain": [
       "Trace(trace_id=tr-0a64bbde0dafc974cbae7b24cdac1e30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mlflow\n",
    "from databricks_langchain import ChatDatabricks\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import codecs\n",
    "\n",
    "# MLflowの自動ロギングを有効化\n",
    "mlflow.langchain.autolog()\n",
    "\n",
    "prompt = mlflow.genai.load_prompt(name_or_uri=f\"prompts:/{uc_prompt_name}/1\")\n",
    "\n",
    "# LangChainのプロンプトテンプレートをMLflowのPromptから作成する\n",
    "langchain_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"user\",\n",
    "            codecs.decode(prompt.to_single_brace_format(), \"unicode-escape\"),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = ChatDatabricks(model=\"databricks-llama-4-maverick\")\n",
    "chain = langchain_prompt | llm\n",
    "\n",
    "# チェーンを実行\n",
    "chain.invoke({\"question\": \"Databricksの特徴を教えてください\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "17fec413-848d-40ff-a1fd-88d5ae329a51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### エイリアスを設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01f2da2d-f1ed-4e1d-8d75-97a547dcb878",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.genai.set_prompt_alias(\n",
    "    name=f\"{uc_prompt_name}\",\n",
    "    alias=\"production\",\n",
    "    version=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c977b12-b294-408c-832c-100ad8af8b38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mRestException\u001B[0m                             Traceback (most recent call last)\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-4e52c6bd-2f7c-4058-a524-3308c9cc7922/lib/python3.11/site-packages/mlflow/tracking/client.py:921\u001B[0m, in \u001B[0;36mMlflowClient.parse_prompt_uri\u001B[0;34m(self, uri)\u001B[0m\n",
       "\u001B[1;32m    920\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m--> 921\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m get_model_name_and_version(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodels:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mparsed\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m    922\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m MlflowException:\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-4e52c6bd-2f7c-4058-a524-3308c9cc7922/lib/python3.11/site-packages/mlflow/store/artifact/utils/models.py:133\u001B[0m, in \u001B[0;36mget_model_name_and_version\u001B[0;34m(client, models_uri)\u001B[0m\n",
       "\u001B[1;32m    132\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_alias \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[0;32m--> 133\u001B[0m     mv \u001B[38;5;241m=\u001B[39m client\u001B[38;5;241m.\u001B[39mget_model_version_by_alias(model_name, model_alias)\n",
       "\u001B[1;32m    134\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model_name, mv\u001B[38;5;241m.\u001B[39mversion\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-4e52c6bd-2f7c-4058-a524-3308c9cc7922/lib/python3.11/site-packages/mlflow/tracking/_model_registry/client.py:451\u001B[0m, in \u001B[0;36mModelRegistryClient.get_model_version_by_alias\u001B[0;34m(self, name, alias)\u001B[0m\n",
       "\u001B[1;32m    441\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Get the model version instance by name and alias.\u001B[39;00m\n",
       "\u001B[1;32m    442\u001B[0m \n",
       "\u001B[1;32m    443\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m    449\u001B[0m \n",
       "\u001B[1;32m    450\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n",
       "\u001B[0;32m--> 451\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstore\u001B[38;5;241m.\u001B[39mget_model_version_by_alias(name, alias)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-4e52c6bd-2f7c-4058-a524-3308c9cc7922/lib/python3.11/site-packages/mlflow/store/_unity_catalog/registry/rest_store.py:1208\u001B[0m, in \u001B[0;36mUcModelRegistryStore.get_model_version_by_alias\u001B[0;34m(self, name, alias)\u001B[0m\n",
       "\u001B[1;32m   1207\u001B[0m req_body \u001B[38;5;241m=\u001B[39m message_to_json(GetModelVersionByAliasRequest(name\u001B[38;5;241m=\u001B[39mfull_name, alias\u001B[38;5;241m=\u001B[39malias))\n",
       "\u001B[0;32m-> 1208\u001B[0m response_proto \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_endpoint(GetModelVersionByAliasRequest, req_body)\n",
       "\u001B[1;32m   1209\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model_version_from_uc_proto(response_proto\u001B[38;5;241m.\u001B[39mmodel_version)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-4e52c6bd-2f7c-4058-a524-3308c9cc7922/lib/python3.11/site-packages/mlflow/store/model_registry/base_rest_store.py:42\u001B[0m, in \u001B[0;36mBaseRestStore._call_endpoint\u001B[0;34m(self, api, json_body, call_all_endpoints, extra_headers)\u001B[0m\n",
       "\u001B[1;32m     41\u001B[0m endpoint, method \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_endpoint_from_method(api)\n",
       "\u001B[0;32m---> 42\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m call_endpoint(\n",
       "\u001B[1;32m     43\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_host_creds(), endpoint, method, json_body, response_proto, extra_headers\n",
       "\u001B[1;32m     44\u001B[0m )\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-4e52c6bd-2f7c-4058-a524-3308c9cc7922/lib/python3.11/site-packages/mlflow/utils/rest_utils.py:590\u001B[0m, in \u001B[0;36mcall_endpoint\u001B[0;34m(host_creds, endpoint, method, json_body, response_proto, extra_headers, retry_timeout_seconds)\u001B[0m\n",
       "\u001B[1;32m    588\u001B[0m     response \u001B[38;5;241m=\u001B[39m http_request(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcall_kwargs)\n",
       "\u001B[0;32m--> 590\u001B[0m response \u001B[38;5;241m=\u001B[39m verify_rest_response(response, endpoint)\n",
       "\u001B[1;32m    591\u001B[0m response_to_parse \u001B[38;5;241m=\u001B[39m response\u001B[38;5;241m.\u001B[39mtext\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-4e52c6bd-2f7c-4058-a524-3308c9cc7922/lib/python3.11/site-packages/mlflow/utils/rest_utils.py:304\u001B[0m, in \u001B[0;36mverify_rest_response\u001B[0;34m(response, endpoint)\u001B[0m\n",
       "\u001B[1;32m    303\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _can_parse_as_json_object(response\u001B[38;5;241m.\u001B[39mtext):\n",
       "\u001B[0;32m--> 304\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m RestException(json\u001B[38;5;241m.\u001B[39mloads(response\u001B[38;5;241m.\u001B[39mtext))\n",
       "\u001B[1;32m    305\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\n",
       "\u001B[0;31mRestException\u001B[0m: RESOURCE_DOES_NOT_EXIST: Routine or Model 'workspace.default.sample_prompt' does not exist.\n",
       "\n",
       "During handling of the above exception, another exception occurred:\n",
       "\n",
       "\u001B[0;31mMlflowException\u001B[0m                           Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-8398490772614362>, line 1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m mlflow\u001B[38;5;241m.\u001B[39mgenai\u001B[38;5;241m.\u001B[39mload_prompt(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprompts:/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00muc_prompt_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m@production\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-4e52c6bd-2f7c-4058-a524-3308c9cc7922/lib/python3.11/site-packages/mlflow/prompt/registry_utils.py:124\u001B[0m, in \u001B[0;36mrequire_prompt_registry.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_prompt_supported_registry(registry_uri):\n",
       "\u001B[1;32m    119\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MlflowException(\n",
       "\u001B[1;32m    120\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m API is not supported with the current registry. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    121\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPrompts are supported in OSS MLflow and Unity Catalog, but not in the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    122\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlegacy Databricks workspace registry.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m    123\u001B[0m     )\n",
       "\u001B[0;32m--> 124\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-4e52c6bd-2f7c-4058-a524-3308c9cc7922/lib/python3.11/site-packages/mlflow/genai/prompts/__init__.py:157\u001B[0m, in \u001B[0;36mload_prompt\u001B[0;34m(name_or_uri, version, allow_missing)\u001B[0m\n",
       "\u001B[1;32m    129\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n",
       "\u001B[1;32m    130\u001B[0m \u001B[38;5;124;03mLoad a :py:class:`Prompt <mlflow.entities.Prompt>` from the MLflow Prompt Registry.\u001B[39;00m\n",
       "\u001B[1;32m    131\u001B[0m \n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m    154\u001B[0m \n",
       "\u001B[1;32m    155\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n",
       "\u001B[1;32m    156\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m suppress_genai_migration_warning():\n",
       "\u001B[0;32m--> 157\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m registry_api\u001B[38;5;241m.\u001B[39mload_prompt(\n",
       "\u001B[1;32m    158\u001B[0m         name_or_uri\u001B[38;5;241m=\u001B[39mname_or_uri, version\u001B[38;5;241m=\u001B[39mversion, allow_missing\u001B[38;5;241m=\u001B[39mallow_missing\n",
       "\u001B[1;32m    159\u001B[0m     )\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-4e52c6bd-2f7c-4058-a524-3308c9cc7922/lib/python3.11/site-packages/mlflow/prompt/registry_utils.py:124\u001B[0m, in \u001B[0;36mrequire_prompt_registry.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_prompt_supported_registry(registry_uri):\n",
       "\u001B[1;32m    119\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MlflowException(\n",
       "\u001B[1;32m    120\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m API is not supported with the current registry. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    121\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPrompts are supported in OSS MLflow and Unity Catalog, but not in the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    122\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlegacy Databricks workspace registry.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m    123\u001B[0m     )\n",
       "\u001B[0;32m--> 124\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-4e52c6bd-2f7c-4058-a524-3308c9cc7922/lib/python3.11/site-packages/mlflow/tracking/_model_registry/fluent.py:695\u001B[0m, in \u001B[0;36mload_prompt\u001B[0;34m(name_or_uri, version, allow_missing, link_to_model, model_id)\u001B[0m\n",
       "\u001B[1;32m    687\u001B[0m warnings\u001B[38;5;241m.\u001B[39mwarn(\n",
       "\u001B[1;32m    688\u001B[0m     PROMPT_API_MIGRATION_MSG\u001B[38;5;241m.\u001B[39mformat(func_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mload_prompt\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n",
       "\u001B[1;32m    689\u001B[0m     category\u001B[38;5;241m=\u001B[39m\u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n",
       "\u001B[1;32m    690\u001B[0m     stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m,\n",
       "\u001B[1;32m    691\u001B[0m )\n",
       "\u001B[1;32m    693\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m@\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m name_or_uri:\n",
       "\u001B[1;32m    694\u001B[0m     \u001B[38;5;66;03m# Don't cache prompts loaded by alias since aliases can change over time\u001B[39;00m\n",
       "\u001B[0;32m--> 695\u001B[0m     prompt \u001B[38;5;241m=\u001B[39m _load_prompt_not_cached(\n",
       "\u001B[1;32m    696\u001B[0m         name_or_uri\u001B[38;5;241m=\u001B[39mname_or_uri,\n",
       "\u001B[1;32m    697\u001B[0m         version\u001B[38;5;241m=\u001B[39mversion,\n",
       "\u001B[1;32m    698\u001B[0m         allow_missing\u001B[38;5;241m=\u001B[39mallow_missing,\n",
       "\u001B[1;32m    699\u001B[0m     )\n",
       "\u001B[1;32m    700\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    701\u001B[0m     \u001B[38;5;66;03m# Otherwise, we use a cached function to avoid loading the same prompt multiple times.\u001B[39;00m\n",
       "\u001B[1;32m    702\u001B[0m     \u001B[38;5;66;03m# If the prompt from the cache is not found and allowing_missing is True, we\u001B[39;00m\n",
       "\u001B[1;32m    703\u001B[0m     \u001B[38;5;66;03m# try to load the prompt from the client without cache, since it may have been\u001B[39;00m\n",
       "\u001B[1;32m    704\u001B[0m     \u001B[38;5;66;03m# registered after the cache was created (uncommon scenario).\u001B[39;00m\n",
       "\u001B[1;32m    705\u001B[0m     prompt \u001B[38;5;241m=\u001B[39m _load_prompt_cached(\n",
       "\u001B[1;32m    706\u001B[0m         name_or_uri\u001B[38;5;241m=\u001B[39mname_or_uri,\n",
       "\u001B[1;32m    707\u001B[0m         version\u001B[38;5;241m=\u001B[39mversion,\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m    712\u001B[0m         allow_missing\u001B[38;5;241m=\u001B[39mallow_missing,\n",
       "\u001B[1;32m    713\u001B[0m     )\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-4e52c6bd-2f7c-4058-a524-3308c9cc7922/lib/python3.11/site-packages/mlflow/tracking/_model_registry/fluent.py:793\u001B[0m, in \u001B[0;36m_load_prompt_not_cached\u001B[0;34m(name_or_uri, version, allow_missing)\u001B[0m\n",
       "\u001B[1;32m    790\u001B[0m parsed_name_or_uri, parsed_version \u001B[38;5;241m=\u001B[39m parse_prompt_name_or_uri(name_or_uri, version)\n",
       "\u001B[1;32m    791\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m parsed_name_or_uri\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprompts:/\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
       "\u001B[1;32m    792\u001B[0m     \u001B[38;5;66;03m# For URIs, don't pass version parameter\u001B[39;00m\n",
       "\u001B[0;32m--> 793\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m client\u001B[38;5;241m.\u001B[39mload_prompt(parsed_name_or_uri, allow_missing\u001B[38;5;241m=\u001B[39mallow_missing)\n",
       "\u001B[1;32m    794\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    795\u001B[0m     \u001B[38;5;66;03m# For names, use the parsed version\u001B[39;00m\n",
       "\u001B[1;32m    796\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m client\u001B[38;5;241m.\u001B[39mload_prompt(\n",
       "\u001B[1;32m    797\u001B[0m         parsed_name_or_uri, version\u001B[38;5;241m=\u001B[39mparsed_version, allow_missing\u001B[38;5;241m=\u001B[39mallow_missing\n",
       "\u001B[1;32m    798\u001B[0m     )\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-4e52c6bd-2f7c-4058-a524-3308c9cc7922/lib/python3.11/site-packages/mlflow/prompt/registry_utils.py:124\u001B[0m, in \u001B[0;36mrequire_prompt_registry.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_prompt_supported_registry(registry_uri):\n",
       "\u001B[1;32m    119\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MlflowException(\n",
       "\u001B[1;32m    120\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m API is not supported with the current registry. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    121\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPrompts are supported in OSS MLflow and Unity Catalog, but not in the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    122\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlegacy Databricks workspace registry.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m    123\u001B[0m     )\n",
       "\u001B[0;32m--> 124\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-4e52c6bd-2f7c-4058-a524-3308c9cc7922/lib/python3.11/site-packages/mlflow/prompt/registry_utils.py:159\u001B[0m, in \u001B[0;36mtranslate_prompt_exception.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    157\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MlflowException(new_message) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
       "\u001B[1;32m    158\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[0;32m--> 159\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-4e52c6bd-2f7c-4058-a524-3308c9cc7922/lib/python3.11/site-packages/mlflow/prompt/registry_utils.py:148\u001B[0m, in \u001B[0;36mtranslate_prompt_exception.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    145\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n",
       "\u001B[1;32m    146\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n",
       "\u001B[1;32m    147\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m--> 148\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[1;32m    149\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m MlflowException \u001B[38;5;28;01mas\u001B[39;00m e:\n",
       "\u001B[1;32m    150\u001B[0m         original_message \u001B[38;5;241m=\u001B[39m e\u001B[38;5;241m.\u001B[39mmessage\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-4e52c6bd-2f7c-4058-a524-3308c9cc7922/lib/python3.11/site-packages/mlflow/tracking/client.py:682\u001B[0m, in \u001B[0;36mMlflowClient.load_prompt\u001B[0;34m(self, name_or_uri, version, allow_missing)\u001B[0m\n",
       "\u001B[1;32m    679\u001B[0m parsed_name_or_uri, parsed_version \u001B[38;5;241m=\u001B[39m parse_prompt_name_or_uri(name_or_uri, version)\n",
       "\u001B[1;32m    680\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m parsed_name_or_uri\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprompts:/\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
       "\u001B[1;32m    681\u001B[0m     \u001B[38;5;66;03m# URI case: parse the URI to extract name and version\u001B[39;00m\n",
       "\u001B[0;32m--> 682\u001B[0m     name, version \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparse_prompt_uri(parsed_name_or_uri)\n",
       "\u001B[1;32m    683\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    684\u001B[0m     \u001B[38;5;66;03m# Name case: use the name and provided version\u001B[39;00m\n",
       "\u001B[1;32m    685\u001B[0m     name \u001B[38;5;241m=\u001B[39m parsed_name_or_uri\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-4e52c6bd-2f7c-4058-a524-3308c9cc7922/lib/python3.11/site-packages/mlflow/tracking/client.py:923\u001B[0m, in \u001B[0;36mMlflowClient.parse_prompt_uri\u001B[0;34m(self, uri)\u001B[0m\n",
       "\u001B[1;32m    921\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m get_model_name_and_version(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodels:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mparsed\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m    922\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m MlflowException:\n",
       "\u001B[0;32m--> 923\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MlflowException(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPrompt \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00muri\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m does not exist.\u001B[39m\u001B[38;5;124m\"\u001B[39m, RESOURCE_DOES_NOT_EXIST)\n",
       "\n",
       "\u001B[0;31mMlflowException\u001B[0m: Prompt 'prompts:/workspace.default.sample_prompt@production' does not exist."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "MlflowException",
        "evalue": "Prompt 'prompts:/workspace.default.sample_prompt@production' does not exist."
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>MlflowException</span>: Prompt 'prompts:/workspace.default.sample_prompt@production' does not exist."
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mRestException\u001B[0m                             Traceback (most recent call last)",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-4e52c6bd-2f7c-4058-a524-3308c9cc7922/lib/python3.11/site-packages/mlflow/tracking/client.py:921\u001B[0m, in \u001B[0;36mMlflowClient.parse_prompt_uri\u001B[0;34m(self, uri)\u001B[0m\n\u001B[1;32m    920\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 921\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m get_model_name_and_version(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodels:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mparsed\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    922\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m MlflowException:\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-4e52c6bd-2f7c-4058-a524-3308c9cc7922/lib/python3.11/site-packages/mlflow/store/artifact/utils/models.py:133\u001B[0m, in \u001B[0;36mget_model_name_and_version\u001B[0;34m(client, models_uri)\u001B[0m\n\u001B[1;32m    132\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_alias \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 133\u001B[0m     mv \u001B[38;5;241m=\u001B[39m client\u001B[38;5;241m.\u001B[39mget_model_version_by_alias(model_name, model_alias)\n\u001B[1;32m    134\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model_name, mv\u001B[38;5;241m.\u001B[39mversion\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-4e52c6bd-2f7c-4058-a524-3308c9cc7922/lib/python3.11/site-packages/mlflow/tracking/_model_registry/client.py:451\u001B[0m, in \u001B[0;36mModelRegistryClient.get_model_version_by_alias\u001B[0;34m(self, name, alias)\u001B[0m\n\u001B[1;32m    441\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Get the model version instance by name and alias.\u001B[39;00m\n\u001B[1;32m    442\u001B[0m \n\u001B[1;32m    443\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    449\u001B[0m \n\u001B[1;32m    450\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m--> 451\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstore\u001B[38;5;241m.\u001B[39mget_model_version_by_alias(name, alias)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-4e52c6bd-2f7c-4058-a524-3308c9cc7922/lib/python3.11/site-packages/mlflow/store/_unity_catalog/registry/rest_store.py:1208\u001B[0m, in \u001B[0;36mUcModelRegistryStore.get_model_version_by_alias\u001B[0;34m(self, name, alias)\u001B[0m\n\u001B[1;32m   1207\u001B[0m req_body \u001B[38;5;241m=\u001B[39m message_to_json(GetModelVersionByAliasRequest(name\u001B[38;5;241m=\u001B[39mfull_name, alias\u001B[38;5;241m=\u001B[39malias))\n\u001B[0;32m-> 1208\u001B[0m response_proto \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_endpoint(GetModelVersionByAliasRequest, req_body)\n\u001B[1;32m   1209\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model_version_from_uc_proto(response_proto\u001B[38;5;241m.\u001B[39mmodel_version)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-4e52c6bd-2f7c-4058-a524-3308c9cc7922/lib/python3.11/site-packages/mlflow/store/model_registry/base_rest_store.py:42\u001B[0m, in \u001B[0;36mBaseRestStore._call_endpoint\u001B[0;34m(self, api, json_body, call_all_endpoints, extra_headers)\u001B[0m\n\u001B[1;32m     41\u001B[0m endpoint, method \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_endpoint_from_method(api)\n\u001B[0;32m---> 42\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m call_endpoint(\n\u001B[1;32m     43\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_host_creds(), endpoint, method, json_body, response_proto, extra_headers\n\u001B[1;32m     44\u001B[0m )\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-4e52c6bd-2f7c-4058-a524-3308c9cc7922/lib/python3.11/site-packages/mlflow/utils/rest_utils.py:590\u001B[0m, in \u001B[0;36mcall_endpoint\u001B[0;34m(host_creds, endpoint, method, json_body, response_proto, extra_headers, retry_timeout_seconds)\u001B[0m\n\u001B[1;32m    588\u001B[0m     response \u001B[38;5;241m=\u001B[39m http_request(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcall_kwargs)\n\u001B[0;32m--> 590\u001B[0m response \u001B[38;5;241m=\u001B[39m verify_rest_response(response, endpoint)\n\u001B[1;32m    591\u001B[0m response_to_parse \u001B[38;5;241m=\u001B[39m response\u001B[38;5;241m.\u001B[39mtext\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-4e52c6bd-2f7c-4058-a524-3308c9cc7922/lib/python3.11/site-packages/mlflow/utils/rest_utils.py:304\u001B[0m, in \u001B[0;36mverify_rest_response\u001B[0;34m(response, endpoint)\u001B[0m\n\u001B[1;32m    303\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _can_parse_as_json_object(response\u001B[38;5;241m.\u001B[39mtext):\n\u001B[0;32m--> 304\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m RestException(json\u001B[38;5;241m.\u001B[39mloads(response\u001B[38;5;241m.\u001B[39mtext))\n\u001B[1;32m    305\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
        "\u001B[0;31mRestException\u001B[0m: RESOURCE_DOES_NOT_EXIST: Routine or Model 'workspace.default.sample_prompt' does not exist.",
        "\nDuring handling of the above exception, another exception occurred:\n",
        "\u001B[0;31mMlflowException\u001B[0m                           Traceback (most recent call last)",
        "File \u001B[0;32m<command-8398490772614362>, line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m mlflow\u001B[38;5;241m.\u001B[39mgenai\u001B[38;5;241m.\u001B[39mload_prompt(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprompts:/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00muc_prompt_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m@production\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-4e52c6bd-2f7c-4058-a524-3308c9cc7922/lib/python3.11/site-packages/mlflow/prompt/registry_utils.py:124\u001B[0m, in \u001B[0;36mrequire_prompt_registry.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_prompt_supported_registry(registry_uri):\n\u001B[1;32m    119\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MlflowException(\n\u001B[1;32m    120\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m API is not supported with the current registry. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    121\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPrompts are supported in OSS MLflow and Unity Catalog, but not in the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    122\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlegacy Databricks workspace registry.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    123\u001B[0m     )\n\u001B[0;32m--> 124\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-4e52c6bd-2f7c-4058-a524-3308c9cc7922/lib/python3.11/site-packages/mlflow/genai/prompts/__init__.py:157\u001B[0m, in \u001B[0;36mload_prompt\u001B[0;34m(name_or_uri, version, allow_missing)\u001B[0m\n\u001B[1;32m    129\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    130\u001B[0m \u001B[38;5;124;03mLoad a :py:class:`Prompt <mlflow.entities.Prompt>` from the MLflow Prompt Registry.\u001B[39;00m\n\u001B[1;32m    131\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    154\u001B[0m \n\u001B[1;32m    155\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    156\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m suppress_genai_migration_warning():\n\u001B[0;32m--> 157\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m registry_api\u001B[38;5;241m.\u001B[39mload_prompt(\n\u001B[1;32m    158\u001B[0m         name_or_uri\u001B[38;5;241m=\u001B[39mname_or_uri, version\u001B[38;5;241m=\u001B[39mversion, allow_missing\u001B[38;5;241m=\u001B[39mallow_missing\n\u001B[1;32m    159\u001B[0m     )\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-4e52c6bd-2f7c-4058-a524-3308c9cc7922/lib/python3.11/site-packages/mlflow/prompt/registry_utils.py:124\u001B[0m, in \u001B[0;36mrequire_prompt_registry.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_prompt_supported_registry(registry_uri):\n\u001B[1;32m    119\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MlflowException(\n\u001B[1;32m    120\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m API is not supported with the current registry. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    121\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPrompts are supported in OSS MLflow and Unity Catalog, but not in the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    122\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlegacy Databricks workspace registry.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    123\u001B[0m     )\n\u001B[0;32m--> 124\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-4e52c6bd-2f7c-4058-a524-3308c9cc7922/lib/python3.11/site-packages/mlflow/tracking/_model_registry/fluent.py:695\u001B[0m, in \u001B[0;36mload_prompt\u001B[0;34m(name_or_uri, version, allow_missing, link_to_model, model_id)\u001B[0m\n\u001B[1;32m    687\u001B[0m warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    688\u001B[0m     PROMPT_API_MIGRATION_MSG\u001B[38;5;241m.\u001B[39mformat(func_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mload_prompt\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m    689\u001B[0m     category\u001B[38;5;241m=\u001B[39m\u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[1;32m    690\u001B[0m     stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m,\n\u001B[1;32m    691\u001B[0m )\n\u001B[1;32m    693\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m@\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m name_or_uri:\n\u001B[1;32m    694\u001B[0m     \u001B[38;5;66;03m# Don't cache prompts loaded by alias since aliases can change over time\u001B[39;00m\n\u001B[0;32m--> 695\u001B[0m     prompt \u001B[38;5;241m=\u001B[39m _load_prompt_not_cached(\n\u001B[1;32m    696\u001B[0m         name_or_uri\u001B[38;5;241m=\u001B[39mname_or_uri,\n\u001B[1;32m    697\u001B[0m         version\u001B[38;5;241m=\u001B[39mversion,\n\u001B[1;32m    698\u001B[0m         allow_missing\u001B[38;5;241m=\u001B[39mallow_missing,\n\u001B[1;32m    699\u001B[0m     )\n\u001B[1;32m    700\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    701\u001B[0m     \u001B[38;5;66;03m# Otherwise, we use a cached function to avoid loading the same prompt multiple times.\u001B[39;00m\n\u001B[1;32m    702\u001B[0m     \u001B[38;5;66;03m# If the prompt from the cache is not found and allowing_missing is True, we\u001B[39;00m\n\u001B[1;32m    703\u001B[0m     \u001B[38;5;66;03m# try to load the prompt from the client without cache, since it may have been\u001B[39;00m\n\u001B[1;32m    704\u001B[0m     \u001B[38;5;66;03m# registered after the cache was created (uncommon scenario).\u001B[39;00m\n\u001B[1;32m    705\u001B[0m     prompt \u001B[38;5;241m=\u001B[39m _load_prompt_cached(\n\u001B[1;32m    706\u001B[0m         name_or_uri\u001B[38;5;241m=\u001B[39mname_or_uri,\n\u001B[1;32m    707\u001B[0m         version\u001B[38;5;241m=\u001B[39mversion,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    712\u001B[0m         allow_missing\u001B[38;5;241m=\u001B[39mallow_missing,\n\u001B[1;32m    713\u001B[0m     )\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-4e52c6bd-2f7c-4058-a524-3308c9cc7922/lib/python3.11/site-packages/mlflow/tracking/_model_registry/fluent.py:793\u001B[0m, in \u001B[0;36m_load_prompt_not_cached\u001B[0;34m(name_or_uri, version, allow_missing)\u001B[0m\n\u001B[1;32m    790\u001B[0m parsed_name_or_uri, parsed_version \u001B[38;5;241m=\u001B[39m parse_prompt_name_or_uri(name_or_uri, version)\n\u001B[1;32m    791\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m parsed_name_or_uri\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprompts:/\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    792\u001B[0m     \u001B[38;5;66;03m# For URIs, don't pass version parameter\u001B[39;00m\n\u001B[0;32m--> 793\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m client\u001B[38;5;241m.\u001B[39mload_prompt(parsed_name_or_uri, allow_missing\u001B[38;5;241m=\u001B[39mallow_missing)\n\u001B[1;32m    794\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    795\u001B[0m     \u001B[38;5;66;03m# For names, use the parsed version\u001B[39;00m\n\u001B[1;32m    796\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m client\u001B[38;5;241m.\u001B[39mload_prompt(\n\u001B[1;32m    797\u001B[0m         parsed_name_or_uri, version\u001B[38;5;241m=\u001B[39mparsed_version, allow_missing\u001B[38;5;241m=\u001B[39mallow_missing\n\u001B[1;32m    798\u001B[0m     )\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-4e52c6bd-2f7c-4058-a524-3308c9cc7922/lib/python3.11/site-packages/mlflow/prompt/registry_utils.py:124\u001B[0m, in \u001B[0;36mrequire_prompt_registry.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_prompt_supported_registry(registry_uri):\n\u001B[1;32m    119\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MlflowException(\n\u001B[1;32m    120\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m API is not supported with the current registry. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    121\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPrompts are supported in OSS MLflow and Unity Catalog, but not in the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    122\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlegacy Databricks workspace registry.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    123\u001B[0m     )\n\u001B[0;32m--> 124\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-4e52c6bd-2f7c-4058-a524-3308c9cc7922/lib/python3.11/site-packages/mlflow/prompt/registry_utils.py:159\u001B[0m, in \u001B[0;36mtranslate_prompt_exception.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    157\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MlflowException(new_message) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m    158\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 159\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-4e52c6bd-2f7c-4058-a524-3308c9cc7922/lib/python3.11/site-packages/mlflow/prompt/registry_utils.py:148\u001B[0m, in \u001B[0;36mtranslate_prompt_exception.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    145\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    146\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    147\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 148\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    149\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m MlflowException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    150\u001B[0m         original_message \u001B[38;5;241m=\u001B[39m e\u001B[38;5;241m.\u001B[39mmessage\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-4e52c6bd-2f7c-4058-a524-3308c9cc7922/lib/python3.11/site-packages/mlflow/tracking/client.py:682\u001B[0m, in \u001B[0;36mMlflowClient.load_prompt\u001B[0;34m(self, name_or_uri, version, allow_missing)\u001B[0m\n\u001B[1;32m    679\u001B[0m parsed_name_or_uri, parsed_version \u001B[38;5;241m=\u001B[39m parse_prompt_name_or_uri(name_or_uri, version)\n\u001B[1;32m    680\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m parsed_name_or_uri\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprompts:/\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    681\u001B[0m     \u001B[38;5;66;03m# URI case: parse the URI to extract name and version\u001B[39;00m\n\u001B[0;32m--> 682\u001B[0m     name, version \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparse_prompt_uri(parsed_name_or_uri)\n\u001B[1;32m    683\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    684\u001B[0m     \u001B[38;5;66;03m# Name case: use the name and provided version\u001B[39;00m\n\u001B[1;32m    685\u001B[0m     name \u001B[38;5;241m=\u001B[39m parsed_name_or_uri\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-4e52c6bd-2f7c-4058-a524-3308c9cc7922/lib/python3.11/site-packages/mlflow/tracking/client.py:923\u001B[0m, in \u001B[0;36mMlflowClient.parse_prompt_uri\u001B[0;34m(self, uri)\u001B[0m\n\u001B[1;32m    921\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m get_model_name_and_version(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodels:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mparsed\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    922\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m MlflowException:\n\u001B[0;32m--> 923\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MlflowException(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPrompt \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00muri\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m does not exist.\u001B[39m\u001B[38;5;124m\"\u001B[39m, RESOURCE_DOES_NOT_EXIST)\n",
        "\u001B[0;31mMlflowException\u001B[0m: Prompt 'prompts:/workspace.default.sample_prompt@production' does not exist."
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlflow.genai.load_prompt(f\"prompts:/{uc_prompt_name}@production\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aebb8571-ee22-439d-90b4-8f802fcf4537",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Quick Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82cfd361-045d-4993-b8d1-cba1c2447543",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created version 3\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "\"tr-c7b8ba83c3de6180d3af6a04a8e03038\"",
      "text/plain": [
       "Trace(trace_id=tr-c7b8ba83c3de6180d3af6a04a8e03038)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mlflow\n",
    "from databricks_langchain import ChatDatabricks\n",
    "\n",
    "mlflow.langchain.autolog()\n",
    "\n",
    "uc_name = \"workspace.default.customer_support\"\n",
    "\n",
    "# Register a prompt template\n",
    "prompt = mlflow.genai.register_prompt(\n",
    "    name=uc_name,\n",
    "    template=\"あなたは親切なアシスタントです。次の問いに答えてください: {{question}}\",\n",
    "    commit_message=\"初期カスタマーアシスタントプロンプト\"\n",
    ")\n",
    "print(f\"Created version {prompt.version}\")  # \"Created version 1\"\n",
    "\n",
    "# Set a production alias\n",
    "mlflow.genai.set_prompt_alias(\n",
    "    name=uc_name,\n",
    "    alias=\"production\",\n",
    "    version=1\n",
    ")\n",
    "\n",
    "llm = ChatDatabricks(model=\"databricks-llama-4-maverick\")\n",
    "\n",
    "# Load and use the prompt in your application\n",
    "prompt = mlflow.genai.load_prompt(name_or_uri=f\"prompts:/{uc_name}/1\")\n",
    "response = llm.invoke(prompt.format(question=\"How do I reset my password?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0037cfc8-0ded-4559-88ee-1a37cb88a684",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# アプリバージョンとの紐づけ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "916ddb85-b138-4de2-a323-a5b72873e4a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created prompt 'workspace.default.customer_support_prompt' (version 1)\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Replace with a Unity Catalog schema where you have CREATE FUNCTION permission\n",
    "uc_schema = \"workspace.default\"\n",
    "prompt_name = \"customer_support_prompt\"\n",
    "\n",
    "# Define the prompt template with variables\n",
    "initial_template = \"\"\"\\\n",
    "You are a helpful customer support assistant for {{company_name}}.\n",
    "\n",
    "Please help the customer with their inquiry about: {{topic}}\n",
    "\n",
    "Customer Question: {{question}}\n",
    "\n",
    "Provide a friendly, professional response that addresses their concern.\n",
    "\"\"\"\n",
    "\n",
    "# Register a new prompt\n",
    "prompt = mlflow.genai.register_prompt(\n",
    "    name=f\"{uc_schema}.{prompt_name}\",\n",
    "    template=initial_template,\n",
    "    commit_message=\"Initial customer support prompt\",\n",
    "    # version_metadata={\n",
    "    #     \"author\": \"support-team@company.com\",\n",
    "    #     \"use_case\": \"customer_service\"\n",
    "    # },\n",
    "    tags={\n",
    "        \"department\": \"customer_support\",\n",
    "        \"language\": \"en\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Created prompt '{prompt.name}' (version {prompt.version})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "82cfa09f-dde7-4a30-ad5f-c00bdc3901d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.delete_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26170248-55f0-4339-a0ea-c2226da0570a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: not a git repository (or any parent up to mount point /)\nStopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n2025/06/21 07:52:12 INFO mlflow.tracking.fluent: Active model is set to the logged model with ID: m-5791397404554c41b313f492fd4b1593\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active LoggedModel: 'customer_support_agent-local-dev', Model ID: 'm-5791397404554c41b313f492fd4b1593'\nLoaded prompt version 1\n\nResponse: \"Thank you for reaching out to us about the issue with your subscription billing. I'm so sorry to hear that you were charged twice last month. I'd be happy to help you resolve this as quickly as possible.\n\nTo assist you better, could you please provide me with your account details, such as your username or the email address associated with your TechCorp account? This will allow me to look into the matter further.\n\nIn the meantime, I'll also check on our end to see if there were any issues with our billing system that might have caused the duplicate charge. We'll work together to get this sorted out and ensure that you're charged correctly going forward.\n\nOnce I have your account information, I'll be able to tell you the next steps to rectify the situation, which may include issuing a refund for the duplicate charge. Your satisfaction is our top priority, and I'm committed to getting this resolved for you promptly.\"\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "\"tr-f84046f2ab3fe54d53f7d81b762321e3\"",
      "text/plain": [
       "Trace(trace_id=tr-f84046f2ab3fe54d53f7d81b762321e3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mlflow\n",
    "import subprocess\n",
    "from openai import OpenAI\n",
    "\n",
    "# MLflowの自動ロギングを有効にして、アプリケーションにトレースを追加\n",
    "mlflow.openai.autolog()\n",
    "\n",
    "# 同じ資格情報を使用してOpenAI経由でDatabricks LLMに接続\n",
    "# 代わりに独自のOpenAI資格情報を使用することも可能\n",
    "mlflow_creds = mlflow.utils.databricks_utils.get_databricks_host_creds()\n",
    "client = OpenAI(\n",
    "    api_key=mlflow_creds.token,\n",
    "    base_url=f\"{mlflow_creds.host}/serving-endpoints\"\n",
    ")\n",
    "\n",
    "# アプリケーションとそのバージョン識別子を定義\n",
    "app_name = \"customer_support_agent\"\n",
    "\n",
    "# バージョニングのために現在のgitコミットハッシュを取得\n",
    "try:\n",
    "    git_commit = (\n",
    "        subprocess.check_output([\"git\", \"rev-parse\", \"HEAD\"])\n",
    "        .decode(\"ascii\")\n",
    "        .strip()[:8]\n",
    "    )\n",
    "    version_identifier = f\"git-{git_commit}\"\n",
    "except subprocess.CalledProcessError:\n",
    "    version_identifier = \"local-dev\"  # gitリポジトリにない場合のフォールバック\n",
    "logged_model_name = f\"{app_name}-{version_identifier}\"\n",
    "\n",
    "# アクティブなモデルコンテキストを設定 - これにより、このバージョンのアプリケーションを表すLoggedModelが作成される\n",
    "active_model_info = mlflow.set_active_model(name=logged_model_name)\n",
    "print(\n",
    "    f\"Active LoggedModel: '{active_model_info.name}', Model ID: '{active_model_info.model_id}'\"\n",
    ")\n",
    "\n",
    "# アプリケーションパラメータをログ\n",
    "# これらのパラメータは、このアプリケーションバージョンの構成を追跡するのに役立つ\n",
    "app_params = {\n",
    "    \"llm\": \"databricks-llama-4-maverick\",\n",
    "    \"temperature\": 0.7,\n",
    "    \"max_tokens\": 500\n",
    "}\n",
    "# mlflow.log_model_params(model_id=active_model_info.model_id, params=app_params)\n",
    "\n",
    "# レジストリからプロンプトをロード\n",
    "# 注意: set_active_model()を呼び出した後にプロンプトをロードすることが、プロンプトバージョンとLoggedModelの間の自動系譜追跡を可能にする\n",
    "prompt = mlflow.genai.load_prompt(f\"prompts:/{uc_schema}.{prompt_name}/1\")\n",
    "print(f\"Loaded prompt version {prompt.version}\")\n",
    "\n",
    "# トレースデコレータを使用してアプリケーションのエントリポイントをキャプチャ\n",
    "# この関数によって作成された各トレースは、上記で設定したLoggedModel（アプリケーションバージョン）に自動的にリンクされる。さらに、LoggedModelはレジストリからロードされたプロンプトバージョンにリンクされる\n",
    "@mlflow.trace\n",
    "def customer_support_app(company_name: str, topic: str, question: str):\n",
    "    # 変数でプロンプトをフォーマット\n",
    "    formatted_prompt = prompt.format(\n",
    "        company_name=company_name,\n",
    "        topic=topic,\n",
    "        question=question\n",
    "    )\n",
    "\n",
    "    # LLMを呼び出す\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"databricks-llama-4-maverick\",  # モデルを置き換える\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": formatted_prompt,\n",
    "            },\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=500\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# アプリケーションをテスト\n",
    "result = customer_support_app(\n",
    "    company_name=\"TechCorp\",\n",
    "    topic=\"billing\",\n",
    "    question=\"I was charged twice for my subscription last month. Can you help?\"\n",
    ")\n",
    "print(f\"\\nResponse: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad9b4d46-f2a4-4fa3-95df-ccfae6559130",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created version 2 of 'workspace.default.customer_support_prompt'\n"
     ]
    }
   ],
   "source": [
    "# Create an improved version of the prompt\n",
    "improved_template = \"\"\"\\\n",
    "You are a helpful and empathetic customer support assistant for {{company_name}}.\n",
    "\n",
    "Customer Topic: {{topic}}\n",
    "Customer Question: {{question}}\n",
    "\n",
    "Please provide a response that:\n",
    "1. Acknowledges the customer's concern with empathy\n",
    "2. Provides a clear solution or next steps\n",
    "3. Offers additional assistance if needed\n",
    "4. Maintains a friendly, professional tone\n",
    "\n",
    "Remember to:\n",
    "- Use the customer's name if provided\n",
    "- Be concise but thorough\n",
    "- Avoid technical jargon unless necessary\n",
    "\"\"\"\n",
    "\n",
    "# Register the new version\n",
    "updated_prompt = mlflow.genai.register_prompt(\n",
    "    name=f\"{uc_schema}.{prompt_name}\",\n",
    "    template=improved_template,\n",
    "    commit_message=\"Added structured response guidelines for better customer experience\",\n",
    "    # version_metadata={\n",
    "    #     \"author\": \"support-team@company.com\",\n",
    "    #     \"improvement\": \"Added empathy guidelines and response structure\"\n",
    "    # }\n",
    ")\n",
    "\n",
    "print(f\"Created version {updated_prompt.version} of '{updated_prompt.name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6eae67b-5fe1-4024-a214-4d41deedd494",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/21 07:54:50 INFO mlflow.tracking.fluent: LoggedModel with name 'customer_support_agent-v2-improved-prompt' does not exist, creating one...\n2025/06/21 07:54:51 INFO mlflow.tracking.fluent: Active model is set to the logged model with ID: m-3204036e75134c91bb6e032e782b0b4d\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active LoggedModel: 'customer_support_agent-v2-improved-prompt', Model ID: 'm-3204036e75134c91bb6e032e782b0b4d'\n\nImproved Response: I'm so sorry to hear that you were charged twice for your subscription last month. I can imagine how frustrating that must be. I'd be happy to help you get this sorted out.\n\nTo assist you further, could you please provide me with your account details, such as your name associated with the account or your order number? This will help me to locate your account and investigate the issue.\n\nOnce I have this information, I'll be able to look into the duplicate charge and process a refund for the extra amount as soon as possible. You can expect a confirmation email from us once the refund has been processed.\n\nIn the meantime, if you have any other questions or concerns, please don't hesitate to ask. I'm here to help.\n\nIf you're ready, you can reply with your account details and I'll get started on resolving this for you.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "\"tr-3ea48c8d557d8a78fbfd3348e086e244\"",
      "text/plain": [
       "Trace(trace_id=tr-3ea48c8d557d8a78fbfd3348e086e244)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a new application version\n",
    "new_version_identifier = \"v2-improved-prompt\"\n",
    "new_logged_model_name = f\"{app_name}-{new_version_identifier}\"\n",
    "\n",
    "# Set the new active model\n",
    "active_model_info_v2 = mlflow.set_active_model(name=new_logged_model_name)\n",
    "print(\n",
    "    f\"Active LoggedModel: '{active_model_info_v2.name}', Model ID: '{active_model_info_v2.model_id}'\"\n",
    ")\n",
    "\n",
    "# Log updated parameters\n",
    "app_params_v2 = {\n",
    "    \"llm\": \"databricks-llama-4-maverick\",\n",
    "    \"temperature\": 0.7,\n",
    "    \"max_tokens\": 500,\n",
    "    \"prompt_version\": \"2\"  # Track which prompt version we're using\n",
    "}\n",
    "mlflow.log_model_params(model_id=active_model_info_v2.model_id, params=app_params_v2)\n",
    "\n",
    "# Load the new prompt version\n",
    "prompt_v2 = mlflow.genai.load_prompt(f\"prompts:/{uc_schema}.{prompt_name}/2\")\n",
    "\n",
    "# Update the app to use the new prompt\n",
    "@mlflow.trace\n",
    "def customer_support_app_v2(company_name: str, topic: str, question: str):\n",
    "    # Format the prompt with variables\n",
    "    formatted_prompt = prompt_v2.format(\n",
    "        company_name=company_name,\n",
    "        topic=topic,\n",
    "        question=question\n",
    "    )\n",
    "\n",
    "    # Call the LLM\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"databricks-llama-4-maverick\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": formatted_prompt,\n",
    "            },\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=500\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Test with the same question to see the difference\n",
    "result_v2 = customer_support_app_v2(\n",
    "    company_name=\"TechCorp\",\n",
    "    topic=\"billing\",\n",
    "    question=\"I was charged twice for my subscription last month. Can you help?\"\n",
    ")\n",
    "print(f\"\\nImproved Response: {result_v2}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "003_prompt_registry",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
