{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cc122c1b-3852-46ca-948c-ef667403622d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# MLflow Prompt Registryを使う\n",
    "\n",
    "https://docs.databricks.com/aws/ja/mlflow3/genai/prompt-version-mgmt/prompt-registry/reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01bbf4ea-8445-4836-ba67-58a1fae9f7df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "> **MLflow Prompt Registry**は、生成AI（GenAI）アプリケーションにおけるプロンプトエンジニアリングと管理を効率化する強力なツールです。組織内でプロンプトをバージョン管理・追跡・再利用できるため、プロンプト開発における一貫性の維持やコラボレーションの向上に役立ちます。\n",
    "> \n",
    "> - **再利用性**：プロンプトを一元管理し、複数のアプリケーションで再利用\n",
    "> - **バージョン管理**：Git風のコミットベースのバージョン管理と、差分比較（diffハイライト）によるプロンプトバージョンの進化の追跡\n",
    "> - **エイリアス**：柔軟なデプロイパイプラインを構築し、プロンプトバージョンをアプリケーション本体から分離。A/Bテストやロールバックも容易\n",
    "> - **系譜（Lineage）**：MLflowの既存機能（モデル追跡や評価）とシームレスに連携し、GenAIライフサイクル全体を管理\n",
    "> - **コラボレーション**：組織全体でプロンプトを共有し、チーム間でのプロンプト開発を促進\n",
    "> \n",
    "> MLflow Prompt RegistryのDatabricks Unity Catalogとの連携は近日公開予定です。\n",
    "> \n",
    "> ---\n",
    "> \n",
    "> ## Unity Catalogとの統合\n",
    "> \n",
    "> Prompt Registryは、Databricks Unity Catalogのガバナンスフレームワークを活用し、以下の機能を提供します。\n",
    "> \n",
    "> - **一元化されたプロンプト管理**：プロンプトテンプレートを統制・検索可能なレジストリで管理\n",
    "> - **バージョン管理**：プロンプトの変更履歴を完全な系譜とロールバック機能で追跡\n",
    "> - **アクセス制御**：Unity Catalogの権限システムを利用し、プロンプトの閲覧・編集・利用を制御\n",
    "> - **コラボレーション**：チーム間でのプロンプト開発の共有と協働を可能に\n",
    "> - **ガバナンス**：分類やコンプライアンス要件を含むデータガバナンスポリシーをプロンプトテンプレートに適用\n",
    "> \n",
    "> ---\n",
    "> \n",
    "> ### 詳細なアクセス制御\n",
    "> \n",
    "> - **個別・チーム・組織単位でのアクセス制御**\n",
    "> - **データの系譜追跡**：プロンプトが異なるアプリケーションや実験でどのように利用されているかを追跡\n",
    "> - **監査証跡**：プロンプトへのアクセスや変更を監視\n",
    "> - **分類とタグ付け**：メタデータでプロンプトを整理し、ガバナンスポリシーを適用\n",
    "> - **ワークスペース間での安全な共有**\n",
    "> \n",
    "> ---\n",
    "> \n",
    "> ## 今後の機能\n",
    "> \n",
    "> 今後、Prompt Registryでは以下の機能がサポートされる予定です。\n",
    "> \n",
    "> - **テンプレート管理**：変数置換機能付きでプロンプトテンプレートを作成・編集・バージョン管理\n",
    "> - **テストと検証**：デプロイ前に評価データセットでプロンプトをテスト\n",
    "> - **A/Bテスト**：異なるプロンプトバージョンを比較し、パフォーマンスを最適化\n",
    "> - **MLflow Trackingとの連携**：プロンプトバージョンと実験・モデル実行を自動的に関連付け\n",
    "> - **APIアクセス**：自動化ワークフローでプロンプトをプログラムから利用\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0795fff5-1f3b-4012-9eaf-ab9235a4d4ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U -q \"mlflow[databricks]>=3.1.0\" databricks-langchain openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d8348542-4c6e-4e44-b7ee-87ff21089b6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Original Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d806c0ab-e4ff-4d42-8e02-63ab84c7f565",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### プロンプトの登録"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c30b34c-ac03-4458-b0b1-1826a5ab501f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Autolog and Register MLflow Chat Prompt"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "catalog = \"workspace\"\n",
    "schema = \"default\"\n",
    "prompt_name = \"sample_prompt\"\n",
    "uc_prompt_name = f\"{catalog}.{schema}.{prompt_name}\"\n",
    "\n",
    "# Register a prompt template\n",
    "prompt = mlflow.genai.register_prompt(\n",
    "    name=uc_prompt_name,\n",
    "    template=\"あなたは親切なアシスタントです。次の問いに答えてください: {{question}}\",\n",
    "    commit_message=\"Initial Commit\"\n",
    ")\n",
    "print(f\"Created version {prompt.version}\")  # \"Created version 1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "165c9661-2497-47f7-b2d6-6a467e517cca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### プロンプトの取得・検索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62d3e42a-5da8-467d-b2c5-6de388a1f312",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prompt = mlflow.genai.load_prompt(name_or_uri=f\"prompts:/{uc_prompt_name}/1\")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cd392d4-f13c-4a46-9def-4474885f8f52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prompts = mlflow.genai.search_prompts(filter_string=f\"catalog='{catalog}' and schema='{schema}'\")\n",
    "prompts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "35844827-d7f8-4d0f-830d-583d8d962d69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### プロンプトの利用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "850bdfc9-667e-4463-811e-964593d63716",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "OpenAIを利用するケース"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from openai import OpenAI\n",
    "\n",
    "# MLflowの自動ロギングを有効にして、アプリケーションにトレースを追加\n",
    "mlflow.openai.autolog()\n",
    "\n",
    "# 実行ノートブックと同じ資格情報を使用してOpenAIクライアント経由でDatabricks LLMに接続\n",
    "mlflow_creds = mlflow.utils.databricks_utils.get_databricks_host_creds()\n",
    "client = OpenAI(\n",
    "    api_key=mlflow_creds.token,\n",
    "    base_url=f\"{mlflow_creds.host}/serving-endpoints\"\n",
    ")\n",
    "\n",
    "# レジストリからプロンプトをロード\n",
    "prompt = mlflow.genai.load_prompt(f\"prompts:/{uc_prompt_name}/1\")\n",
    "formatted_prompt = prompt.format(question=\"Databricksとは何ですか?\")\n",
    "\n",
    "# LLMを呼び出す\n",
    "response = client.chat.completions.create(\n",
    "    model=\"databricks-llama-4-maverick\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": formatted_prompt,\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e13d1d53-f7ea-461c-a1b5-ce29067445c5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "LangChainを利用するケース"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from databricks_langchain import ChatDatabricks\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import codecs\n",
    "\n",
    "# MLflowの自動ロギングを有効化\n",
    "mlflow.langchain.autolog()\n",
    "\n",
    "prompt = mlflow.genai.load_prompt(name_or_uri=f\"prompts:/{uc_prompt_name}/1\")\n",
    "\n",
    "# LangChainのプロンプトテンプレートをMLflowのPromptから作成する\n",
    "langchain_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"user\",\n",
    "            codecs.decode(prompt.to_single_brace_format(), \"unicode-escape\"),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = ChatDatabricks(model=\"databricks-llama-4-maverick\")\n",
    "chain = langchain_prompt | llm\n",
    "\n",
    "# チェーンを実行\n",
    "chain.invoke({\"question\": \"Databricksの特徴を教えてください\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "17fec413-848d-40ff-a1fd-88d5ae329a51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### エイリアスを設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01f2da2d-f1ed-4e1d-8d75-97a547dcb878",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.genai.set_prompt_alias(\n",
    "    name=f\"{uc_prompt_name}\",\n",
    "    alias=\"production\",\n",
    "    version=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c977b12-b294-408c-832c-100ad8af8b38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.genai.load_prompt(f\"prompts:/{uc_prompt_name}@production\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aebb8571-ee22-439d-90b4-8f802fcf4537",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Quick Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82cfd361-045d-4993-b8d1-cba1c2447543",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from databricks_langchain import ChatDatabricks\n",
    "\n",
    "mlflow.langchain.autolog()\n",
    "\n",
    "uc_name = \"workspace.default.customer_support\"\n",
    "\n",
    "# Register a prompt template\n",
    "prompt = mlflow.genai.register_prompt(\n",
    "    name=uc_name,\n",
    "    template=\"あなたは親切なアシスタントです。次の問いに答えてください: {{question}}\",\n",
    "    commit_message=\"初期カスタマーアシスタントプロンプト\"\n",
    ")\n",
    "print(f\"Created version {prompt.version}\")  # \"Created version 1\"\n",
    "\n",
    "# Set a production alias\n",
    "mlflow.genai.set_prompt_alias(\n",
    "    name=uc_name,\n",
    "    alias=\"production\",\n",
    "    version=1\n",
    ")\n",
    "\n",
    "llm = ChatDatabricks(model=\"databricks-llama-4-maverick\")\n",
    "\n",
    "# Load and use the prompt in your application\n",
    "prompt = mlflow.genai.load_prompt(name_or_uri=f\"prompts:/{uc_name}/1\")\n",
    "response = llm.invoke(prompt.format(question=\"How do I reset my password?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0037cfc8-0ded-4559-88ee-1a37cb88a684",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# アプリバージョンとの紐づけ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "916ddb85-b138-4de2-a323-a5b72873e4a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# Replace with a Unity Catalog schema where you have CREATE FUNCTION permission\n",
    "uc_schema = \"workspace.default\"\n",
    "prompt_name = \"customer_support_prompt\"\n",
    "\n",
    "# Define the prompt template with variables\n",
    "initial_template = \"\"\"\\\n",
    "You are a helpful customer support assistant for {{company_name}}.\n",
    "\n",
    "Please help the customer with their inquiry about: {{topic}}\n",
    "\n",
    "Customer Question: {{question}}\n",
    "\n",
    "Provide a friendly, professional response that addresses their concern.\n",
    "\"\"\"\n",
    "\n",
    "# Register a new prompt\n",
    "prompt = mlflow.genai.register_prompt(\n",
    "    name=f\"{uc_schema}.{prompt_name}\",\n",
    "    template=initial_template,\n",
    "    commit_message=\"Initial customer support prompt\",\n",
    "    # version_metadata={\n",
    "    #     \"author\": \"support-team@company.com\",\n",
    "    #     \"use_case\": \"customer_service\"\n",
    "    # },\n",
    "    tags={\n",
    "        \"department\": \"customer_support\",\n",
    "        \"language\": \"en\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Created prompt '{prompt.name}' (version {prompt.version})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "82cfa09f-dde7-4a30-ad5f-c00bdc3901d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.delete_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26170248-55f0-4339-a0ea-c2226da0570a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import subprocess\n",
    "from openai import OpenAI\n",
    "\n",
    "# MLflowの自動ロギングを有効にして、アプリケーションにトレースを追加\n",
    "mlflow.openai.autolog()\n",
    "\n",
    "# 同じ資格情報を使用してOpenAI経由でDatabricks LLMに接続\n",
    "# 代わりに独自のOpenAI資格情報を使用することも可能\n",
    "mlflow_creds = mlflow.utils.databricks_utils.get_databricks_host_creds()\n",
    "client = OpenAI(\n",
    "    api_key=mlflow_creds.token,\n",
    "    base_url=f\"{mlflow_creds.host}/serving-endpoints\"\n",
    ")\n",
    "\n",
    "# アプリケーションとそのバージョン識別子を定義\n",
    "app_name = \"customer_support_agent\"\n",
    "\n",
    "# バージョニングのために現在のgitコミットハッシュを取得\n",
    "try:\n",
    "    git_commit = (\n",
    "        subprocess.check_output([\"git\", \"rev-parse\", \"HEAD\"])\n",
    "        .decode(\"ascii\")\n",
    "        .strip()[:8]\n",
    "    )\n",
    "    version_identifier = f\"git-{git_commit}\"\n",
    "except subprocess.CalledProcessError:\n",
    "    version_identifier = \"local-dev\"  # gitリポジトリにない場合のフォールバック\n",
    "logged_model_name = f\"{app_name}-{version_identifier}\"\n",
    "\n",
    "# アクティブなモデルコンテキストを設定 - これにより、このバージョンのアプリケーションを表すLoggedModelが作成される\n",
    "active_model_info = mlflow.set_active_model(name=logged_model_name)\n",
    "print(\n",
    "    f\"Active LoggedModel: '{active_model_info.name}', Model ID: '{active_model_info.model_id}'\"\n",
    ")\n",
    "\n",
    "# アプリケーションパラメータをログ\n",
    "# これらのパラメータは、このアプリケーションバージョンの構成を追跡するのに役立つ\n",
    "app_params = {\n",
    "    \"llm\": \"databricks-llama-4-maverick\",\n",
    "    \"temperature\": 0.7,\n",
    "    \"max_tokens\": 500\n",
    "}\n",
    "# mlflow.log_model_params(model_id=active_model_info.model_id, params=app_params)\n",
    "\n",
    "# レジストリからプロンプトをロード\n",
    "# 注意: set_active_model()を呼び出した後にプロンプトをロードすることが、プロンプトバージョンとLoggedModelの間の自動系譜追跡を可能にする\n",
    "prompt = mlflow.genai.load_prompt(f\"prompts:/{uc_schema}.{prompt_name}/1\")\n",
    "print(f\"Loaded prompt version {prompt.version}\")\n",
    "\n",
    "# トレースデコレータを使用してアプリケーションのエントリポイントをキャプチャ\n",
    "# この関数によって作成された各トレースは、上記で設定したLoggedModel（アプリケーションバージョン）に自動的にリンクされる。さらに、LoggedModelはレジストリからロードされたプロンプトバージョンにリンクされる\n",
    "@mlflow.trace\n",
    "def customer_support_app(company_name: str, topic: str, question: str):\n",
    "    # 変数でプロンプトをフォーマット\n",
    "    formatted_prompt = prompt.format(\n",
    "        company_name=company_name,\n",
    "        topic=topic,\n",
    "        question=question\n",
    "    )\n",
    "\n",
    "    # LLMを呼び出す\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"databricks-llama-4-maverick\",  # モデルを置き換える\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": formatted_prompt,\n",
    "            },\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=500\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# アプリケーションをテスト\n",
    "result = customer_support_app(\n",
    "    company_name=\"TechCorp\",\n",
    "    topic=\"billing\",\n",
    "    question=\"I was charged twice for my subscription last month. Can you help?\"\n",
    ")\n",
    "print(f\"\\nResponse: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad9b4d46-f2a4-4fa3-95df-ccfae6559130",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create an improved version of the prompt\n",
    "improved_template = \"\"\"\\\n",
    "You are a helpful and empathetic customer support assistant for {{company_name}}.\n",
    "\n",
    "Customer Topic: {{topic}}\n",
    "Customer Question: {{question}}\n",
    "\n",
    "Please provide a response that:\n",
    "1. Acknowledges the customer's concern with empathy\n",
    "2. Provides a clear solution or next steps\n",
    "3. Offers additional assistance if needed\n",
    "4. Maintains a friendly, professional tone\n",
    "\n",
    "Remember to:\n",
    "- Use the customer's name if provided\n",
    "- Be concise but thorough\n",
    "- Avoid technical jargon unless necessary\n",
    "\"\"\"\n",
    "\n",
    "# Register the new version\n",
    "updated_prompt = mlflow.genai.register_prompt(\n",
    "    name=f\"{uc_schema}.{prompt_name}\",\n",
    "    template=improved_template,\n",
    "    commit_message=\"Added structured response guidelines for better customer experience\",\n",
    "    # version_metadata={\n",
    "    #     \"author\": \"support-team@company.com\",\n",
    "    #     \"improvement\": \"Added empathy guidelines and response structure\"\n",
    "    # }\n",
    ")\n",
    "\n",
    "print(f\"Created version {updated_prompt.version} of '{updated_prompt.name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6eae67b-5fe1-4024-a214-4d41deedd494",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a new application version\n",
    "new_version_identifier = \"v2-improved-prompt\"\n",
    "new_logged_model_name = f\"{app_name}-{new_version_identifier}\"\n",
    "\n",
    "# Set the new active model\n",
    "active_model_info_v2 = mlflow.set_active_model(name=new_logged_model_name)\n",
    "print(\n",
    "    f\"Active LoggedModel: '{active_model_info_v2.name}', Model ID: '{active_model_info_v2.model_id}'\"\n",
    ")\n",
    "\n",
    "# Log updated parameters\n",
    "app_params_v2 = {\n",
    "    \"llm\": \"databricks-llama-4-maverick\",\n",
    "    \"temperature\": 0.7,\n",
    "    \"max_tokens\": 500,\n",
    "    \"prompt_version\": \"2\"  # Track which prompt version we're using\n",
    "}\n",
    "mlflow.log_model_params(model_id=active_model_info_v2.model_id, params=app_params_v2)\n",
    "\n",
    "# Load the new prompt version\n",
    "prompt_v2 = mlflow.genai.load_prompt(f\"prompts:/{uc_schema}.{prompt_name}/2\")\n",
    "\n",
    "# Update the app to use the new prompt\n",
    "@mlflow.trace\n",
    "def customer_support_app_v2(company_name: str, topic: str, question: str):\n",
    "    # Format the prompt with variables\n",
    "    formatted_prompt = prompt_v2.format(\n",
    "        company_name=company_name,\n",
    "        topic=topic,\n",
    "        question=question\n",
    "    )\n",
    "\n",
    "    # Call the LLM\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"databricks-llama-4-maverick\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": formatted_prompt,\n",
    "            },\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=500\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Test with the same question to see the difference\n",
    "result_v2 = customer_support_app_v2(\n",
    "    company_name=\"TechCorp\",\n",
    "    topic=\"billing\",\n",
    "    question=\"I was charged twice for my subscription last month. Can you help?\"\n",
    ")\n",
    "print(f\"\\nImproved Response: {result_v2}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "003_prompt_registry",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
