{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bc266db7-3276-4ee2-8ab9-d2719909b5ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# MLflow を使用して Git ベースのアプリケーションのバージョンを追跡する\n",
    "\n",
    "https://docs.databricks.com/aws/ja/mlflow3/genai/prompt-version-mgmt/version-tracking/track-application-versions-with-mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "424c4703-4999-4281-a1af-b25cfa864b29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**LoggedModel** は、Experiment 内で AI モデル、エージェント、または GenAI アプリケーションを表すファーストクラスのエンティティです。開発ライフサイクル全体を通じて、モデルアーティファクト、実行トレース、評価指標、メタデータの統合トラッキングを提供します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "722d0bfb-65e5-4437-8ef6-298ce3cc657d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## LoggedModel の主な機能\n",
    "LoggedModel は次のものを接続する中心的なハブとして機能します:\n",
    "\n",
    "- **モデルアーティファクト** と構成パラメータ\n",
    "- 開発および本番環境からの **実行トレース**\n",
    "- **評価指標** とパフォーマンス評価\n",
    "- **バージョン履歴** とデプロイ追跡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8026fb07-e8fc-4cae-beb3-5f7eee883a6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## LoggedModel の利点\n",
    "**統合トラッキング:** すべてのモデル関連アーティファクト、トレース、メトリクスが単一のエンティティの下に整理され、モデルの挙動とパフォーマンスを完全に可視化できます。\n",
    "\n",
    "**自動トレースリンク:** アクティブモデルパターンを使用すると、すべての実行トレースが自動的に LoggedModel に関連付けられ、手動での追跡作業が不要になります。\n",
    "\n",
    "**バージョン管理:** LoggedModel は、異なるモデル反復間での体系的なバージョン管理と比較をサポートし、データ駆動型のモデル選択を可能にします。\n",
    "\n",
    "**評価統合:** 評価指標や結果が直接 LoggedModel にリンクされ、包括的なパフォーマンス評価が可能です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64e66503-f050-47ca-80f9-b19c619d3128",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade \"mlflow[databricks]>=3.1.0\" openai\n",
    "\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e975856c-f6b6-446f-9e9d-91ba6632cc0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from openai import OpenAI\n",
    "\n",
    "# MLflowの自動ロギングを有効にして、アプリケーションにトレースを追加\n",
    "mlflow.openai.autolog()\n",
    "\n",
    "# トレースデコレータを使用してアプリケーションのエントリポイントをキャプチャ\n",
    "@mlflow.trace\n",
    "def my_app(model_input: str):\n",
    "    # Notebook実行の資格情報を利用してDatabricks Foundation Model APIへのCredentialを取得\n",
    "    mlflow_creds = mlflow.utils.databricks_utils.get_databricks_host_creds()\n",
    "    client = OpenAI(\n",
    "        api_key=mlflow_creds.token, base_url=f\"{mlflow_creds.host}/serving-endpoints\"\n",
    "    )\n",
    "\n",
    "    # この呼び出しは`mlflow.openai.autolog()`によって自動的に計測されます\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"databricks-meta-llama-3-3-70b-instruct\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"あなたは役に立つアシスタントです。\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": model_input,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# テスト実行\n",
    "result = my_app(model_input=\"MLflowとは何ですか？\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d40edcc-20f1-4c8e-bbcb-93e0cdadb7a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_info = mlflow.pyfunc.log_model(\n",
    "    name=\"my_app\",\n",
    "    python_model=my_app,\n",
    "    pip_requirements=[\"openai\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7193e49f-e53b-4b9e-9534-645b71e43e8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model = mlflow.pyfunc.load_model(model_info.model_uri)\n",
    "prediction = model.predict(\"MLflowとは何ですか？\")\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8cd5e6ac-e510-4a6d-ba72-8778c9b555fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## バージョン管理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c3b8d8b-3253-472d-b2ce-cc8cf18c1594",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from openai import OpenAI\n",
    "\n",
    "mlflow.openai.autolog()\n",
    "\n",
    "@mlflow.trace\n",
    "def my_app_revised(model_input: str):\n",
    "    # Notebook実行の資格情報を利用してDatabricks Foundation Model APIへのCredentialを取得\n",
    "    mlflow_creds = mlflow.utils.databricks_utils.get_databricks_host_creds()\n",
    "    client = OpenAI(\n",
    "        api_key=mlflow_creds.token, base_url=f\"{mlflow_creds.host}/serving-endpoints\"\n",
    "    )\n",
    "\n",
    "    # 利用するモデルをLlama3.3 70BからLlama4 に変更する\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"databricks-llama-4-maverick\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"あなたは役に立つアシスタントです。\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": model_input,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# テスト実行\n",
    "result = my_app_revised(model_input=\"MLflowとは何ですか？\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a85aa876-60f2-4244-8a51-cf18e2e19d31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "active_model_info = mlflow.set_active_model(name=\"my_app_dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2cfc376b-13ed-42f5-98e9-154097f1307b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# テスト実行２\n",
    "my_app_revised(model_input=\"MLflowとは何ですか？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f41055b7-3a2a-4378-a8b0-dad4e7a63bb7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 新たなバージョンのモデルも併せて作成・設定\n",
    "active_model_info = mlflow.set_active_model(name=\"my_app_dev2\")\n",
    "\n",
    "@mlflow.trace\n",
    "def my_app_revise_ver2(model_input: str):\n",
    "    mlflow_creds = mlflow.utils.databricks_utils.get_databricks_host_creds()\n",
    "    client = OpenAI(\n",
    "        api_key=mlflow_creds.token, base_url=f\"{mlflow_creds.host}/serving-endpoints\"\n",
    "    )\n",
    "\n",
    "    # システムプロンプトを変更\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"databricks-llama-4-maverick\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"あなたは役に立つアシスタントです。関西弁で面白おかしく回答してください。\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": model_input,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# テスト実行\n",
    "result = my_app_revise_ver2(model_input=\"MLflowとは何ですか？\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63315141-643d-4b4f-a74d-f294c515f2fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Keep original imports\n",
    "### NEW CODE\n",
    "import subprocess\n",
    "\n",
    "# Define your application and its version identifier\n",
    "app_name = \"customer_support_agent\"\n",
    "\n",
    "# Get current git commit hash for versioning\n",
    "try:\n",
    "    git_commit = (\n",
    "        subprocess.check_output([\"git\", \"rev-parse\", \"HEAD\"])\n",
    "        .decode(\"ascii\")\n",
    "        .strip()[:8]\n",
    "    )\n",
    "    version_identifier = f\"git-{git_commit}\"\n",
    "except subprocess.CalledProcessError:\n",
    "    version_identifier = \"local-dev\"  # Fallback if not in a git repo\n",
    "logged_model_name = f\"{app_name}-{version_identifier}\"\n",
    "\n",
    "# Set the active model context\n",
    "active_model_info = mlflow.set_active_model(name=logged_model_name)\n",
    "print(\n",
    "    f\"Active LoggedModel: '{active_model_info.name}', Model ID: '{active_model_info.model_id}'\"\n",
    ")\n",
    "\n",
    "### END NEW CODE\n",
    "\n",
    "### ORIGINAL CODE BELOW\n",
    "### ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3bac024e-3457-420a-92c8-39a9c002fc48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "app_params = {\n",
    "    \"llm\": \"gpt-4o-mini\",\n",
    "    \"temperature\": 0.7,\n",
    "    \"retrieval_strategy\": \"vector_search_v3\",\n",
    "}\n",
    "\n",
    "# Log params\n",
    "mlflow.log_model_params(model_id=active_model_info.model_id, params=app_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bb05a37-88c1-46ac-95b6-4c0f230c246d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# These 2 invocations will be linked to the same LoggedModel\n",
    "result = my_app(input=\"What is MLflow?\")\n",
    "print(result)\n",
    "\n",
    "result = my_app(input=\"What is Databricks?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd94fb08-b341-44ed-bd98-ad7f3e4a4b47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Set the active model context\n",
    "active_model_info = mlflow.set_active_model(name=\"new-name-set-manually\")\n",
    "print(\n",
    "    f\"Active LoggedModel: '{active_model_info.name}', Model ID: '{active_model_info.model_id}'\"\n",
    ")\n",
    "\n",
    "app_params = {\n",
    "    \"llm\": \"gpt-4o\",\n",
    "    \"temperature\": 0.7,\n",
    "    \"retrieval_strategy\": \"vector_search_v4\",\n",
    "}\n",
    "\n",
    "# Log params\n",
    "mlflow.log_model_params(model_id=active_model_info.model_id, params=app_params)\n",
    "\n",
    "# This will create a new LoggedModel\n",
    "result = my_app(input=\"What is GenAI?\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "006_versions",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
