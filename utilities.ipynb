{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40875ee7-5a64-45a3-a480-4146f836749b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: markitdown in /local_disk0/.ephemeral_nfs/envs/pythonEnv-356d659b-131a-48e9-95ca-ed07b87cbb43/lib/python3.12/site-packages (0.1.2)\nRequirement already satisfied: pandas in /local_disk0/.ephemeral_nfs/envs/pythonEnv-356d659b-131a-48e9-95ca-ed07b87cbb43/lib/python3.12/site-packages (2.3.0)\nRequirement already satisfied: beautifulsoup4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-356d659b-131a-48e9-95ca-ed07b87cbb43/lib/python3.12/site-packages (from markitdown) (4.13.4)\nRequirement already satisfied: charset-normalizer in /databricks/python3/lib/python3.12/site-packages (from markitdown) (2.0.4)\nRequirement already satisfied: defusedxml in /local_disk0/.ephemeral_nfs/envs/pythonEnv-356d659b-131a-48e9-95ca-ed07b87cbb43/lib/python3.12/site-packages (from markitdown) (0.7.1)\nRequirement already satisfied: magika~=0.6.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-356d659b-131a-48e9-95ca-ed07b87cbb43/lib/python3.12/site-packages (from markitdown) (0.6.2)\nRequirement already satisfied: markdownify in /local_disk0/.ephemeral_nfs/envs/pythonEnv-356d659b-131a-48e9-95ca-ed07b87cbb43/lib/python3.12/site-packages (from markitdown) (1.1.0)\nRequirement already satisfied: requests in /databricks/python3/lib/python3.12/site-packages (from markitdown) (2.32.2)\nRequirement already satisfied: numpy>=1.26.0 in /databricks/python3/lib/python3.12/site-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /databricks/python3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.12/site-packages (from pandas) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /databricks/python3/lib/python3.12/site-packages (from pandas) (2024.1)\nRequirement already satisfied: click>=8.1.7 in /databricks/python3/lib/python3.12/site-packages (from magika~=0.6.1->markitdown) (8.1.7)\nRequirement already satisfied: onnxruntime>=1.17.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-356d659b-131a-48e9-95ca-ed07b87cbb43/lib/python3.12/site-packages (from magika~=0.6.1->markitdown) (1.22.0)\nRequirement already satisfied: python-dotenv>=1.0.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-356d659b-131a-48e9-95ca-ed07b87cbb43/lib/python3.12/site-packages (from magika~=0.6.1->markitdown) (1.1.1)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\nRequirement already satisfied: soupsieve>1.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-356d659b-131a-48e9-95ca-ed07b87cbb43/lib/python3.12/site-packages (from beautifulsoup4->markitdown) (2.7)\nRequirement already satisfied: typing-extensions>=4.0.0 in /databricks/python3/lib/python3.12/site-packages (from beautifulsoup4->markitdown) (4.11.0)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.12/site-packages (from requests->markitdown) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.12/site-packages (from requests->markitdown) (2.2.2)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.12/site-packages (from requests->markitdown) (2024.6.2)\nRequirement already satisfied: coloredlogs in /local_disk0/.ephemeral_nfs/envs/pythonEnv-356d659b-131a-48e9-95ca-ed07b87cbb43/lib/python3.12/site-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown) (15.0.1)\nRequirement already satisfied: flatbuffers in /local_disk0/.ephemeral_nfs/envs/pythonEnv-356d659b-131a-48e9-95ca-ed07b87cbb43/lib/python3.12/site-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown) (25.2.10)\nRequirement already satisfied: packaging in /databricks/python3/lib/python3.12/site-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown) (24.1)\nRequirement already satisfied: protobuf in /databricks/python3/lib/python3.12/site-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown) (5.29.4)\nRequirement already satisfied: sympy in /local_disk0/.ephemeral_nfs/envs/pythonEnv-356d659b-131a-48e9-95ca-ed07b87cbb43/lib/python3.12/site-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown) (1.14.0)\nRequirement already satisfied: humanfriendly>=9.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-356d659b-131a-48e9-95ca-ed07b87cbb43/lib/python3.12/site-packages (from coloredlogs->onnxruntime>=1.17.0->magika~=0.6.1->markitdown) (10.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-356d659b-131a-48e9-95ca-ed07b87cbb43/lib/python3.12/site-packages (from sympy->onnxruntime>=1.17.0->magika~=0.6.1->markitdown) (1.3.0)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install -U markitdown pandas\n",
    "\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7650beac-2657-4693-a6da-9b11c98f1ca3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sitemap](/sitemap/sitemap.xml)\n\n[Open in app](https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F72d14a94e562&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderUser&%7Estage=mobileNavBar&source=post_page---top_nav_layout_nav-----------------------------------------)\n\nSign up\n\n[Sign in](/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2F%40codehimanshu24%2Frevolutionizing-etl-an-agentic-medallion-data-pipeline-on-databricks-72d14a94e562&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\n\n[Medium Logo](/?source=post_page---top_nav_layout_nav-----------------------------------------)\n\n[Write](/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---top_nav_layout_nav-----------------------new_post_topnav------------------)\n\nSign up\n\n[Sign in](/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2F%40codehimanshu24%2Frevolutionizing-etl-an-agentic-medallion-data-pipeline-on-databricks-72d14a94e562&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\n\n![](https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png)\n\n# Revolutionizing ETL: An Agentic Medallion Data Pipeline on Databricks\n\n[![Codehimanshu](https://miro.medium.com/v2/da:true/resize:fill:64:64/0*v4f8xi3HM8ndVBUA)](/%40codehimanshu24?source=post_page---byline--72d14a94e562---------------------------------------)\n\n[Codehimanshu](/%40codehimanshu24?source=post_page---byline--72d14a94e562---------------------------------------)\n\n4 min read\n\n¬∑\n\nJust now\n\n--\n\nListen\n\nShare\n\n![]()\n\nabstract logo\n\nImagine a world where your entire data transformation pipeline from raw ingestion to analytics-ready dashboards runs itself, heals itself, and learns from each run. That‚Äôs not science fiction. It‚Äôs the Agentic Medallion Data Pipeline, a project I built during my Accenture internship, fusing Databricks‚Äô Medallion Architecture with the latest in agentic AI. In this article, I‚Äôll take you inside this groundbreaking system, show you the architecture, workflow, and code, and explain why it‚Äôs a true paradigm shift for enterprise data engineering.\n\n# üöÄ Why This Project Is Revolutionary\n\nTraditional ETL pipelines are labor-intensive, error-prone, and slow to adapt. This project changes the game by introducing:\n\n* **Fully Autonomous ETL**: AI agents plan, generate, review, and execute all transformations no human in the loop.\n* **Self-Healing Workflows**: Agents detect errors, revise code, and retry automatically.\n* **Zero-Touch Medallion Processing**: Data flows seamlessly from Bronze (raw) to Silver (cleaned) to Gold (analytics-ready) layers.\n* **Enterprise-Grade Observability**: Every step is traced and monitored with LangSmith.\n* **Scalability**: Built on Databricks‚Äô serverless Mosaic AI platform for real-world workloads\n\n# üìñ The Genesis: From Accenture to Autonomous AI\n\nDuring my time at Accenture, I witnessed the complexity of data transformations for Fortune 500 clients. Manual ETL processes were slow, repetitive, and prone to human error. Discovering the Medallion Architecture ‚Äî an industry-standard pattern that organizes data into Bronze, Silver, and Gold layers ‚Äî sparked an idea: What if AI agents could automate this entire workflow?\n\nCombining my hands-on experience with cutting-edge AI frameworks (LangChain, LangGraph, Claude 3.7 Sonnet), I set out to build the a agentic Medallion pipeline, leveraging Databricks‚Äô 14-day free trial and $400 in credits\n\n# üèóÔ∏è Architecture Deep Dive\n\n![]()\n\nArchitecture Deep Dive\n\n## **1. Medallion Data Transformation Pipeline**\n\n* **Bronze Layer**: Ingests raw, unprocessed data, preserving lineage and audit trails.\n* **Silver Layer**: Applies data quality rules, deduplication, and validation to create trusted datasets.\n* **Gold Layer**: Aggregates and enriches data for analytics, reporting, and machine learning\n\n**Agentic Workflow Loop:**\n\nAI agents orchestrate each transformation step, leveraging **LangChain** and **LangGraph** for planning, code generation, review, and execution. **LangSmith** provides full observability and debugging.\n\n# 2. Medallion Architecture Data Flow\n\n![]()\n\nMedallion Workflow\n\n![]()\n\nBronze ‚Üí Silver ‚Üí Gold flow\n\n* Silver: Cleaned tables (`customers_cleaned`, `transactions_cleaned`, etc.)\n* Gold: Aggregated business tables (`customer_spending`, `account_performance`, etc.)\n\nEach layer progressively refines data quality, structure, and business value\n\n# 3. Agentic Workflow: Self-Healing Data Engineering\n\n![]()\n\nagent orchestration and workflow\n\n* **Planner Agent**: Designs transformation strategies based on user/business input.\n* **Code Generator Agent**: Writes production-ready PySpark code.\n* **Code Reviewer Agent:** Performs QA, suggests fixes, or approves code.\n* **Executor Agent**: Runs code, handles errors, and triggers retries if needed.\n\nThis loop continues until transformations are correct and successful ‚Äî *no manual intervention required*\n\n# üõ†Ô∏è Technical Implementation\n\n# Core Stack\n\n* **Databricks Serverless**: Mosaic AI Agent Framework for scalable compute.\n* **Apache Spark**: Distributed processing engine.\n* **Delta Lake**: ACID-compliant storage and time travel.\n* **LangChain & LangGraph**: Agent orchestration and workflow management.\n* **Claude 3.7 Sonnet**: Advanced LLM for reasoning and code generation.\n* **LangSmith**: End-to-end observability and debugging\n\n# Key Features\n\n* **Intelligent Data Profiling**: AI tools analyze schema, stats, and data samples.\n* **Safe Code Execution**: All PySpark code runs in a secure, validated environment.\n* **Automated Visualization**: Dashboards are generated for business insights.\n* **Observability**: Every agent action and transformation is traced for transparency.\n\n# ‚ö° Traditional ETL vs. Agentic Pipeline\n\n![]()\n\nDifference between Traditional ETL and Agentic ETL\n\n# üèÜ Why This Approach Matters\n\n* **Productivity Gains**: Up to 90% reduction in development time.\n* **Quality Improvements**: Consistent, production-grade code and robust error handling.\n* **Cost Optimization**: Serverless, auto-scaling, and reduced manual effort.\n* **Adaptability**: Self-modifies based on data patterns and schema changes\n\n# üîÆ What‚Äôs Next? Future Enhancements\n\n* **Advanced AI**: Multi-modal data support, predictive transformation recommendations.\n* **Enterprise Integration**: REST APIs, real-time streaming, multi-cloud deployment.\n* **Enhanced Analytics**: Automated ML training, anomaly detection, and more.\n\n# üôè Acknowledgements\n\nSpecial thanks to[**Krish Naik**](https://www.youtube.com/%40krishnaik06)for his outstanding tutorials on LangChain, LangGraph, and agentic AI that really helped in making this whole pipeline.\n\n# üì¶ Get Started\n\n* **Repo**: [github.com/HimanshuMohanty-Git24/Agentic-Medallion](https://github.com/HimanshuMohanty-Git24/Agentic-Medallion)\n* **Requirements**: Databricks (trial or pro), LangSmith account, basic PySpark knowledge.\n* **Setup**: Clone the repo, configure your environment, and run the notebook.\n\nThis project isn‚Äôt just about automating ETL it‚Äôs about reimagining what‚Äôs possible when AI and data engineering converge. If you‚Äôre passionate about the future of data, check out the [repo](https://github.com/HimanshuMohanty-Git24/Agentic-Medallion), try it yourself, and join the revolution!\n\n[Data Engineering](/tag/data-engineering?source=post_page-----72d14a94e562---------------------------------------)\n\n[Artificial Intelligence](/tag/artificial-intelligence?source=post_page-----72d14a94e562---------------------------------------)\n\n[Databricks](/tag/databricks?source=post_page-----72d14a94e562---------------------------------------)\n\n[Agentic Ai](/tag/agentic-ai?source=post_page-----72d14a94e562---------------------------------------)\n\n[Automation](/tag/automation?source=post_page-----72d14a94e562---------------------------------------)\n\n--\n\n--\n\n[![Codehimanshu](https://miro.medium.com/v2/resize:fill:96:96/0*v4f8xi3HM8ndVBUA)](/%40codehimanshu24?source=post_page---post_author_info--72d14a94e562---------------------------------------)\n\n[![Codehimanshu](https://miro.medium.com/v2/resize:fill:128:128/0*v4f8xi3HM8ndVBUA)](/%40codehimanshu24?source=post_page---post_author_info--72d14a94e562---------------------------------------)\n\n[## Written by Codehimanshu](/%40codehimanshu24?source=post_page---post_author_info--72d14a94e562---------------------------------------)\n\n[1 follower](/%40codehimanshu24/followers?source=post_page---post_author_info--72d14a94e562---------------------------------------)\n\n¬∑[1 following](/%40codehimanshu24/following?source=post_page---post_author_info--72d14a94e562---------------------------------------)\n\nüëã Hello! I'm Himanshu Mohanty, a passionate developer and problem solver, dedicated to creating impactful solutions through code. üöÄ\n\n## No responses yet\n\n[Help](https://help.medium.com/hc/en-us?source=post_page-----72d14a94e562---------------------------------------)\n\n[Status](https://medium.statuspage.io/?source=post_page-----72d14a94e562---------------------------------------)\n\n[About](/about?autoplay=1&source=post_page-----72d14a94e562---------------------------------------)\n\n[Careers](/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----72d14a94e562---------------------------------------)\n\nPress\n\n[Blog](https://blog.medium.com/?source=post_page-----72d14a94e562---------------------------------------)\n\n[Privacy](https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----72d14a94e562---------------------------------------)\n\n[Rules](https://policy.medium.com/medium-rules-30e5502c4eb4?source=post_page-----72d14a94e562---------------------------------------)\n\n[Terms](https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----72d14a94e562---------------------------------------)\n\n[Text to speech](https://speechify.com/medium?source=post_page-----72d14a94e562---------------------------------------)\n"
     ]
    }
   ],
   "source": [
    "from markitdown import MarkItDown\n",
    "\n",
    "# url = \"https://mlflow.org/docs/latest/genai/data-model/logged-model\"\n",
    "# url = \"https://docs.databricks.com/aws/ja/mlflow3/genai/eval-monitor/evaluate-app\"\n",
    "# url = \"https://docs.databricks.com/aws/ja/mlflow3/genai/eval-monitor/run-scorer-in-prod\"\n",
    "url = \"https://medium.com/@codehimanshu24/revolutionizing-etl-an-agentic-medallion-data-pipeline-on-databricks-72d14a94e562\"\n",
    "\n",
    "md = MarkItDown(enable_plugins=False) # Set to True to enable plugins\n",
    "result = md.convert(url)\n",
    "print(result.text_content)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "utilities",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
