{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "beecd6bf-71f4-4179-a6ea-ac65d198106a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# MLflow プロンプト最適化\n",
    "\n",
    "https://docs.databricks.com/aws/ja/mlflow3/genai/prompt-version-mgmt/prompt-registry/automatically-optimize-prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5bf08dab-81da-4414-bcfa-bca149b32ff3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> # プロンプト最適化（実験的機能）\n",
    "> MLflowでは、```mlflow.genai.optimize_prompt()```APIを使用したMLflowの統合インターフェースを通じて、プロンプトを高度なプロンプト最適化手法に組み込むことができます。この機能は、評価指標とラベル付きデータを活用して、プロンプトを自動的に改善するのに役立ちます。現在、このAPIはDSPyのMIPROv2アルゴリズムをサポートしています。\n",
    "> \n",
    "> ## 主なメリット\n",
    "> - **統合インターフェース:** 中立的なインターフェースを介して最先端のプロンプト最適化アルゴリズムにアクセスできます。\n",
    "> - **プロンプト管理:** MLflow プロンプト レジストリと統合して、再利用性、バージョン管理、系統を実現します。\n",
    "> - **評価:** MLflow の評価機能を使用してプロンプトのパフォーマンスを総合的に評価します。\n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d117d829-cbe0-4568-9520-fe46e74292e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 簡易チュートリアル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c573fc5c-7574-48e7-b190-8f45019e4088",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlflow>=3.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from mlflow[databricks]>=3.1.0) (3.1.0)\nCollecting databricks-langchain\n  Downloading databricks_langchain-0.5.1-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: langgraph in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (0.4.8)\nRequirement already satisfied: dspy in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (2.6.27)\nRequirement already satisfied: databricks-agents in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (1.1.0)\nRequirement already satisfied: mlflow-skinny==3.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (3.1.0)\nRequirement already satisfied: Flask<4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (3.1.1)\nRequirement already satisfied: alembic!=1.10.0,<2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (1.16.2)\nRequirement already satisfied: docker<8,>=4.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (7.1.0)\nRequirement already satisfied: graphene<4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (3.4.3)\nRequirement already satisfied: gunicorn<24 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (23.0.0)\nRequirement already satisfied: matplotlib<4 in /databricks/python3/lib/python3.11/site-packages (from mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (3.7.2)\nRequirement already satisfied: numpy<3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (1.26.4)\nRequirement already satisfied: pandas<3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (2.3.0)\nRequirement already satisfied: pyarrow<21,>=4.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (20.0.0)\nRequirement already satisfied: scikit-learn<2 in /databricks/python3/lib/python3.11/site-packages (from mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (1.3.0)\nRequirement already satisfied: scipy<2 in /databricks/python3/lib/python3.11/site-packages (from mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (1.11.1)\nRequirement already satisfied: sqlalchemy<3,>=1.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (2.0.41)\nRequirement already satisfied: cachetools<7,>=5.0.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (5.5.0)\nRequirement already satisfied: click<9,>=7.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (8.2.1)\nRequirement already satisfied: cloudpickle<4 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (3.0.0)\nRequirement already satisfied: databricks-sdk<1,>=0.20.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (0.55.0)\nRequirement already satisfied: fastapi<1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (0.115.13)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (3.1.43)\nRequirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (8.7.0)\nRequirement already satisfied: opentelemetry-api<3,>=1.9.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (1.34.1)\nRequirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (1.34.1)\nRequirement already satisfied: packaging<26 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (23.2)\nRequirement already satisfied: protobuf<7,>=3.12.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (4.25.8)\nRequirement already satisfied: pydantic<3,>=1.10.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (2.11.7)\nRequirement already satisfied: pyyaml<7,>=5.1 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (6.0)\nRequirement already satisfied: requests<3,>=2.17.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (2.32.4)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (0.5.1)\nRequirement already satisfied: typing-extensions<5,>=4.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (4.14.0)\nRequirement already satisfied: uvicorn<1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (0.34.3)\nCollecting databricks-ai-bridge>=0.4.2 (from databricks-langchain)\n  Downloading databricks_ai_bridge-0.5.1-py3-none-any.whl.metadata (6.2 kB)\nCollecting databricks-connect>=16.1.1 (from databricks-langchain)\n  Downloading databricks_connect-16.1.6-py2.py3-none-any.whl.metadata (2.6 kB)\nCollecting databricks-vectorsearch>=0.50 (from databricks-langchain)\n  Downloading databricks_vectorsearch-0.56-py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: langchain>=0.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from databricks-langchain) (0.3.26)\nCollecting unitycatalog-langchain>=0.2.0 (from unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain)\n  Downloading unitycatalog_langchain-0.2.0-py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: langchain-core>=0.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from langgraph) (0.3.66)\nRequirement already satisfied: langgraph-checkpoint>=2.0.26 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from langgraph) (2.1.0)\nRequirement already satisfied: langgraph-prebuilt>=0.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from langgraph) (0.2.2)\nRequirement already satisfied: langgraph-sdk>=0.1.42 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from langgraph) (0.1.70)\nRequirement already satisfied: xxhash>=3.5.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from langgraph) (3.5.0)\nRequirement already satisfied: backoff>=2.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from dspy) (2.2.1)\nRequirement already satisfied: joblib~=1.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from dspy) (1.5.1)\nRequirement already satisfied: openai>=0.28.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from dspy) (1.90.0)\nRequirement already satisfied: regex>=2023.10.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from dspy) (2024.11.6)\nRequirement already satisfied: ujson>=5.8.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from dspy) (5.10.0)\nRequirement already satisfied: tqdm>=4.66.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from dspy) (4.67.1)\nRequirement already satisfied: datasets>=2.14.6 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from dspy) (3.6.0)\nRequirement already satisfied: optuna>=3.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from dspy) (4.4.0)\nRequirement already satisfied: magicattr>=0.1.6 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from dspy) (0.1.6)\nRequirement already satisfied: litellm>=1.60.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from dspy) (1.72.9)\nRequirement already satisfied: diskcache>=5.6.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from dspy) (5.6.3)\nRequirement already satisfied: json-repair>=0.30.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from dspy) (0.47.1)\nRequirement already satisfied: tenacity>=8.2.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from dspy) (9.1.2)\nRequirement already satisfied: anyio in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from dspy) (4.9.0)\nRequirement already satisfied: asyncer==0.0.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from dspy) (0.0.8)\nRequirement already satisfied: rich>=13.7.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from dspy) (14.0.0)\nRequirement already satisfied: dataclasses-json in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from databricks-agents) (0.6.7)\nRequirement already satisfied: jinja2>=3.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from databricks-agents) (3.1.6)\nRequirement already satisfied: tiktoken>=0.8.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from databricks-agents) (0.9.0)\nRequirement already satisfied: urllib3>=2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from databricks-agents) (2.0.7)\nRequirement already satisfied: azure-storage-file-datalake>12 in /databricks/python3/lib/python3.11/site-packages (from mlflow[databricks]>=3.1.0) (12.14.0)\nRequirement already satisfied: google-cloud-storage>=1.30.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow[databricks]>=3.1.0) (2.18.2)\nRequirement already satisfied: boto3>1 in /databricks/python3/lib/python3.11/site-packages (from mlflow[databricks]>=3.1.0) (1.34.39)\nRequirement already satisfied: botocore in /databricks/python3/lib/python3.11/site-packages (from mlflow[databricks]>=3.1.0) (1.34.39)\nRequirement already satisfied: Mako in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from alembic!=1.10.0,<2->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (1.3.10)\nRequirement already satisfied: idna>=2.8 in /databricks/python3/lib/python3.11/site-packages (from anyio->dspy) (3.4)\nRequirement already satisfied: sniffio>=1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from anyio->dspy) (1.3.1)\nRequirement already satisfied: azure-core<2.0.0,>=1.28.0 in /databricks/python3/lib/python3.11/site-packages (from azure-storage-file-datalake>12->mlflow[databricks]>=3.1.0) (1.32.0)\nRequirement already satisfied: azure-storage-blob<13.0.0,>=12.19.0 in /databricks/python3/lib/python3.11/site-packages (from azure-storage-file-datalake>12->mlflow[databricks]>=3.1.0) (12.19.1)\nRequirement already satisfied: isodate>=0.6.1 in /databricks/python3/lib/python3.11/site-packages (from azure-storage-file-datalake>12->mlflow[databricks]>=3.1.0) (0.7.2)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /databricks/python3/lib/python3.11/site-packages (from boto3>1->mlflow[databricks]>=3.1.0) (0.10.0)\nRequirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /databricks/python3/lib/python3.11/site-packages (from boto3>1->mlflow[databricks]>=3.1.0) (0.10.3)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /databricks/python3/lib/python3.11/site-packages (from botocore->mlflow[databricks]>=3.1.0) (2.8.2)\nCollecting tabulate>=0.9.0 (from databricks-ai-bridge>=0.4.2->databricks-langchain)\n  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\nRequirement already satisfied: googleapis-common-protos>=1.56.4 in /databricks/python3/lib/python3.11/site-packages (from databricks-connect>=16.1.1->databricks-langchain) (1.65.0)\nRequirement already satisfied: grpcio-status>=1.59.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from databricks-connect>=16.1.1->databricks-langchain) (1.62.3)\nRequirement already satisfied: grpcio>=1.59.3 in /databricks/python3/lib/python3.11/site-packages (from databricks-connect>=16.1.1->databricks-langchain) (1.69.0)\nRequirement already satisfied: py4j==0.10.9.7 in /databricks/python3/lib/python3.11/site-packages (from databricks-connect>=16.1.1->databricks-langchain) (0.10.9.7)\nRequirement already satisfied: setuptools>=68.0.0 in /databricks/python3/lib/python3.11/site-packages (from databricks-connect>=16.1.1->databricks-langchain) (75.1.0)\nRequirement already satisfied: six in /usr/lib/python3/dist-packages (from databricks-connect>=16.1.1->databricks-langchain) (1.16.0)\nRequirement already satisfied: google-auth~=2.0 in /databricks/python3/lib/python3.11/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (2.35.0)\nCollecting deprecation>=2 (from databricks-vectorsearch>=0.50->databricks-langchain)\n  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\nRequirement already satisfied: filelock in /databricks/python3/lib/python3.11/site-packages (from datasets>=2.14.6->dspy) (3.13.4)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from datasets>=2.14.6->dspy) (0.3.8)\nRequirement already satisfied: multiprocess<0.70.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from datasets>=2.14.6->dspy) (0.70.16)\nRequirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.6->dspy) (2025.3.0)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from datasets>=2.14.6->dspy) (0.33.0)\nRequirement already satisfied: blinker>=1.9.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from Flask<4->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (1.9.0)\nRequirement already satisfied: itsdangerous>=2.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from Flask<4->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (2.2.0)\nRequirement already satisfied: markupsafe>=2.1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from Flask<4->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (3.0.2)\nRequirement already satisfied: werkzeug>=3.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from Flask<4->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (3.1.3)\nRequirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /databricks/python3/lib/python3.11/site-packages (from google-cloud-storage>=1.30.0->mlflow[databricks]>=3.1.0) (2.18.0)\nRequirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /databricks/python3/lib/python3.11/site-packages (from google-cloud-storage>=1.30.0->mlflow[databricks]>=3.1.0) (2.4.1)\nRequirement already satisfied: google-resumable-media>=2.7.2 in /databricks/python3/lib/python3.11/site-packages (from google-cloud-storage>=1.30.0->mlflow[databricks]>=3.1.0) (2.7.2)\nRequirement already satisfied: google-crc32c<2.0dev,>=1.0 in /databricks/python3/lib/python3.11/site-packages (from google-cloud-storage>=1.30.0->mlflow[databricks]>=3.1.0) (1.6.0)\nRequirement already satisfied: graphql-core<3.3,>=3.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from graphene<4->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (3.2.6)\nRequirement already satisfied: graphql-relay<3.3,>=3.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from graphene<4->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (3.2.0)\nRequirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from langchain>=0.3.0->databricks-langchain) (0.3.8)\nRequirement already satisfied: langsmith>=0.1.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from langchain>=0.3.0->databricks-langchain) (0.4.1)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from langchain-core>=0.1->langgraph) (1.33)\nRequirement already satisfied: ormsgpack>=1.10.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from langgraph-checkpoint>=2.0.26->langgraph) (1.10.0)\nRequirement already satisfied: httpx>=0.25.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from langgraph-sdk>=0.1.42->langgraph) (0.28.1)\nRequirement already satisfied: orjson>=3.10.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from langgraph-sdk>=0.1.42->langgraph) (3.10.18)\nRequirement already satisfied: aiohttp>=3.10 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from litellm>=1.60.3->dspy) (3.12.13)\nRequirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from litellm>=1.60.3->dspy) (4.24.0)\nRequirement already satisfied: python-dotenv>=0.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from litellm>=1.60.3->dspy) (1.1.0)\nRequirement already satisfied: tokenizers in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from litellm>=1.60.3->dspy) (0.21.1)\nRequirement already satisfied: contourpy>=1.0.1 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (1.0.5)\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (4.25.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (1.4.4)\nRequirement already satisfied: pillow>=6.2.0 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (10.3.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (3.0.9)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=0.28.1->dspy) (1.7.0)\nRequirement already satisfied: jiter<1,>=0.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from openai>=0.28.1->dspy) (0.10.0)\nRequirement already satisfied: colorlog in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from optuna>=3.4.0->dspy) (6.9.0)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.11/site-packages (from pandas<3->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (2022.7)\nRequirement already satisfied: tzdata>=2022.7 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from pandas<3->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (2025.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (0.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /databricks/python3/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (2.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (2023.7.22)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from rich>=13.7.1->dspy) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /databricks/python3/lib/python3.11/site-packages (from rich>=13.7.1->dspy) (2.15.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.11/site-packages (from scikit-learn<2->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (2.2.0)\nRequirement already satisfied: greenlet>=1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from sqlalchemy<3,>=1.4.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (3.2.3)\nRequirement already satisfied: langchain-community>=0.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain) (0.3.26)\nCollecting unitycatalog-ai (from unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain)\n  Downloading unitycatalog_ai-0.3.1-py3-none-any.whl.metadata (31 kB)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from dataclasses-json->databricks-agents) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from dataclasses-json->databricks-agents) (0.9.0)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from aiohttp>=3.10->litellm>=1.60.3->dspy) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from aiohttp>=3.10->litellm>=1.60.3->dspy) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from aiohttp>=3.10->litellm>=1.60.3->dspy) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from aiohttp>=3.10->litellm>=1.60.3->dspy) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from aiohttp>=3.10->litellm>=1.60.3->dspy) (6.5.0)\nRequirement already satisfied: propcache>=0.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from aiohttp>=3.10->litellm>=1.60.3->dspy) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from aiohttp>=3.10->litellm>=1.60.3->dspy) (1.20.1)\nRequirement already satisfied: cryptography>=2.1.4 in /databricks/python3/lib/python3.11/site-packages (from azure-storage-blob<13.0.0,>=12.19.0->azure-storage-file-datalake>12->mlflow[databricks]>=3.1.0) (41.0.3)\nRequirement already satisfied: starlette<0.47.0,>=0.40.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from fastapi<1->mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (0.46.2)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /databricks/python3/lib/python3.11/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (4.0.11)\nRequirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /databricks/python3/lib/python3.11/site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage>=1.30.0->mlflow[databricks]>=3.1.0) (1.25.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /databricks/python3/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (0.2.8)\nRequirement already satisfied: rsa<5,>=3.1.4 in /databricks/python3/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (4.9)\nRequirement already satisfied: httpcore==1.* in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (0.16.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from huggingface-hub>=0.24.0->datasets>=2.14.6->dspy) (1.1.5)\nRequirement already satisfied: zipp>=3.20 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (3.23.0)\nRequirement already satisfied: jsonpointer>=1.9 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.60.3->dspy) (2025.4.1)\nRequirement already satisfied: referencing>=0.28.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.60.3->dspy) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.60.3->dspy) (0.25.1)\nRequirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from langchain-community>=0.2.0->unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain) (2.9.1)\nRequirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from langchain-community>=0.2.0->unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain) (0.4.0)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from langsmith>=0.1.17->langchain>=0.3.0->databricks-langchain) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /databricks/python3/lib/python3.11/site-packages (from langsmith>=0.1.17->langchain>=0.3.0->databricks-langchain) (0.23.0)\nRequirement already satisfied: mdurl~=0.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->dspy) (0.1.2)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.55b1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086/lib/python3.11/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (0.55b1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /databricks/python3/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->databricks-agents) (0.4.3)\nRequirement already satisfied: nest-asyncio in /databricks/python3/lib/python3.11/site-packages (from unitycatalog-ai->unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain) (1.5.6)\nCollecting unitycatalog-client (from unitycatalog-ai->unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain)\n  Downloading unitycatalog_client-0.3.0-py3-none-any.whl.metadata (7.8 kB)\nRequirement already satisfied: cffi>=1.12 in /databricks/python3/lib/python3.11/site-packages (from cryptography>=2.1.4->azure-storage-blob<13.0.0,>=12.19.0->azure-storage-file-datalake>12->mlflow[databricks]>=3.1.0) (1.15.1)\nRequirement already satisfied: smmap<6,>=3.0.1 in /databricks/python3/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (5.0.1)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /databricks/python3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (0.4.8)\nCollecting aiohttp-retry>=2.8.3 (from unitycatalog-client->unitycatalog-ai->unitycatalog-langchain>=0.2.0->unitycatalog-langchain[databricks]>=0.2.0->databricks-langchain)\n  Downloading aiohttp_retry-2.9.1-py3-none-any.whl.metadata (8.8 kB)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob<13.0.0,>=12.19.0->azure-storage-file-datalake>12->mlflow[databricks]>=3.1.0) (2.21)\nDownloading databricks_langchain-0.5.1-py3-none-any.whl (22 kB)\nDownloading databricks_ai_bridge-0.5.1-py3-none-any.whl (16 kB)\nDownloading databricks_connect-16.1.6-py2.py3-none-any.whl (2.4 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/2.4 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.4/2.4 MB\u001B[0m \u001B[31m42.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading databricks_vectorsearch-0.56-py3-none-any.whl (15 kB)\nDownloading unitycatalog_langchain-0.2.0-py3-none-any.whl (5.4 kB)\nDownloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\nDownloading tabulate-0.9.0-py3-none-any.whl (35 kB)\nDownloading unitycatalog_ai-0.3.1-py3-none-any.whl (66 kB)\nDownloading unitycatalog_client-0.3.0-py3-none-any.whl (159 kB)\nDownloading aiohttp_retry-2.9.1-py3-none-any.whl (10.0 kB)\nInstalling collected packages: tabulate, deprecation, aiohttp-retry, unitycatalog-client, databricks-connect, unitycatalog-ai, databricks-vectorsearch, databricks-ai-bridge, unitycatalog-langchain, databricks-langchain\n  Attempting uninstall: databricks-connect\n    Found existing installation: databricks-connect 15.4.5\n    Not uninstalling databricks-connect at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-ae181e2a-f5d8-4b07-a760-73915ce79086\n    Can't uninstall 'databricks-connect'. No files were found to uninstall.\nSuccessfully installed aiohttp-retry-2.9.1 databricks-ai-bridge-0.5.1 databricks-connect-16.1.6 databricks-langchain-0.5.1 databricks-vectorsearch-0.56 deprecation-2.1.0 tabulate-0.9.0 unitycatalog-ai-0.3.1 unitycatalog-client-0.3.0 unitycatalog-langchain-0.2.0\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install -U \"mlflow[databricks]>=3.1.0\" databricks-langchain langgraph dspy databricks-agents\n",
    "\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "372cc1bf-9409-457b-a036-a1aecce8a984",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.entities import Prompt\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "CATALOG = \"workspace\"\n",
    "SCHEMA = \"default\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddb066e7-c24d-4c78-8f4b-4cdc205c30c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "PromptVersion(name=workspace.default.qa_prompt, version=3, template=\"\\u6b21\\u306e\\u8cea\\u554f\\u306...)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First prompt for summarization.\n",
    "qa_prompt = mlflow.genai.register_prompt(\n",
    "    name=f\"{CATALOG}.{SCHEMA}.qa_prompt\",\n",
    "    template=\"次の質問に対して日本語で回答してください:{{question}}\",\n",
    ")\n",
    "\n",
    "qa_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ab5d4f1-f020-4599-beea-c55ea1d660eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>inputs</th><th>expectations</th></tr></thead><tbody><tr><td>List(Databricksとは何ですか？)</td><td>List(Databricksは、データエンジニアリング、データサイエンス、機械学習のための統合データ分析プラットフォームです。)</td></tr><tr><td>List(Databricksの主な機能は何ですか？)</td><td>List(Databricksの主な機能には、データの統合、分析、機械学習モデルのトレーニングとデプロイがあります。)</td></tr><tr><td>List(Databricksで使用できるプログラミング言語は何ですか？)</td><td>List(Databricksでは、Python、SQL、R、Scalaなどのプログラミング言語を使用できます。)</td></tr><tr><td>List(Databricksのノートブックとは何ですか？)</td><td>List(Databricksのノートブックは、データ分析や機械学習のコードを記述、実行、共有するためのインタラクティブな環境です。)</td></tr><tr><td>List(Databricksのクラスターとは何ですか？)</td><td>List(Databricksのクラスターは、データ処理や分析のために使用されるコンピューティングリソースの集合です。)</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         [
          "Databricksとは何ですか？"
         ],
         [
          "Databricksは、データエンジニアリング、データサイエンス、機械学習のための統合データ分析プラットフォームです。"
         ]
        ],
        [
         [
          "Databricksの主な機能は何ですか？"
         ],
         [
          "Databricksの主な機能には、データの統合、分析、機械学習モデルのトレーニングとデプロイがあります。"
         ]
        ],
        [
         [
          "Databricksで使用できるプログラミング言語は何ですか？"
         ],
         [
          "Databricksでは、Python、SQL、R、Scalaなどのプログラミング言語を使用できます。"
         ]
        ],
        [
         [
          "Databricksのノートブックとは何ですか？"
         ],
         [
          "Databricksのノートブックは、データ分析や機械学習のコードを記述、実行、共有するためのインタラクティブな環境です。"
         ]
        ],
        [
         [
          "Databricksのクラスターとは何ですか？"
         ],
         [
          "Databricksのクラスターは、データ処理や分析のために使用されるコンピューティングリソースの集合です。"
         ]
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "inputs",
         "type": "{\"fields\":[{\"metadata\":{},\"name\":\"question\",\"nullable\":true,\"type\":\"string\"}],\"type\":\"struct\"}"
        },
        {
         "metadata": "{}",
         "name": "expectations",
         "type": "{\"fields\":[{\"metadata\":{},\"name\":\"answer\",\"nullable\":true,\"type\":\"string\"}],\"type\":\"struct\"}"
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 質問と回答のペアをリストとして定義\n",
    "train_data = [\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"Databricksとは何ですか？\"},\n",
    "        \"expectations\": {\n",
    "            \"answer\": \"Databricksは、データエンジニアリング、データサイエンス、機械学習のための統合データ分析プラットフォームです。\"\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"Databricksの主な機能は何ですか？\"},\n",
    "        \"expectations\": {\n",
    "            \"answer\": \"Databricksの主な機能には、データの統合、分析、機械学習モデルのトレーニングとデプロイがあります。\"\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"Databricksで使用できるプログラミング言語は何ですか？\"},\n",
    "        \"expectations\": {\n",
    "            \"answer\": \"Databricksでは、Python、SQL、R、Scalaなどのプログラミング言語を使用できます。\"\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"Databricksのノートブックとは何ですか？\"},\n",
    "        \"expectations\": {\n",
    "            \"answer\": \"Databricksのノートブックは、データ分析や機械学習のコードを記述、実行、共有するためのインタラクティブな環境です。\"\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"Databricksのクラスターとは何ですか？\"},\n",
    "        \"expectations\": {\n",
    "            \"answer\": \"Databricksのクラスターは、データ処理や分析のために使用されるコンピューティングリソースの集合です。\"\n",
    "        },\n",
    "    },\n",
    "]\n",
    "eval_data = [\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"DatabricksのDelta Lakeとは何ですか？\"},\n",
    "        \"expectations\": {\n",
    "            \"answer\": \"Delta Lakeは、Databricks上で提供される信頼性の高いデータレイクソリューションで、ACIDトランザクションやスキーマエンフォースメントをサポートします。\"\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"DatabricksのMLflowとは何ですか？\"},\n",
    "        \"expectations\": {\"answer\": \"MLflowは、機械学習モデルのライフサイクル管理を支援するオープンソースプラットフォームです。\"},\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"Databricksのジョブとは何ですか？\"},\n",
    "        \"expectations\": {\n",
    "            \"answer\": \"Databricksのジョブは、スケジュールされたデータ処理タスクやワークフローを自動化するための機能です。\"\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"Databricksのワークスペースとは何ですか？\"},\n",
    "        \"expectations\": {\n",
    "            \"answer\": \"Databricksのワークスペースは、データ分析や機械学習プロジェクトを管理するためのコラボレーション環境です。\"\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"DatabricksのUnity Catalogとは何ですか？\"},\n",
    "        \"expectations\": {\n",
    "            \"answer\": \"Unity Catalogは、Databricks上でデータガバナンスとセキュリティを提供するための統合データカタログです。\"\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "# pandasデータフレームに変換\n",
    "pdf = pd.DataFrame(train_data)\n",
    "\n",
    "# データフレームを表示\n",
    "display(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15eeb240-760f-48cb-9a91-92206b7c85ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/22 09:16:23 INFO mlflow.genai.optimize.base: Run `9c9d4d9743df4673a55f3bad9e06a308` is created for autologging prompt optimization. Watch the run to track the optimization progress.\n2025/06/22 09:16:24 INFO mlflow.genai.optimize.optimizers.dspy_mipro_optimizer: Started optimizing prompt prompts:/workspace.default.qa_prompt/1. Please wait as this process typically takes several minutes, but can take longer with large datasets...\n2025/06/22 09:17:36 INFO mlflow.genai.optimize.optimizers.dspy_mipro_optimizer: Prompt optimization completed. Evaluation score did not change. Score 80.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompts:/workspace.default.qa_prompt/15\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "[\"tr-724e4c59534f92e0a1cc2b81348647f1\", \"tr-a93d85e284f9d130ca11b258cf8f3e0a\"]",
      "text/plain": [
       "[Trace(trace_id=tr-724e4c59534f92e0a1cc2b81348647f1), Trace(trace_id=tr-a93d85e284f9d130ca11b258cf8f3e0a)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import Any\n",
    "from mlflow.genai.scorers import Correctness\n",
    "from mlflow.genai.optimize import OptimizerConfig, LLMParams\n",
    "from mlflow.genai.scorers import scorer\n",
    "import os\n",
    "\n",
    "# OpenAI Clientが利用できるように、現在のCredentialをOPENAI_API_KEYに登録\n",
    "mlflow_creds = mlflow.utils.databricks_utils.get_databricks_host_creds()\n",
    "os.environ[\"OPENAI_API_KEY\"] = mlflow_creds.token\n",
    "\n",
    "# Correctnessスコアを計算するbuilt-inオブジェクトを作成\n",
    "_correctness = Correctness()\n",
    "\n",
    "# プロンプト最適化のための評価関数（確からしさのテスト)\n",
    "@scorer\n",
    "def correctness(inputs, outputs, expectations):\n",
    "    expectations = {\"expected_response\": expectations.get(\"answer\")}\n",
    "    return (\n",
    "        _correctness(inputs=inputs, outputs=outputs, expectations=expectations).value\n",
    "        == \"yes\"\n",
    "    )\n",
    "\n",
    "# 最適化対象のプロンプト\n",
    "prompt = mlflow.genai.load_prompt(f\"prompts:/{CATALOG}.{SCHEMA}.qa_prompt/1\")\n",
    "\n",
    "# プロンプトを最適化\n",
    "result = mlflow.genai.optimize_prompt(\n",
    "    target_llm_params=LLMParams(\n",
    "        model_name=\"openai/databricks-llama-4-maverick\",\n",
    "        base_uri=f\"{mlflow_creds.host}/serving-endpoints\",\n",
    "    ),\n",
    "    prompt=prompt,\n",
    "    train_data=train_data,\n",
    "    eval_data=eval_data,\n",
    "    scorers=[correctness],\n",
    "    optimizer_config=OptimizerConfig(\n",
    "        num_instruction_candidates=8,\n",
    "        max_few_show_examples=2,\n",
    "        # verbose=True,\n",
    "        autolog=True,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# 最適化結果のプロンプトレジストリのURLを表示\n",
    "print(result.prompt.uri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3aa4d6f2-07a9-41f1-8893-be55fd1f35cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"<system>\\nYour input fields are:\\n1. `question` (str):\\nYour output fields are:\\n1. `answer` (str):\\nAll interactions will be structured in the following way, with the appropriate values filled in.\\n\\nInputs will have the following structure:\\n\\n[[ ## question ## ]]\\n{question}\\n\\nOutputs will be a JSON object with the following fields.\\n\\n{\\n  \\\"answer\\\": \\\"{answer}\\\"\\n}\\nIn adhering to this structure, your objective is: \\n        {{question}}\\n</system>\\n\\n<user>\\n[[ ## question ## ]]\\n{{question}}\\n\\nRespond with a JSON object in the following order of fields: `answer`.\\n</user>\"\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "prompt = mlflow.genai.load_prompt(result.prompt.uri)\n",
    "\n",
    "print(prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73df1a76-d8ba-46ee-9f36-f6c6ad49970c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Databricksは、Apache Sparkを利用したビッグデータ処理と分析のためのプラットフォームおよびサービスを提供する企業、およびそのプラットフォームの名称です。Databricksは、Sparkの開発に携わった人々によって設立されました。Sparkは、大規模なデータセットを高速に処理できるオープンソースの分散処理フレームワークです。\n\nDatabricksが提供するプラットフォームは、データエンジニアリング、データサイエンス、およびビジネスユーザーを対象に設計されており、Apache Sparkを用いたデータの取り込み、変換、分析を容易に行えるようにします。主な特徴としては、以下のようなものがあります：\n\n1. **インタラクティブなワークスペース**: データの探索、変換、分析をインタラクティブに行うための環境を提供します。ノートブック形式での作業が可能で、Python、R、Scala、SQLなどの言語に対応しています。\n\n2. **データの取り込みと統合**: 多様なデータソースからのデータの取り込みをサポートし、データレイクやデータウェアハウスへのデータ統合を容易にします。\n\n3. **高度な分析**: Apache Sparkの力を利用して、大規模なデータセットに対する高度な分析や機械学習を高速に実行できます。\n\n4. **コラボレーション機能**: データサイエンティスト、エンジニア、ビジネスユーザー間のコラボレーションを促進するための機能が備わっています。\n\n5. **セキュリティとガバナンス**: 企業がデータを安全に扱えるように、アクセス制御や監査ログなどのセキュリティ機能を提供しています。\n\nDatabricksは、クラウド（AWS、Azure、GCP）上でサービスとして提供されるほか、オンプレミス環境やプライベートクラウドへのデプロイメントもサポートしています。これにより、企業は自社のニーズや既存のITインフラに合わせた形で、ビッグデータと分析技術を活用することができます。\n{\n  \"answer\": \"Databricksは、Apache Sparkの創始者たちが開発した、ビッグデータ処理および分析プラットフォームです。データエンジニアリング、データサイエンス、ビジネスアナリティクスのための統合環境を提供し、データの処理、分析、可視化を容易にします。クラウドベースのサービスとして、AWS、Azure、Google Cloudなどの主要なクラウドプロバイダー上で動作します。\"\n}\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "[\"tr-db0ff0b3fcc5cf7dae695eaba7000084\", \"tr-ab8011b8960e57eba06d88a5539b8eed\"]",
      "text/plain": [
       "[Trace(trace_id=tr-db0ff0b3fcc5cf7dae695eaba7000084), Trace(trace_id=tr-ab8011b8960e57eba06d88a5539b8eed)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mlflow\n",
    "from openai import OpenAI\n",
    "import codecs\n",
    "\n",
    "# MLflowの自動ロギングを有効にして、アプリケーションにトレースを追加\n",
    "mlflow.openai.autolog()\n",
    "\n",
    "# 実行ノートブックと同じ資格情報を使用してOpenAIクライアント経由でDatabricks LLMに接続\n",
    "mlflow_creds = mlflow.utils.databricks_utils.get_databricks_host_creds()\n",
    "client = OpenAI(\n",
    "    api_key=mlflow_creds.token, base_url=f\"{mlflow_creds.host}/serving-endpoints\"\n",
    ")\n",
    "\n",
    "# レジストリからプロンプトをロード\n",
    "first_prompt = mlflow.genai.load_prompt(f\"prompts:/{CATALOG}.{SCHEMA}.qa_prompt/1\")\n",
    "optimized_prompt = mlflow.genai.load_prompt(result.prompt.uri)\n",
    "endpoint = \"databricks-llama-4-maverick\"\n",
    "\n",
    "def predict(prompt):\n",
    "    formatted_prompt = prompt.format(question=\"Databricksとは何ですか?\")\n",
    "    \n",
    "    # LLMを呼び出す\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"databricks-llama-4-maverick\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": formatted_prompt,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "for p in [first_prompt, optimized_prompt]:\n",
    "    print(predict(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d7f10e1d-7469-4b0e-96ba-bded768162ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 公式Notebook\n",
    "\n",
    "https://docs.databricks.com/aws/ja/notebooks/source/mlflow/prompt-optimization.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e62558b4-45d3-4d83-abf1-426521961d23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlflow>=3.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages (from mlflow[databricks]>=3.1.0) (3.1.0)\nCollecting langchain-community\n  Downloading langchain_community-0.3.26-py3-none-any.whl.metadata (2.9 kB)\nCollecting langchain-openai\n  Downloading langchain_openai-0.3.24-py3-none-any.whl.metadata (2.3 kB)\nCollecting beautifulsoup4\n  Downloading beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\nCollecting langgraph\n  Downloading langgraph-0.4.8-py3-none-any.whl.metadata (6.8 kB)\nCollecting dspy\n  Downloading dspy-2.6.27-py3-none-any.whl.metadata (7.0 kB)\nRequirement already satisfied: databricks-agents in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages (1.1.0)\nRequirement already satisfied: mlflow-skinny==3.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages (from mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (3.1.0)\nRequirement already satisfied: Flask<4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages (from mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (3.1.1)\nRequirement already satisfied: alembic!=1.10.0,<2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages (from mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (1.16.2)\nRequirement already satisfied: docker<8,>=4.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages (from mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (7.1.0)\nRequirement already satisfied: graphene<4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages (from mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (3.4.3)\nRequirement already satisfied: gunicorn<24 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages (from mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (23.0.0)\nRequirement already satisfied: matplotlib<4 in /databricks/python3/lib/python3.11/site-packages (from mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (3.7.2)\nRequirement already satisfied: numpy<3 in /databricks/python3/lib/python3.11/site-packages (from mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (1.23.5)\nRequirement already satisfied: pandas<3 in /databricks/python3/lib/python3.11/site-packages (from mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (1.5.3)\nRequirement already satisfied: pyarrow<21,>=4.0.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (14.0.1)\nRequirement already satisfied: scikit-learn<2 in /databricks/python3/lib/python3.11/site-packages (from mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (1.3.0)\nRequirement already satisfied: scipy<2 in /databricks/python3/lib/python3.11/site-packages (from mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (1.11.1)\nRequirement already satisfied: sqlalchemy<3,>=1.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages (from mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (2.0.41)\nRequirement already satisfied: cachetools<7,>=5.0.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (5.5.0)\nRequirement already satisfied: click<9,>=7.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages (from mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (8.2.1)\nRequirement already satisfied: cloudpickle<4 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (3.0.0)\nRequirement already satisfied: databricks-sdk<1,>=0.20.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages (from mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (0.55.0)\nRequirement already satisfied: fastapi<1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages (from mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (0.115.13)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (3.1.43)\nRequirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (6.0.0)\nRequirement already satisfied: opentelemetry-api<3,>=1.9.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages (from mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (1.34.1)\nRequirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages (from mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (1.34.1)\nRequirement already satisfied: packaging<26 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (23.2)\nRequirement already satisfied: protobuf<7,>=3.12.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages (from mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (4.25.8)\nRequirement already satisfied: pydantic<3,>=1.10.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages (from mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (2.11.7)\nRequirement already satisfied: pyyaml<7,>=5.1 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (6.0)\nRequirement already satisfied: requests<3,>=2.17.3 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (2.31.0)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (0.5.1)\nRequirement already satisfied: typing-extensions<5,>=4.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages (from mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (4.14.0)\nRequirement already satisfied: uvicorn<1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages (from mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (0.34.3)\nCollecting langchain-core<1.0.0,>=0.3.66 (from langchain-community)\n  Downloading langchain_core-0.3.66-py3-none-any.whl.metadata (5.8 kB)\nCollecting langchain<1.0.0,>=0.3.26 (from langchain-community)\n  Downloading langchain-0.3.26-py3-none-any.whl.metadata (7.8 kB)\nCollecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n  Downloading aiohttp-3.12.13-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (7.6 kB)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages (from langchain-community) (9.1.2)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages (from langchain-community) (0.6.7)\nCollecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\nCollecting langsmith>=0.1.125 (from langchain-community)\n  Downloading langsmith-0.4.1-py3-none-any.whl.metadata (15 kB)\nCollecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\nCollecting numpy<3 (from mlflow>=3.1.0->mlflow[databricks]>=3.1.0)\n  Downloading numpy-2.3.0-cp311-cp311-manylinux_2_28_aarch64.whl.metadata (62 kB)\nCollecting openai<2.0.0,>=1.86.0 (from langchain-openai)\n  Downloading openai-1.90.0-py3-none-any.whl.metadata (26 kB)\nRequirement already satisfied: tiktoken<1,>=0.7 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages (from langchain-openai) (0.9.0)\nCollecting soupsieve>1.2 (from beautifulsoup4)\n  Downloading soupsieve-2.7-py3-none-any.whl.metadata (4.6 kB)\nCollecting langgraph-checkpoint>=2.0.26 (from langgraph)\n  Downloading langgraph_checkpoint-2.1.0-py3-none-any.whl.metadata (4.2 kB)\nCollecting langgraph-prebuilt>=0.2.0 (from langgraph)\n  Downloading langgraph_prebuilt-0.2.2-py3-none-any.whl.metadata (4.5 kB)\nCollecting langgraph-sdk>=0.1.42 (from langgraph)\n  Downloading langgraph_sdk-0.1.70-py3-none-any.whl.metadata (1.5 kB)\nCollecting xxhash>=3.5.0 (from langgraph)\n  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (12 kB)\nCollecting backoff>=2.2 (from dspy)\n  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\nCollecting joblib~=1.3 (from dspy)\n  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\nCollecting pandas<3 (from mlflow>=3.1.0->mlflow[databricks]>=3.1.0)\n  Downloading pandas-2.3.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (91 kB)\nRequirement already satisfied: regex>=2023.10.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages (from dspy) (2024.11.6)\nCollecting ujson>=5.8.0 (from dspy)\n  Downloading ujson-5.10.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (9.3 kB)\nRequirement already satisfied: tqdm>=4.66.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages (from dspy) (4.67.1)\nCollecting datasets>=2.14.6 (from dspy)\n  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\nCollecting optuna>=3.4.0 (from dspy)\n  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\nCollecting magicattr>=0.1.6 (from dspy)\n  Downloading magicattr-0.1.6-py2.py3-none-any.whl.metadata (3.2 kB)\nCollecting litellm>=1.60.3 (from dspy)\n  Downloading litellm-1.72.9-py3-none-any.whl.metadata (39 kB)\nCollecting diskcache>=5.6.0 (from dspy)\n  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\nCollecting json-repair>=0.30.0 (from dspy)\n  Downloading json_repair-0.47.1-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: anyio in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages (from dspy) (4.9.0)\nCollecting asyncer==0.0.8 (from dspy)\n  Downloading asyncer-0.0.8-py3-none-any.whl.metadata (6.7 kB)\nCollecting rich>=13.7.1 (from dspy)\n  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: databricks-connect in /databricks/python3/lib/python3.11/site-packages (from databricks-agents) (15.4.5)\nRequirement already satisfied: jinja2>=3.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages (from databricks-agents) (3.1.6)\nRequirement already satisfied: urllib3>=2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages (from databricks-agents) (2.0.7)\nRequirement already satisfied: azure-storage-file-datalake>12 in /databricks/python3/lib/python3.11/site-packages (from mlflow[databricks]>=3.1.0) (12.14.0)\nRequirement already satisfied: google-cloud-storage>=1.30.0 in /databricks/python3/lib/python3.11/site-packages (from mlflow[databricks]>=3.1.0) (2.18.2)\nRequirement already satisfied: boto3>1 in /databricks/python3/lib/python3.11/site-packages (from mlflow[databricks]>=3.1.0) (1.34.39)\nRequirement already satisfied: botocore in /databricks/python3/lib/python3.11/site-packages (from mlflow[databricks]>=3.1.0) (1.34.39)\nCollecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\nCollecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\nCollecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\nCollecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n  Downloading frozenlist-1.7.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (18 kB)\nCollecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n  Downloading multidict-6.5.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (5.3 kB)\nCollecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n  Downloading propcache-0.3.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (12 kB)\nCollecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n  Downloading yarl-1.20.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (73 kB)\nRequirement already satisfied: Mako in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages (from alembic!=1.10.0,<2->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (1.3.10)\nRequirement already satisfied: idna>=2.8 in /databricks/python3/lib/python3.11/site-packages (from anyio->dspy) (3.4)\nRequirement already satisfied: sniffio>=1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages (from anyio->dspy) (1.3.1)\nRequirement already satisfied: azure-core<2.0.0,>=1.28.0 in /databricks/python3/lib/python3.11/site-packages (from azure-storage-file-datalake>12->mlflow[databricks]>=3.1.0) (1.32.0)\nRequirement already satisfied: azure-storage-blob<13.0.0,>=12.19.0 in /databricks/python3/lib/python3.11/site-packages (from azure-storage-file-datalake>12->mlflow[databricks]>=3.1.0) (12.19.1)\nRequirement already satisfied: isodate>=0.6.1 in /databricks/python3/lib/python3.11/site-packages (from azure-storage-file-datalake>12->mlflow[databricks]>=3.1.0) (0.7.2)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /databricks/python3/lib/python3.11/site-packages (from boto3>1->mlflow[databricks]>=3.1.0) (0.10.0)\nRequirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /databricks/python3/lib/python3.11/site-packages (from boto3>1->mlflow[databricks]>=3.1.0) (0.10.3)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /databricks/python3/lib/python3.11/site-packages (from botocore->mlflow[databricks]>=3.1.0) (2.8.2)\nRequirement already satisfied: google-auth~=2.0 in /databricks/python3/lib/python3.11/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (2.35.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\nRequirement already satisfied: filelock in /databricks/python3/lib/python3.11/site-packages (from datasets>=2.14.6->dspy) (3.13.4)\nCollecting pyarrow<21,>=4.0.0 (from mlflow>=3.1.0->mlflow[databricks]>=3.1.0)\n  Downloading pyarrow-20.0.0-cp311-cp311-manylinux_2_28_aarch64.whl.metadata (3.3 kB)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /databricks/python3/lib/python3.11/site-packages (from datasets>=2.14.6->dspy) (0.3.6)\nCollecting requests<3,>=2.17.3 (from mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0)\n  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\nCollecting multiprocess<0.70.17 (from datasets>=2.14.6->dspy)\n  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\nCollecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.6->dspy)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nCollecting huggingface-hub>=0.24.0 (from datasets>=2.14.6->dspy)\n  Downloading huggingface_hub-0.33.0-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: blinker>=1.9.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages (from Flask<4->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (1.9.0)\nRequirement already satisfied: itsdangerous>=2.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages (from Flask<4->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (2.2.0)\nRequirement already satisfied: markupsafe>=2.1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages (from Flask<4->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (3.0.2)\nRequirement already satisfied: werkzeug>=3.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages (from Flask<4->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (3.1.3)\nRequirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /databricks/python3/lib/python3.11/site-packages (from google-cloud-storage>=1.30.0->mlflow[databricks]>=3.1.0) (2.18.0)\nRequirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /databricks/python3/lib/python3.11/site-packages (from google-cloud-storage>=1.30.0->mlflow[databricks]>=3.1.0) (2.4.1)\nRequirement already satisfied: google-resumable-media>=2.7.2 in /databricks/python3/lib/python3.11/site-packages (from google-cloud-storage>=1.30.0->mlflow[databricks]>=3.1.0) (2.7.2)\nRequirement already satisfied: google-crc32c<2.0dev,>=1.0 in /databricks/python3/lib/python3.11/site-packages (from google-cloud-storage>=1.30.0->mlflow[databricks]>=3.1.0) (1.6.0)\nRequirement already satisfied: graphql-core<3.3,>=3.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages (from graphene<4->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (3.2.6)\nRequirement already satisfied: graphql-relay<3.3,>=3.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages (from graphene<4->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (3.2.0)\nCollecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain<1.0.0,>=0.3.26->langchain-community)\n  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\nCollecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.66->langchain-community)\n  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\nCollecting ormsgpack>=1.10.0 (from langgraph-checkpoint>=2.0.26->langgraph)\n  Downloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (43 kB)\nCollecting httpx>=0.25.2 (from langgraph-sdk>=0.1.42->langgraph)\n  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\nCollecting orjson>=3.10.1 (from langgraph-sdk>=0.1.42->langgraph)\n  Downloading orjson-3.10.18-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (41 kB)\nCollecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith>=0.1.125->langchain-community)\n  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /databricks/python3/lib/python3.11/site-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\nCollecting importlib_metadata!=4.7.0,<9,>=3.7.0 (from mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0)\n  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\nCollecting jsonschema<5.0.0,>=4.22.0 (from litellm>=1.60.3->dspy)\n  Downloading jsonschema-4.24.0-py3-none-any.whl.metadata (7.8 kB)\nCollecting python-dotenv>=0.2.0 (from litellm>=1.60.3->dspy)\n  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\nCollecting tokenizers (from litellm>=1.60.3->dspy)\n  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (6.8 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (1.0.5)\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (4.25.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (1.4.4)\nRequirement already satisfied: pillow>=6.2.0 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (10.3.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /databricks/python3/lib/python3.11/site-packages (from matplotlib<4->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (3.0.9)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.7.0)\nCollecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.86.0->langchain-openai)\n  Downloading jiter-0.10.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (5.2 kB)\nCollecting colorlog (from optuna>=3.4.0->dspy)\n  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.11/site-packages (from pandas<3->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (2022.7)\nCollecting tzdata>=2022.7 (from pandas<3->mlflow>=3.1.0->mlflow[databricks]>=3.1.0)\n  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\nRequirement already satisfied: annotated-types>=0.6.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (0.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /databricks/python3/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (2.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (2023.7.22)\nCollecting markdown-it-py>=2.2.0 (from rich>=13.7.1->dspy)\n  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /databricks/python3/lib/python3.11/site-packages (from rich>=13.7.1->dspy) (2.15.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.11/site-packages (from scikit-learn<2->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (2.2.0)\nCollecting numpy<3 (from mlflow>=3.1.0->mlflow[databricks]>=3.1.0)\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (62 kB)\nRequirement already satisfied: greenlet>=1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages (from sqlalchemy<3,>=1.4.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (3.2.3)\nRequirement already satisfied: googleapis-common-protos>=1.56.4 in /databricks/python3/lib/python3.11/site-packages (from databricks-connect->databricks-agents) (1.65.0)\nRequirement already satisfied: grpcio-status>=1.59.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages (from databricks-connect->databricks-agents) (1.62.3)\nRequirement already satisfied: grpcio>=1.59.3 in /databricks/python3/lib/python3.11/site-packages (from databricks-connect->databricks-agents) (1.69.0)\nRequirement already satisfied: py4j==0.10.9.7 in /databricks/python3/lib/python3.11/site-packages (from databricks-connect->databricks-agents) (0.10.9.7)\nRequirement already satisfied: setuptools>=68.0.0 in /databricks/python3/lib/python3.11/site-packages (from databricks-connect->databricks-agents) (75.1.0)\nRequirement already satisfied: six in /usr/lib/python3/dist-packages (from databricks-connect->databricks-agents) (1.16.0)\nRequirement already satisfied: cryptography>=2.1.4 in /databricks/python3/lib/python3.11/site-packages (from azure-storage-blob<13.0.0,>=12.19.0->azure-storage-file-datalake>12->mlflow[databricks]>=3.1.0) (41.0.3)\nRequirement already satisfied: starlette<0.47.0,>=0.40.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages (from fastapi<1->mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (0.46.2)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /databricks/python3/lib/python3.11/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (4.0.11)\nRequirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /databricks/python3/lib/python3.11/site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage>=1.30.0->mlflow[databricks]>=3.1.0) (1.25.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /databricks/python3/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (0.2.8)\nRequirement already satisfied: rsa<5,>=3.1.4 in /databricks/python3/lib/python3.11/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (4.9)\nCollecting httpcore==1.* (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph)\n  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\nRequirement already satisfied: h11>=0.16 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (0.16.0)\nCollecting hf-xet<2.0.0,>=1.1.2 (from huggingface-hub>=0.24.0->datasets>=2.14.6->dspy)\n  Downloading hf_xet-1.1.5-cp37-abi3-manylinux_2_28_aarch64.whl.metadata (879 bytes)\nCollecting zipp>=3.20 (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0)\n  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\nCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain-community)\n  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\nCollecting jsonschema-specifications>=2023.03.6 (from jsonschema<5.0.0,>=4.22.0->litellm>=1.60.3->dspy)\n  Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\nCollecting referencing>=0.28.4 (from jsonschema<5.0.0,>=4.22.0->litellm>=1.60.3->dspy)\n  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\nCollecting rpds-py>=0.7.1 (from jsonschema<5.0.0,>=4.22.0->litellm>=1.60.3->dspy)\n  Downloading rpds_py-0.25.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (4.1 kB)\nCollecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=13.7.1->dspy)\n  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\nCollecting dill<0.3.9,>=0.3.0 (from datasets>=2.14.6->dspy)\n  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.55b1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (0.55b1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /databricks/python3/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (0.4.3)\nRequirement already satisfied: cffi>=1.12 in /databricks/python3/lib/python3.11/site-packages (from cryptography>=2.1.4->azure-storage-blob<13.0.0,>=12.19.0->azure-storage-file-datalake>12->mlflow[databricks]>=3.1.0) (1.15.1)\nRequirement already satisfied: smmap<6,>=3.0.1 in /databricks/python3/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (5.0.1)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /databricks/python3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.1.0->mlflow>=3.1.0->mlflow[databricks]>=3.1.0) (0.4.8)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob<13.0.0,>=12.19.0->azure-storage-file-datalake>12->mlflow[databricks]>=3.1.0) (2.21)\nDownloading langchain_community-0.3.26-py3-none-any.whl (2.5 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/2.5 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.5/2.5 MB\u001B[0m \u001B[31m63.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading langchain_openai-0.3.24-py3-none-any.whl (68 kB)\nDownloading beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\nDownloading langgraph-0.4.8-py3-none-any.whl (152 kB)\nDownloading dspy-2.6.27-py3-none-any.whl (297 kB)\nDownloading asyncer-0.0.8-py3-none-any.whl (9.2 kB)\nDownloading aiohttp-3.12.13-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (1.7 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/1.7 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.7/1.7 MB\u001B[0m \u001B[31m94.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\nDownloading datasets-3.6.0-py3-none-any.whl (491 kB)\nDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\nDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\nDownloading joblib-1.5.1-py3-none-any.whl (307 kB)\nDownloading json_repair-0.47.1-py3-none-any.whl (22 kB)\nDownloading langchain-0.3.26-py3-none-any.whl (1.0 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/1.0 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.0/1.0 MB\u001B[0m \u001B[31m53.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading langchain_core-0.3.66-py3-none-any.whl (438 kB)\nDownloading langgraph_checkpoint-2.1.0-py3-none-any.whl (43 kB)\nDownloading langgraph_prebuilt-0.2.2-py3-none-any.whl (23 kB)\nDownloading langgraph_sdk-0.1.70-py3-none-any.whl (49 kB)\nDownloading langsmith-0.4.1-py3-none-any.whl (364 kB)\nDownloading litellm-1.72.9-py3-none-any.whl (8.4 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/8.4 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m8.4/8.4 MB\u001B[0m \u001B[31m155.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading magicattr-0.1.6-py2.py3-none-any.whl (4.7 kB)\nDownloading openai-1.90.0-py3-none-any.whl (734 kB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/734.6 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m734.6/734.6 kB\u001B[0m \u001B[31m64.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading optuna-4.4.0-py3-none-any.whl (395 kB)\nDownloading pandas-2.3.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (11.8 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/11.8 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m11.8/11.8 MB\u001B[0m \u001B[31m154.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading pyarrow-20.0.0-cp311-cp311-manylinux_2_28_aarch64.whl (40.7 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/40.7 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m40.6/40.7 MB\u001B[0m \u001B[31m297.5 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m40.7/40.7 MB\u001B[0m \u001B[31m174.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\nDownloading requests-2.32.4-py3-none-any.whl (64 kB)\nDownloading rich-14.0.0-py3-none-any.whl (243 kB)\nDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (14.2 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/14.2 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m14.2/14.2 MB\u001B[0m \u001B[31m198.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading soupsieve-2.7-py3-none-any.whl (36 kB)\nDownloading ujson-5.10.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (51 kB)\nDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (221 kB)\nDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\nDownloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\nDownloading attrs-25.3.0-py3-none-any.whl (63 kB)\nDownloading frozenlist-1.7.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (237 kB)\nDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\nDownloading httpx-0.28.1-py3-none-any.whl (73 kB)\nDownloading httpcore-1.0.9-py3-none-any.whl (78 kB)\nDownloading huggingface_hub-0.33.0-py3-none-any.whl (514 kB)\nDownloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\nDownloading jiter-0.10.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (345 kB)\nDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\nDownloading jsonschema-4.24.0-py3-none-any.whl (88 kB)\nDownloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\nDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\nDownloading multidict-6.5.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (236 kB)\nDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\nDownloading dill-0.3.8-py3-none-any.whl (116 kB)\nDownloading orjson-3.10.18-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (136 kB)\nDownloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (204 kB)\nDownloading propcache-0.3.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (217 kB)\nDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\nDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\nDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\nDownloading yarl-1.20.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (347 kB)\nDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\nDownloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (2.9 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/2.9 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.9/2.9 MB\u001B[0m \u001B[31m143.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading hf_xet-1.1.5-cp37-abi3-manylinux_2_28_aarch64.whl (3.0 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/3.0 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.0/3.0 MB\u001B[0m \u001B[31m162.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\nDownloading jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\nDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\nDownloading referencing-0.36.2-py3-none-any.whl (26 kB)\nDownloading rpds_py-0.25.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (386 kB)\nDownloading zipp-3.23.0-py3-none-any.whl (10 kB)\nInstalling collected packages: magicattr, zipp, xxhash, ujson, tzdata, soupsieve, rpds-py, requests, python-dotenv, pyarrow, propcache, ormsgpack, orjson, numpy, multidict, mdurl, jsonpointer, json-repair, joblib, jiter, httpx-sse, httpcore, hf-xet, fsspec, frozenlist, diskcache, dill, colorlog, backoff, attrs, aiohappyeyeballs, yarl, requests-toolbelt, referencing, pandas, multiprocess, markdown-it-py, jsonpatch, importlib_metadata, huggingface-hub, httpx, beautifulsoup4, asyncer, aiosignal, tokenizers, rich, pydantic-settings, optuna, openai, langsmith, langgraph-sdk, jsonschema-specifications, aiohttp, langchain-core, jsonschema, litellm, langgraph-checkpoint, langchain-text-splitters, langchain-openai, datasets, langgraph-prebuilt, langchain, dspy, langgraph, langchain-community\n  Attempting uninstall: zipp\n    Found existing installation: zipp 3.11.0\n    Not uninstalling zipp at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e\n    Can't uninstall 'zipp'. No files were found to uninstall.\n  Attempting uninstall: ujson\n    Found existing installation: ujson 5.4.0\n    Not uninstalling ujson at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e\n    Can't uninstall 'ujson'. No files were found to uninstall.\n  Attempting uninstall: tzdata\n    Found existing installation: tzdata 2022.1\n    Not uninstalling tzdata at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e\n    Can't uninstall 'tzdata'. No files were found to uninstall.\n  Attempting uninstall: requests\n    Found existing installation: requests 2.31.0\n    Not uninstalling requests at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e\n    Can't uninstall 'requests'. No files were found to uninstall.\n  Attempting uninstall: pyarrow\n    Found existing installation: pyarrow 14.0.1\n    Not uninstalling pyarrow at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e\n    Can't uninstall 'pyarrow'. No files were found to uninstall.\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.23.5\n    Not uninstalling numpy at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e\n    Can't uninstall 'numpy'. No files were found to uninstall.\n  Attempting uninstall: joblib\n    Found existing installation: joblib 1.2.0\n    Not uninstalling joblib at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e\n    Can't uninstall 'joblib'. No files were found to uninstall.\n  Attempting uninstall: dill\n    Found existing installation: dill 0.3.6\n    Not uninstalling dill at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e\n    Can't uninstall 'dill'. No files were found to uninstall.\n  Attempting uninstall: pandas\n    Found existing installation: pandas 1.5.3\n    Not uninstalling pandas at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e\n    Can't uninstall 'pandas'. No files were found to uninstall.\n  Attempting uninstall: importlib_metadata\n    Found existing installation: importlib-metadata 6.0.0\n    Not uninstalling importlib-metadata at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e\n    Can't uninstall 'importlib-metadata'. No files were found to uninstall.\nSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.13 aiosignal-1.3.2 asyncer-0.0.8 attrs-25.3.0 backoff-2.2.1 beautifulsoup4-4.13.4 colorlog-6.9.0 datasets-3.6.0 dill-0.3.8 diskcache-5.6.3 dspy-2.6.27 frozenlist-1.7.0 fsspec-2025.3.0 hf-xet-1.1.5 httpcore-1.0.9 httpx-0.28.1 httpx-sse-0.4.0 huggingface-hub-0.33.0 importlib_metadata-8.7.0 jiter-0.10.0 joblib-1.5.1 json-repair-0.47.1 jsonpatch-1.33 jsonpointer-3.0.0 jsonschema-4.24.0 jsonschema-specifications-2025.4.1 langchain-0.3.26 langchain-community-0.3.26 langchain-core-0.3.66 langchain-openai-0.3.24 langchain-text-splitters-0.3.8 langgraph-0.4.8 langgraph-checkpoint-2.1.0 langgraph-prebuilt-0.2.2 langgraph-sdk-0.1.70 langsmith-0.4.1 litellm-1.72.9 magicattr-0.1.6 markdown-it-py-3.0.0 mdurl-0.1.2 multidict-6.5.0 multiprocess-0.70.16 numpy-1.26.4 openai-1.90.0 optuna-4.4.0 orjson-3.10.18 ormsgpack-1.10.0 pandas-2.3.0 propcache-0.3.2 pyarrow-20.0.0 pydantic-settings-2.9.1 python-dotenv-1.1.0 referencing-0.36.2 requests-2.32.4 requests-toolbelt-1.0.0 rich-14.0.0 rpds-py-0.25.1 soupsieve-2.7 tokenizers-0.21.1 tzdata-2025.2 ujson-5.10.0 xxhash-3.5.0 yarl-1.20.1 zipp-3.23.0\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install -U \"mlflow[databricks]>=3.1.0\" langchain-community langchain-openai beautifulsoup4 langgraph dspy databricks-agents\n",
    "\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "694490e2-d139-4664-ad9c-4a27d499c8ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO: If necessary, change the catalog and schema name here\n",
    "CATALOG = \"workspace\"\n",
    "SCHEMA = \"default\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d222037-47e7-4fc7-9ab8-81749b096765",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.entities import Prompt\n",
    "mlflow.set_registry_uri(\"databricks-uc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6840a9d5-2fe7-4083-811d-f9310619f8ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1003, which is longer than the specified 1000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 13 documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1000, chunk_overlap=0\n",
    ")\n",
    "\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "docs = loader.load()\n",
    "\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "print(f\"Generated {len(split_docs)} documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d70420b-d21a-47c2-ac94-7b5b22b14529",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "mlflow_creds = mlflow.utils.databricks_utils.get_databricks_host_creds()\n",
    "llm = init_chat_model(\n",
    "    # \"databricks-llama-4-maverick\",\n",
    "    \"databricks-meta-llama-3-1-405b-instruct\",\n",
    "    model_provider=\"openai\",\n",
    "    api_key=mlflow_creds.token,\n",
    "    base_url=f\"{mlflow_creds.host}/serving-endpoints\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "591d4053-7ac0-4f94-b9b1-2704107377b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# First prompt for summarization.\n",
    "summary_prompt = mlflow.genai.register_prompt(\n",
    "    name=f\"{CATALOG}.{SCHEMA}.summary_prompt\",\n",
    "    template=\"Write a concise summary of the following:{{content}}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1aa74d01-1254-4ec1-831a-3fccb99acad4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "PromptVersion(name=workspace.default.summary_prompt, version=1, template=\"Write a concise summary of th...)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d2ba550-47ae-42a2-adba-4ae46cb46e17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "summary_chain = llm | StrOutputParser()\n",
    "\n",
    "@mlflow.trace()\n",
    "def call_summary_chain(content):\n",
    "  return summary_chain.invoke([HumanMessage(summary_prompt.format(content=content))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a321841-48c2-43e6-842e-df0cfb900426",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Second prompt for topic extraction.\n",
    "topic_prompt = mlflow.genai.register_prompt(name=f\"{CATALOG}.{SCHEMA}.topic_prompt\",\n",
    "                       template=\"\"\"\n",
    "The following is the summary:\n",
    "{{summary}}\n",
    "Extract the main topic in a few words.\n",
    "Return the response in JSON format: {\"topic\": \"...\"}\n",
    "\"\"\")\n",
    "\n",
    "topic_chain = llm | JsonOutputParser()\n",
    "\n",
    "@mlflow.trace()\n",
    "def call_topic_chain(summary):\n",
    "  return topic_chain.invoke([HumanMessage(topic_prompt.format(summary=summary))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02f6b1d4-0fa6-45f3-8abb-1ddf044b1894",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "@mlflow.trace\n",
    "def agent(content):\n",
    "  summary = call_summary_chain(content=content)\n",
    "  return call_topic_chain(summary=summary)[\"topic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6deb4496-bbfd-47af-af9d-904a35f61f78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Enable Autologging\n",
    "mlflow.langchain.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3956c1d0-6d2a-4a61-b49e-bfb6bc778412",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM-powered Autonomous Agents\nAI Planning and Self-Reflection\nmissing < at position 482 (line 1, column 483)\nbad escape \\l at position 4430 (line 28, column 180)\n'topic'\n'topic'\n'topic'\n'topic'\nSuper Mario Game\n'topic'\n'topic'\n'topic'\nLLM-powered Autonomous Agents\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "[\"tr-0eb1475a3bdf2dd5a95794f3219ec1eb\", \"tr-5f1c57bea6d5197e1c15ae406495e767\", \"tr-462dd004173bd3b9f17434c5f0ca1ad7\", \"tr-16e855eabcef7a8279abbbe3f9863302\", \"tr-cc07480d4b172f4c4db60b15756e0999\", \"tr-b4ebe25baa4ca90ccea3486c38fa8bdd\", \"tr-d0d2a03072127ab9b1530fb4defee860\", \"tr-09399bf2adb47ec7ca7450763dc554b6\", \"tr-10b2e71d21977e093ffec7373d2e1685\", \"tr-71a3842b32fbcc5399619dc9123caf6d\"]",
      "text/plain": [
       "[Trace(trace_id=tr-0eb1475a3bdf2dd5a95794f3219ec1eb), Trace(trace_id=tr-5f1c57bea6d5197e1c15ae406495e767), Trace(trace_id=tr-462dd004173bd3b9f17434c5f0ca1ad7), Trace(trace_id=tr-16e855eabcef7a8279abbbe3f9863302), Trace(trace_id=tr-cc07480d4b172f4c4db60b15756e0999), Trace(trace_id=tr-b4ebe25baa4ca90ccea3486c38fa8bdd), Trace(trace_id=tr-d0d2a03072127ab9b1530fb4defee860), Trace(trace_id=tr-09399bf2adb47ec7ca7450763dc554b6), Trace(trace_id=tr-10b2e71d21977e093ffec7373d2e1685), Trace(trace_id=tr-71a3842b32fbcc5399619dc9123caf6d)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run the agent\n",
    "for doc in split_docs:\n",
    "  try:\n",
    "    print(agent(doc.page_content))\n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f52445e-1437-48df-977a-294ab88cb3b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c649ff2b-3394-4c36-9886-ce0d618fd318",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# Extract the inputs and outputs of the second LLM call\n",
    "traces = mlflow.search_traces(extract_fields=[\n",
    "  \"call_topic_chain.inputs\",\n",
    "  \"call_topic_chain.outputs\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7293cb4c-c81a-41e7-a92a-0604fc52c696",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trace_id</th>\n",
       "      <th>trace</th>\n",
       "      <th>client_request_id</th>\n",
       "      <th>state</th>\n",
       "      <th>request_time</th>\n",
       "      <th>execution_duration</th>\n",
       "      <th>request</th>\n",
       "      <th>response</th>\n",
       "      <th>trace_metadata</th>\n",
       "      <th>tags</th>\n",
       "      <th>spans</th>\n",
       "      <th>assessments</th>\n",
       "      <th>call_topic_chain.inputs</th>\n",
       "      <th>call_topic_chain.outputs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tr-4047c21100faf7a16a91eb95c690e727</td>\n",
       "      <td>Trace(trace_id=tr-4047c21100faf7a16a91eb95c690...</td>\n",
       "      <td>tr-4047c21100faf7a16a91eb95c690e727</td>\n",
       "      <td>TraceState.OK</td>\n",
       "      <td>1750501933630</td>\n",
       "      <td>6076</td>\n",
       "      <td>{'content': 'Or\n",
       "@article{weng2023agent,\n",
       "  titl...</td>\n",
       "      <td>LLM-powered Autonomous Agents</td>\n",
       "      <td>{'mlflow.databricks.workspaceID': '17655129088...</td>\n",
       "      <td>{'mlflow.artifactLocation': 'dbfs:/databricks/...</td>\n",
       "      <td>[{'trace_id': 'QEfCEQD696FqkeuVxpDnJw==', 'spa...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'summary': 'The article discusses the concept...</td>\n",
       "      <td>{'topic': 'LLM-powered Autonomous Agents'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tr-d96123695e54adc72b80036c20a8d10b</td>\n",
       "      <td>Trace(trace_id=tr-d96123695e54adc72b80036c20a8...</td>\n",
       "      <td>tr-d96123695e54adc72b80036c20a8d10b</td>\n",
       "      <td>TraceState.ERROR</td>\n",
       "      <td>1750501929342</td>\n",
       "      <td>3990</td>\n",
       "      <td>{'content': 'Finite context length: The restri...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'mlflow.databricks.workspaceID': '17655129088...</td>\n",
       "      <td>{'mlflow.artifactLocation': 'dbfs:/databricks/...</td>\n",
       "      <td>[{'trace_id': '2WEjaV5UrccrgANsIKjRCw==', 'spa...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'summary': 'Here is a concise summary:\n",
       "\n",
       "LLM-p...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tr-124d7f6c158ef804b22206dfa219374c</td>\n",
       "      <td>Trace(trace_id=tr-124d7f6c158ef804b22206dfa219...</td>\n",
       "      <td>tr-124d7f6c158ef804b22206dfa219374c</td>\n",
       "      <td>TraceState.ERROR</td>\n",
       "      <td>1750501922995</td>\n",
       "      <td>6021</td>\n",
       "      <td>{'content': 'Conversatin samples:\n",
       "[\n",
       "  {\n",
       "    \"r...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'mlflow.databricks.workspaceID': '17655129088...</td>\n",
       "      <td>{'mlflow.artifactLocation': 'dbfs:/databricks/...</td>\n",
       "      <td>[{'trace_id': 'Ek1/bBWO+ASyIgbfohk3TA==', 'spa...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'summary': 'Here is a concise summary of the ...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tr-71a3842b32fbcc5399619dc9123caf6d</td>\n",
       "      <td>Trace(trace_id=tr-71a3842b32fbcc5399619dc9123c...</td>\n",
       "      <td>tr-71a3842b32fbcc5399619dc9123caf6d</td>\n",
       "      <td>TraceState.ERROR</td>\n",
       "      <td>1750501915653</td>\n",
       "      <td>7070</td>\n",
       "      <td>{'content': 'You will get instructions for cod...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'mlflow.databricks.workspaceID': '17655129088...</td>\n",
       "      <td>{'mlflow.artifactLocation': 'dbfs:/databricks/...</td>\n",
       "      <td>[{'trace_id': 'caOEKzL7zFOZYZ3JEjyvbQ==', 'spa...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'summary': 'Here is a concise summary:\n",
       "\n",
       "**Tas...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tr-10b2e71d21977e093ffec7373d2e1685</td>\n",
       "      <td>Trace(trace_id=tr-10b2e71d21977e093ffec7373d2e...</td>\n",
       "      <td>tr-10b2e71d21977e093ffec7373d2e1685</td>\n",
       "      <td>TraceState.OK</td>\n",
       "      <td>1750501908439</td>\n",
       "      <td>6940</td>\n",
       "      <td>{'content': 'You should only respond in JSON f...</td>\n",
       "      <td>Super Mario Game</td>\n",
       "      <td>{'mlflow.databricks.workspaceID': '17655129088...</td>\n",
       "      <td>{'mlflow.artifactLocation': 'dbfs:/databricks/...</td>\n",
       "      <td>[{'trace_id': 'ELLnHSGXfgk//sc3PS4WhQ==', 'spa...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'summary': 'Here is a summary of the conversa...</td>\n",
       "      <td>{'topic': 'Super Mario Game'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tr-09399bf2adb47ec7ca7450763dc554b6</td>\n",
       "      <td>Trace(trace_id=tr-09399bf2adb47ec7ca7450763dc5...</td>\n",
       "      <td>tr-09399bf2adb47ec7ca7450763dc554b6</td>\n",
       "      <td>TraceState.ERROR</td>\n",
       "      <td>1750501902566</td>\n",
       "      <td>5614</td>\n",
       "      <td>{'content': 'Commands:\n",
       "1. Google Search: \"goog...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'mlflow.databricks.workspaceID': '17655129088...</td>\n",
       "      <td>{'mlflow.artifactLocation': 'dbfs:/databricks/...</td>\n",
       "      <td>[{'trace_id': 'CTmb8q20fsfKdFB2PcVUtg==', 'spa...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'summary': 'The text outlines a set of 20 com...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tr-d0d2a03072127ab9b1530fb4defee860</td>\n",
       "      <td>Trace(trace_id=tr-d0d2a03072127ab9b1530fb4defe...</td>\n",
       "      <td>tr-d0d2a03072127ab9b1530fb4defee860</td>\n",
       "      <td>TraceState.ERROR</td>\n",
       "      <td>1750501895202</td>\n",
       "      <td>7057</td>\n",
       "      <td>{'content': 'inquired about current trends in ...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'mlflow.databricks.workspaceID': '17655129088...</td>\n",
       "      <td>{'mlflow.artifactLocation': 'dbfs:/databricks/...</td>\n",
       "      <td>[{'trace_id': '0NKgMHISermxUw+03v7oYA==', 'spa...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'summary': 'Here is a concise summary of the ...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tr-b4ebe25baa4ca90ccea3486c38fa8bdd</td>\n",
       "      <td>Trace(trace_id=tr-b4ebe25baa4ca90ccea3486c38fa...</td>\n",
       "      <td>tr-b4ebe25baa4ca90ccea3486c38fa8bdd</td>\n",
       "      <td>TraceState.ERROR</td>\n",
       "      <td>1750501886627</td>\n",
       "      <td>8253</td>\n",
       "      <td>{'content': '(3) Task execution: Expert models...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'mlflow.databricks.workspaceID': '17655129088...</td>\n",
       "      <td>{'mlflow.artifactLocation': 'dbfs:/databricks/...</td>\n",
       "      <td>[{'trace_id': 'tOviW6pMqQzOo0hsOPqL3Q==', 'spa...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'summary': 'Here is a concise summary of the ...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tr-cc07480d4b172f4c4db60b15756e0999</td>\n",
       "      <td>Trace(trace_id=tr-cc07480d4b172f4c4db60b15756e...</td>\n",
       "      <td>tr-cc07480d4b172f4c4db60b15756e0999</td>\n",
       "      <td>TraceState.ERROR</td>\n",
       "      <td>1750501879556</td>\n",
       "      <td>6831</td>\n",
       "      <td>{'content': 'Comparison of MIPS algorithms, me...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'mlflow.databricks.workspaceID': '17655129088...</td>\n",
       "      <td>{'mlflow.artifactLocation': 'dbfs:/databricks/...</td>\n",
       "      <td>[{'trace_id': 'zAdIDUsXL0xNtgsVdW4JmQ==', 'spa...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'summary': 'Here is a concise summary of the ...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tr-16e855eabcef7a8279abbbe3f9863302</td>\n",
       "      <td>Trace(trace_id=tr-16e855eabcef7a8279abbbe3f986...</td>\n",
       "      <td>tr-16e855eabcef7a8279abbbe3f9863302</td>\n",
       "      <td>TraceState.ERROR</td>\n",
       "      <td>1750501879276</td>\n",
       "      <td>5</td>\n",
       "      <td>{'content': 'Sensory Memory: This is the earli...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'mlflow.databricks.workspaceID': '17655129088...</td>\n",
       "      <td>{'mlflow.artifactLocation': 'dbfs:/databricks/...</td>\n",
       "      <td>[{'trace_id': 'FuhV6rzveoJ5q7vj+YYzAg==', 'spa...</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              trace_id  ...                    call_topic_chain.outputs\n",
       "0  tr-4047c21100faf7a16a91eb95c690e727  ...  {'topic': 'LLM-powered Autonomous Agents'}\n",
       "1  tr-d96123695e54adc72b80036c20a8d10b  ...                                          {}\n",
       "2  tr-124d7f6c158ef804b22206dfa219374c  ...                                          {}\n",
       "3  tr-71a3842b32fbcc5399619dc9123caf6d  ...                                          {}\n",
       "4  tr-10b2e71d21977e093ffec7373d2e1685  ...               {'topic': 'Super Mario Game'}\n",
       "5  tr-09399bf2adb47ec7ca7450763dc554b6  ...                                          {}\n",
       "6  tr-d0d2a03072127ab9b1530fb4defee860  ...                                          {}\n",
       "7  tr-b4ebe25baa4ca90ccea3486c38fa8bdd  ...                                          {}\n",
       "8  tr-cc07480d4b172f4c4db60b15756e0999  ...                                          {}\n",
       "9  tr-16e855eabcef7a8279abbbe3f9863302  ...                                        None\n",
       "\n",
       "[10 rows x 14 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traces.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b359b24-648c-49a8-a25a-634cd94fccc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.genai import datasets\n",
    "\n",
    "EVAL_DATASET_NAME=f\"{CATALOG}.{SCHEMA}.data\"\n",
    "dataset = datasets.create_dataset(EVAL_DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0550bf8e-c2d5-41dc-9a07-28f3770e9cb3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<mlflow.genai.datasets.evaluation_dataset.EvaluationDataset at 0xffff2c06ba10>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f671d45-89bf-475f-98e7-f910a95fc329",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<mlflow.genai.datasets.evaluation_dataset.EvaluationDataset at 0xffff2b57b410>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataset by treating the agent outputs as the default expectations.\n",
    "traces = traces.rename(\n",
    "    columns={\n",
    "      \"call_topic_chain.inputs\": \"inputs\",\n",
    "      \"call_topic_chain.outputs\": \"expectations\",\n",
    "    }\n",
    ")[[\"inputs\", \"expectations\"]]\n",
    "traces = traces.dropna()\n",
    "dataset.merge_records(traces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a9551dfb-ed60-4d0b-98dc-f364d7db7a66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b2cfbd0-00c9-4f67-ae27-0de25a5c4a40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<mlflow.genai.datasets.evaluation_dataset.EvaluationDataset at 0xffff2ae59f90>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = datasets.get_dataset(EVAL_DATASET_NAME)\n",
    "dataset.merge_records([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d3c5319-fda0-446f-b3cf-7ffc66d06804",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_record_id</th>\n",
       "      <th>inputs</th>\n",
       "      <th>expectations</th>\n",
       "      <th>source</th>\n",
       "      <th>tags</th>\n",
       "      <th>create_time</th>\n",
       "      <th>last_update_time</th>\n",
       "      <th>created_by</th>\n",
       "      <th>last_updated_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0db4e3cc-5799-4290-b93f-e688c3003e8f</td>\n",
       "      <td>{'summary': 'Here is a concise summary of the ...</td>\n",
       "      <td>{'topic': 'Autonomous Agents'}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-06-21T10:34:46.638Z</td>\n",
       "      <td>2025-06-21T10:34:46.638Z</td>\n",
       "      <td>isanakamishiro@gmail.com</td>\n",
       "      <td>isanakamishiro@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19b313e3-c2b7-44f6-96fc-ad402f5f2f97</td>\n",
       "      <td>{'summary': 'The article discusses the concept...</td>\n",
       "      <td>{'topic': 'LLM-powered Autonomous Agents'}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-06-21T10:34:46.638Z</td>\n",
       "      <td>2025-06-21T10:34:46.638Z</td>\n",
       "      <td>isanakamishiro@gmail.com</td>\n",
       "      <td>isanakamishiro@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29980eb3-82d4-4c98-a403-a5eb5b74140d</td>\n",
       "      <td>{'summary': 'Here is a concise summary of the ...</td>\n",
       "      <td>{'topic': 'AI models and applications'}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-06-21T10:34:46.638Z</td>\n",
       "      <td>2025-06-21T10:34:46.638Z</td>\n",
       "      <td>isanakamishiro@gmail.com</td>\n",
       "      <td>isanakamishiro@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2c2cf9ed-b87c-458b-a6df-89dacbe2fa69</td>\n",
       "      <td>{'summary': 'Here is a concise summary of the ...</td>\n",
       "      <td>{}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-06-21T10:34:46.638Z</td>\n",
       "      <td>2025-06-21T10:34:46.638Z</td>\n",
       "      <td>isanakamishiro@gmail.com</td>\n",
       "      <td>isanakamishiro@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2f51fcb7-2cb2-4d31-a2d2-0a3e4af780c3</td>\n",
       "      <td>{'summary': 'Here's a concise summary:\n",
       "\n",
       "The te...</td>\n",
       "      <td>{'topic': 'LLMs Tool Integration'}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-06-21T10:34:46.638Z</td>\n",
       "      <td>2025-06-21T10:34:46.638Z</td>\n",
       "      <td>isanakamishiro@gmail.com</td>\n",
       "      <td>isanakamishiro@gmail.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      dataset_record_id  ...           last_updated_by\n",
       "0  0db4e3cc-5799-4290-b93f-e688c3003e8f  ...  isanakamishiro@gmail.com\n",
       "1  19b313e3-c2b7-44f6-96fc-ad402f5f2f97  ...  isanakamishiro@gmail.com\n",
       "2  29980eb3-82d4-4c98-a403-a5eb5b74140d  ...  isanakamishiro@gmail.com\n",
       "3  2c2cf9ed-b87c-458b-a6df-89dacbe2fa69  ...  isanakamishiro@gmail.com\n",
       "4  2f51fcb7-2cb2-4d31-a2d2-0a3e4af780c3  ...  isanakamishiro@gmail.com\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.to_df()\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b4b2a75-60dc-4952-9e33-ad1b94b3910f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0652ed95-20cd-4b11-b389-0c218c8a6064",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages/mlflow/genai/optimize/base.py:130: FutureWarning: The `mlflow.load_prompt` API is moved to the `mlflow.genai` namespace. Please use `mlflow.genai.load_prompt` instead. The original API will be removed in the future release.\n  prompt: PromptVersion = load_prompt(prompt)\n2025/06/21 10:41:26 INFO mlflow.genai.optimize.optimizers.dspy_mipro_optimizer: Started optimizing prompt prompts:/workspace.default.qa/2. Please wait as this process typically takes several minutes, but can take longer with large datasets...\n2025/06/21 10:45:47 INFO mlflow.genai.optimize.optimizers.dspy_mipro_optimizer: Prompt optimization completed. Evaluation score did not change. Score 0.0\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages/mlflow/genai/optimize/optimizers/dspy_mipro_optimizer.py:116: FutureWarning: The `mlflow.register_prompt` API is moved to the `mlflow.genai` namespace. Please use `mlflow.genai.register_prompt` instead. The original API will be removed in the future release.\n  optimized_prompt = register_prompt(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"<system>\\nYour input fields are:\\n1. `question` (str):\\nYour output fields are:\\n1. `answer` (str):\\nAll interactions will be structured in the following way, with the appropriate values filled in.\\n\\nInputs will have the following structure:\\n\\n[[ ## question ## ]]\\n{question}\\n\\nOutputs will be a JSON object with the following fields.\\n\\n{\\n  \\\"answer\\\": \\\"{answer}\\\"\\n}\\nIn adhering to this structure, your objective is: \\n        Answer the question that will be provided.\\n</system>\\n\\n<user>\\n[[ ## question ## ]]\\n{{question}}\\n\\nRespond with a JSON object in the following order of fields: `answer`.\\n</user>\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mlflow\n",
    "from typing import Any\n",
    "from mlflow.genai.scorers import scorer\n",
    "from mlflow.genai.optimize import OptimizerConfig, LLMParams\n",
    "\n",
    "mlflow_creds = mlflow.utils.databricks_utils.get_databricks_host_creds()\n",
    "os.environ[\"OPENAI_API_KEY\"] = mlflow_creds.token\n",
    "\n",
    "\n",
    "@scorer\n",
    "def exact_match(expectations: dict[str, Any], outputs: dict[str, Any]) -> bool:\n",
    "    return expectations == outputs\n",
    "\n",
    "prompt = mlflow.genai.register_prompt(\n",
    "    name=f\"{CATALOG}.{SCHEMA}.qa\",\n",
    "    template=\"Answer the following question: {{question}}\",\n",
    ")\n",
    "\n",
    "result = mlflow.genai.optimize_prompt(\n",
    "    target_llm_params=LLMParams(\n",
    "        model_name=\"openai/databricks-meta-llama-3-1-405b-instruct\",\n",
    "        base_uri=f\"{mlflow_creds.host}/serving-endpoints\",\n",
    "    ),\n",
    "    train_data=[\n",
    "        {\"inputs\": {\"question\": f\"{i}+1\"}, \"expectations\": {\"answer\": f\"{i + 1}\"}}\n",
    "        for i in range(100)\n",
    "    ],\n",
    "    scorers=[exact_match],\n",
    "    prompt=prompt.uri,\n",
    "    optimizer_config=OptimizerConfig(num_instruction_candidates=5),\n",
    ")\n",
    "\n",
    "print(result.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2b9928b-d2a8-4745-a145-22f1ce69257e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "PromptVersion(name=workspace.default.qa, version=3, template=\"<system>\\nYour input fields a...)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91bca07e-4f77-4320-b706-15b76414468b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/21 10:50:14 INFO mlflow.genai.optimize.optimizers.dspy_mipro_optimizer: Started optimizing prompt prompts:/workspace.default.topic_prompt/2. Please wait as this process typically takes several minutes, but can take longer with large datasets...\n2025/06/21 10:50:14 INFO dspy.teleprompt.mipro_optimizer_v2: \n==> STEP 1: BOOTSTRAP FEWSHOT EXAMPLES <==\n2025/06/21 10:50:14 INFO dspy.teleprompt.mipro_optimizer_v2: These will be used as few-shot example candidates for our program and for creating instructions.\n\n2025/06/21 10:50:14 INFO dspy.teleprompt.mipro_optimizer_v2: Bootstrapping N=8 sets of demonstrations...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapping set 1/8\nBootstrapping set 2/8\nBootstrapping set 3/8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/5 [00:00<?, ?it/s]2025/06/21 10:50:14 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n\r 20%|██        | 1/5 [00:02<00:10,  2.61s/it]2025/06/21 10:50:17 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n\r 40%|████      | 2/5 [00:05<00:08,  2.81s/it]\r 40%|████      | 2/5 [00:05<00:08,  2.78s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\nBootstrapping set 4/8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/5 [00:00<?, ?it/s]2025/06/21 10:50:20 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n\r 20%|██        | 1/5 [00:01<00:07,  2.00s/it]\r 20%|██        | 1/5 [00:01<00:07,  2.00s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\nBootstrapping set 5/8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/5 [00:00<?, ?it/s]2025/06/21 10:50:22 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n\r 20%|██        | 1/5 [00:02<00:08,  2.11s/it]\r 20%|██        | 1/5 [00:02<00:08,  2.12s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\nBootstrapping set 6/8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/5 [00:00<?, ?it/s]2025/06/21 10:50:24 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n2025/06/21 10:50:24 ERROR dspy.teleprompt.bootstrap: Failed to run or to evaluate example Example({'summary': \"Here is a concise summary of the provided text:\\n\\n**Task Execution and Response Generation**\\n\\n* Expert models execute tasks and log results, which are then used to generate a response for the user.\\n* The response includes a straightforward answer to the user's request, followed by a description of the task process, analysis, and model inference results.\\n\\n**Challenges and Benchmarks**\\n\\n* To apply HuggingGPT in real-world scenarios, challenges such as efficiency improvement, stability, and long context windows need to be addressed.\\n* API-Bank is a benchmark that evaluates the performance of tool-augmented LLMs using 53 APIs and 264 annotated dialogues.\\n\\n**API-Bank Workflow**\\n\\n* LLMs make decisions on whether to call an API, identify the right API, and respond based on API results.\\n* The benchmark evaluates tool use capabilities at three levels: calling an API, retrieving an API, and planning API calls.\\n\\n**Case Studies**\\n\\n* ChemCrow is a domain-specific example of an LLM augmented with expert-designed tools for scientific discovery tasks.\\n* The study highlights the potential problem of using LLMs to evaluate their own performance in domains that require deep expertise.\\n* Another study demonstrates an LLM-empowered agent for scientific discovery that can use tools to browse the internet, execute code, and leverage other LLMs.\"}) (input_keys={'summary'}) with <function _DSPyOptimizer._convert_to_dspy_metric.<locals>.metric at 0xffff1eed0a40> due to Correctness scorer requires either `expected_response` or `expected_facts` in the `expectations` dictionary..\n\r 20%|██        | 1/5 [00:00<00:01,  2.52it/s]2025/06/21 10:50:24 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n\r 40%|████      | 2/5 [00:02<00:04,  1.65s/it]\r 40%|████      | 2/5 [00:02<00:04,  1.46s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\nBootstrapping set 7/8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/5 [00:00<?, ?it/s]2025/06/21 10:50:27 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n\r 20%|██        | 1/5 [00:02<00:09,  2.34s/it]\r 20%|██        | 1/5 [00:02<00:09,  2.34s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\nBootstrapping set 8/8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r  0%|          | 0/5 [00:00<?, ?it/s]2025/06/21 10:50:29 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n\r 20%|██        | 1/5 [00:02<00:10,  2.62s/it]2025/06/21 10:50:32 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n\r 40%|████      | 2/5 [00:04<00:07,  2.37s/it]\r 40%|████      | 2/5 [00:04<00:07,  2.41s/it]\n2025/06/21 10:50:34 INFO dspy.teleprompt.mipro_optimizer_v2: \n==> STEP 2: PROPOSE INSTRUCTION CANDIDATES <==\n2025/06/21 10:50:34 INFO dspy.teleprompt.mipro_optimizer_v2: We will use the few-shot examples from the previous step, a generated dataset summary, a summary of the program code, and a randomly selected prompting tip to propose instructions.\n2025/06/21 10:50:34 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/21 10:50:36 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n2025/06/21 10:50:38 INFO dspy.teleprompt.mipro_optimizer_v2: \nProposing N=8 instructions...\n\n2025/06/21 10:50:38 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n2025/06/21 10:50:38 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n2025/06/21 10:50:39 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n2025/06/21 10:50:40 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n2025/06/21 10:50:42 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n2025/06/21 10:50:44 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n2025/06/21 10:50:46 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n2025/06/21 10:50:48 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n2025/06/21 10:50:50 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n2025/06/21 10:50:51 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n2025/06/21 10:50:53 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n2025/06/21 10:50:55 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n2025/06/21 10:50:56 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n2025/06/21 10:50:59 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n2025/06/21 10:51:00 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-8398490772614388>, line 21\u001B[0m\n",
       "\u001B[1;32m     14\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\n",
       "\u001B[1;32m     15\u001B[0m         _correctness(inputs\u001B[38;5;241m=\u001B[39minputs, outputs\u001B[38;5;241m=\u001B[39moutputs, expectations\u001B[38;5;241m=\u001B[39mexpectations)\u001B[38;5;241m.\u001B[39mvalue\n",
       "\u001B[1;32m     16\u001B[0m         \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myes\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m     17\u001B[0m     )\n",
       "\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m# Optimize the prompt\u001B[39;00m\n",
       "\u001B[0;32m---> 21\u001B[0m result \u001B[38;5;241m=\u001B[39m mlflow\u001B[38;5;241m.\u001B[39mgenai\u001B[38;5;241m.\u001B[39moptimize_prompt(\n",
       "\u001B[1;32m     22\u001B[0m     target_llm_params\u001B[38;5;241m=\u001B[39mLLMParams(\n",
       "\u001B[1;32m     23\u001B[0m         model_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mopenai/databricks-meta-llama-3-3-70b-instruct\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m     24\u001B[0m         base_uri\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmlflow_creds\u001B[38;5;241m.\u001B[39mhost\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/serving-endpoints\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m     25\u001B[0m     ),\n",
       "\u001B[1;32m     26\u001B[0m     prompt\u001B[38;5;241m=\u001B[39mtopic_prompt,\n",
       "\u001B[1;32m     27\u001B[0m     train_data\u001B[38;5;241m=\u001B[39mdataset,\n",
       "\u001B[1;32m     28\u001B[0m     scorers\u001B[38;5;241m=\u001B[39m[correctness],\n",
       "\u001B[1;32m     29\u001B[0m     optimizer_config\u001B[38;5;241m=\u001B[39mOptimizerConfig(\n",
       "\u001B[1;32m     30\u001B[0m         num_instruction_candidates\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m8\u001B[39m,\n",
       "\u001B[1;32m     31\u001B[0m         max_few_show_examples\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n",
       "\u001B[1;32m     32\u001B[0m         verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n",
       "\u001B[1;32m     33\u001B[0m     ),\n",
       "\u001B[1;32m     34\u001B[0m )\n",
       "\u001B[1;32m     36\u001B[0m \u001B[38;5;66;03m# The optimized prompt is automatically registered as a new version\u001B[39;00m\n",
       "\u001B[1;32m     37\u001B[0m \u001B[38;5;66;03m# Open the prompt registry web site to check the new prompt\u001B[39;00m\n",
       "\u001B[1;32m     38\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe new prompt URI: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;241m.\u001B[39mprompt\u001B[38;5;241m.\u001B[39muri\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages/mlflow/genai/optimize/base.py:133\u001B[0m, in \u001B[0;36moptimize_prompt\u001B[0;34m(target_llm_params, prompt, train_data, scorers, objective, eval_data, optimizer_config)\u001B[0m\n",
       "\u001B[1;32m    130\u001B[0m     prompt: PromptVersion \u001B[38;5;241m=\u001B[39m load_prompt(prompt)\n",
       "\u001B[1;32m    132\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _maybe_start_autolog(optimizer_config, train_data, eval_data, prompt, target_llm_params):\n",
       "\u001B[0;32m--> 133\u001B[0m     optimized_prompt \u001B[38;5;241m=\u001B[39m optimzer\u001B[38;5;241m.\u001B[39moptimize(\n",
       "\u001B[1;32m    134\u001B[0m         prompt\u001B[38;5;241m=\u001B[39mprompt,\n",
       "\u001B[1;32m    135\u001B[0m         target_llm_params\u001B[38;5;241m=\u001B[39mtarget_llm_params,\n",
       "\u001B[1;32m    136\u001B[0m         train_data\u001B[38;5;241m=\u001B[39mtrain_data,\n",
       "\u001B[1;32m    137\u001B[0m         scorers\u001B[38;5;241m=\u001B[39mscorers,\n",
       "\u001B[1;32m    138\u001B[0m         objective\u001B[38;5;241m=\u001B[39mobjective,\n",
       "\u001B[1;32m    139\u001B[0m         eval_data\u001B[38;5;241m=\u001B[39meval_data,\n",
       "\u001B[1;32m    140\u001B[0m     )\n",
       "\u001B[1;32m    142\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m PromptOptimizationResult(prompt\u001B[38;5;241m=\u001B[39moptimized_prompt)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages/mlflow/genai/optimize/optimizers/dspy_mipro_optimizer.py:100\u001B[0m, in \u001B[0;36m_DSPyMIPROv2Optimizer.optimize\u001B[0;34m(self, prompt, target_llm_params, train_data, scorers, objective, eval_data)\u001B[0m\n",
       "\u001B[1;32m     98\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m dspy\u001B[38;5;241m.\u001B[39mcontext(lm\u001B[38;5;241m=\u001B[39mlm, adapter\u001B[38;5;241m=\u001B[39madapter, callbacks\u001B[38;5;241m=\u001B[39mcallbacks):\n",
       "\u001B[1;32m     99\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_suppress_stdout_stderr():\n",
       "\u001B[0;32m--> 100\u001B[0m         optimized_program \u001B[38;5;241m=\u001B[39m optimizer\u001B[38;5;241m.\u001B[39mcompile(\n",
       "\u001B[1;32m    101\u001B[0m             program,\n",
       "\u001B[1;32m    102\u001B[0m             trainset\u001B[38;5;241m=\u001B[39mtrain_data,\n",
       "\u001B[1;32m    103\u001B[0m             valset\u001B[38;5;241m=\u001B[39meval_data,\n",
       "\u001B[1;32m    104\u001B[0m             num_trials\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_num_trials(num_candidates),\n",
       "\u001B[1;32m    105\u001B[0m             minibatch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_minibatch_size(train_data, eval_data),\n",
       "\u001B[1;32m    106\u001B[0m             requires_permission_to_run\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n",
       "\u001B[1;32m    107\u001B[0m         )\n",
       "\u001B[1;32m    109\u001B[0m     template \u001B[38;5;241m=\u001B[39m format_optimized_prompt(\n",
       "\u001B[1;32m    110\u001B[0m         program\u001B[38;5;241m=\u001B[39moptimized_program,\n",
       "\u001B[1;32m    111\u001B[0m         input_fields\u001B[38;5;241m=\u001B[39minput_fields,\n",
       "\u001B[1;32m    112\u001B[0m     )\n",
       "\u001B[1;32m    114\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_display_optimization_result(optimized_program)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages/dspy/teleprompt/mipro_optimizer_v2.py:188\u001B[0m, in \u001B[0;36mMIPROv2.compile\u001B[0;34m(self, student, trainset, teacher, valset, num_trials, max_bootstrapped_demos, max_labeled_demos, seed, minibatch, minibatch_size, minibatch_full_eval_steps, program_aware_proposer, data_aware_proposer, view_data_batch_size, tip_aware_proposer, fewshot_aware_proposer, requires_permission_to_run, provide_traceback)\u001B[0m\n",
       "\u001B[1;32m    185\u001B[0m demo_candidates \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bootstrap_fewshot_examples(program, trainset, seed, teacher)\n",
       "\u001B[1;32m    187\u001B[0m \u001B[38;5;66;03m# Step 2: Propose instruction candidates\u001B[39;00m\n",
       "\u001B[0;32m--> 188\u001B[0m instruction_candidates \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_propose_instructions(\n",
       "\u001B[1;32m    189\u001B[0m     program,\n",
       "\u001B[1;32m    190\u001B[0m     trainset,\n",
       "\u001B[1;32m    191\u001B[0m     demo_candidates,\n",
       "\u001B[1;32m    192\u001B[0m     view_data_batch_size,\n",
       "\u001B[1;32m    193\u001B[0m     program_aware_proposer,\n",
       "\u001B[1;32m    194\u001B[0m     data_aware_proposer,\n",
       "\u001B[1;32m    195\u001B[0m     tip_aware_proposer,\n",
       "\u001B[1;32m    196\u001B[0m     fewshot_aware_proposer,\n",
       "\u001B[1;32m    197\u001B[0m )\n",
       "\u001B[1;32m    199\u001B[0m \u001B[38;5;66;03m# If zero-shot, discard demos\u001B[39;00m\n",
       "\u001B[1;32m    200\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m zeroshot_opt:\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages/dspy/teleprompt/mipro_optimizer_v2.py:469\u001B[0m, in \u001B[0;36mMIPROv2._propose_instructions\u001B[0;34m(self, program, trainset, demo_candidates, view_data_batch_size, program_aware_proposer, data_aware_proposer, tip_aware_proposer, fewshot_aware_proposer)\u001B[0m\n",
       "\u001B[1;32m    451\u001B[0m proposer \u001B[38;5;241m=\u001B[39m GroundedProposer(\n",
       "\u001B[1;32m    452\u001B[0m     program\u001B[38;5;241m=\u001B[39mprogram,\n",
       "\u001B[1;32m    453\u001B[0m     trainset\u001B[38;5;241m=\u001B[39mtrainset,\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m    465\u001B[0m     rng\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrng,\n",
       "\u001B[1;32m    466\u001B[0m )\n",
       "\u001B[1;32m    468\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mProposing N=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_instruct_candidates\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m instructions...\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[0;32m--> 469\u001B[0m instruction_candidates \u001B[38;5;241m=\u001B[39m proposer\u001B[38;5;241m.\u001B[39mpropose_instructions_for_program(\n",
       "\u001B[1;32m    470\u001B[0m     trainset\u001B[38;5;241m=\u001B[39mtrainset,\n",
       "\u001B[1;32m    471\u001B[0m     program\u001B[38;5;241m=\u001B[39mprogram,\n",
       "\u001B[1;32m    472\u001B[0m     demo_candidates\u001B[38;5;241m=\u001B[39mdemo_candidates,\n",
       "\u001B[1;32m    473\u001B[0m     N\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_instruct_candidates,\n",
       "\u001B[1;32m    474\u001B[0m     T\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minit_temperature,\n",
       "\u001B[1;32m    475\u001B[0m     trial_logs\u001B[38;5;241m=\u001B[39m{},\n",
       "\u001B[1;32m    476\u001B[0m )\n",
       "\u001B[1;32m    478\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, pred \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(program\u001B[38;5;241m.\u001B[39mpredictors()):\n",
       "\u001B[1;32m    479\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mProposed Instructions for Predictor \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages/dspy/propose/grounded_proposer.py:374\u001B[0m, in \u001B[0;36mGroundedProposer.propose_instructions_for_program\u001B[0;34m(self, trainset, program, demo_candidates, trial_logs, N, T)\u001B[0m\n",
       "\u001B[1;32m    370\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose:\n",
       "\u001B[1;32m    371\u001B[0m                 \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSelected tip: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mselected_tip_key\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m    373\u001B[0m         proposed_instructions[pred_i]\u001B[38;5;241m.\u001B[39mappend(\n",
       "\u001B[0;32m--> 374\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpropose_instruction_for_predictor(\n",
       "\u001B[1;32m    375\u001B[0m                 program\u001B[38;5;241m=\u001B[39mprogram,\n",
       "\u001B[1;32m    376\u001B[0m                 predictor\u001B[38;5;241m=\u001B[39mpredictor,\n",
       "\u001B[1;32m    377\u001B[0m                 pred_i\u001B[38;5;241m=\u001B[39mpred_i,\n",
       "\u001B[1;32m    378\u001B[0m                 T\u001B[38;5;241m=\u001B[39mT,\n",
       "\u001B[1;32m    379\u001B[0m                 demo_candidates\u001B[38;5;241m=\u001B[39mdemo_candidates,\n",
       "\u001B[1;32m    380\u001B[0m                 demo_set_i\u001B[38;5;241m=\u001B[39mdemo_set_i,\n",
       "\u001B[1;32m    381\u001B[0m                 trial_logs\u001B[38;5;241m=\u001B[39mtrial_logs,\n",
       "\u001B[1;32m    382\u001B[0m                 tip\u001B[38;5;241m=\u001B[39mselected_tip,\n",
       "\u001B[1;32m    383\u001B[0m             ),\n",
       "\u001B[1;32m    384\u001B[0m         )\n",
       "\u001B[1;32m    386\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m proposed_instructions\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages/dspy/propose/grounded_proposer.py:425\u001B[0m, in \u001B[0;36mGroundedProposer.propose_instruction_for_predictor\u001B[0;34m(self, program, predictor, pred_i, T, demo_candidates, demo_set_i, trial_logs, tip)\u001B[0m\n",
       "\u001B[1;32m    423\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m dspy\u001B[38;5;241m.\u001B[39msettings\u001B[38;5;241m.\u001B[39mcontext(lm\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprompt_model):\n",
       "\u001B[1;32m    424\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprompt_model\u001B[38;5;241m.\u001B[39mkwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtemperature\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m modified_temp\n",
       "\u001B[0;32m--> 425\u001B[0m     proposed_instruction \u001B[38;5;241m=\u001B[39m instruction_generator\u001B[38;5;241m.\u001B[39mforward(\n",
       "\u001B[1;32m    426\u001B[0m         demo_candidates\u001B[38;5;241m=\u001B[39mdemo_candidates,\n",
       "\u001B[1;32m    427\u001B[0m         pred_i\u001B[38;5;241m=\u001B[39mpred_i,\n",
       "\u001B[1;32m    428\u001B[0m         demo_set_i\u001B[38;5;241m=\u001B[39mdemo_set_i,\n",
       "\u001B[1;32m    429\u001B[0m         program\u001B[38;5;241m=\u001B[39mprogram,\n",
       "\u001B[1;32m    430\u001B[0m         data_summary\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata_summary,\n",
       "\u001B[1;32m    431\u001B[0m         previous_instructions\u001B[38;5;241m=\u001B[39minstruction_history,\n",
       "\u001B[1;32m    432\u001B[0m         num_demos_in_context \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_demos_in_context,\n",
       "\u001B[1;32m    433\u001B[0m         tip\u001B[38;5;241m=\u001B[39mtip,\n",
       "\u001B[1;32m    434\u001B[0m     )\u001B[38;5;241m.\u001B[39mproposed_instruction\n",
       "\u001B[1;32m    435\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprompt_model\u001B[38;5;241m.\u001B[39mkwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtemperature\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m original_temp\n",
       "\u001B[1;32m    437\u001B[0m \u001B[38;5;66;03m# Log the trace used to generate the new instruction, along with the new instruction itself\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages/dspy/propose/grounded_proposer.py:265\u001B[0m, in \u001B[0;36mGenerateModuleInstruction.forward\u001B[0;34m(self, demo_candidates, pred_i, demo_set_i, program, previous_instructions, data_summary, num_demos_in_context, tip)\u001B[0m\n",
       "\u001B[1;32m    251\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtask_demos \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtask_demos\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m    253\u001B[0m instruct \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgenerate_module_instruction(\n",
       "\u001B[1;32m    254\u001B[0m     dataset_description\u001B[38;5;241m=\u001B[39mdata_summary,\n",
       "\u001B[1;32m    255\u001B[0m     program_code\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprogram_code_string,\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m    262\u001B[0m     previous_instructions\u001B[38;5;241m=\u001B[39mprevious_instructions,\n",
       "\u001B[1;32m    263\u001B[0m )\n",
       "\u001B[0;32m--> 265\u001B[0m proposed_instruction \u001B[38;5;241m=\u001B[39m strip_prefix(instruct\u001B[38;5;241m.\u001B[39mproposed_instruction)\n",
       "\u001B[1;32m    267\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m dspy\u001B[38;5;241m.\u001B[39mPrediction(proposed_instruction\u001B[38;5;241m=\u001B[39mproposed_instruction)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages/dspy/propose/utils.py:19\u001B[0m, in \u001B[0;36mstrip_prefix\u001B[0;34m(text)\u001B[0m\n",
       "\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstrip_prefix\u001B[39m(text):\n",
       "\u001B[1;32m     18\u001B[0m     pattern \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m^[\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124m*\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124ms]*(([\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;130;01m\\'\u001B[39;00m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124m-]+\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124ms+)\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m0,4}[\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;130;01m\\'\u001B[39;00m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124m-]+):\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124ms*\u001B[39m\u001B[38;5;124m'\u001B[39m\n",
       "\u001B[0;32m---> 19\u001B[0m     modified_text \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(pattern, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m, text)\n",
       "\u001B[1;32m     20\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m modified_text\u001B[38;5;241m.\u001B[39mstrip(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/usr/lib/python3.11/re/__init__.py:185\u001B[0m, in \u001B[0;36msub\u001B[0;34m(pattern, repl, string, count, flags)\u001B[0m\n",
       "\u001B[1;32m    178\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msub\u001B[39m(pattern, repl, string, count\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, flags\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m):\n",
       "\u001B[1;32m    179\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Return the string obtained by replacing the leftmost\u001B[39;00m\n",
       "\u001B[1;32m    180\u001B[0m \u001B[38;5;124;03m    non-overlapping occurrences of the pattern in string by the\u001B[39;00m\n",
       "\u001B[1;32m    181\u001B[0m \u001B[38;5;124;03m    replacement repl.  repl can be either a string or a callable;\u001B[39;00m\n",
       "\u001B[1;32m    182\u001B[0m \u001B[38;5;124;03m    if a string, backslash escapes in it are processed.  If it is\u001B[39;00m\n",
       "\u001B[1;32m    183\u001B[0m \u001B[38;5;124;03m    a callable, it's passed the Match object and must return\u001B[39;00m\n",
       "\u001B[1;32m    184\u001B[0m \u001B[38;5;124;03m    a replacement string to be used.\"\"\"\u001B[39;00m\n",
       "\u001B[0;32m--> 185\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _compile(pattern, flags)\u001B[38;5;241m.\u001B[39msub(repl, string, count)\n",
       "\n",
       "\u001B[0;31mTypeError\u001B[0m: expected string or bytes-like object, got 'NoneType'"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "TypeError",
        "evalue": "expected string or bytes-like object, got 'NoneType'"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>TypeError</span>: expected string or bytes-like object, got 'NoneType'"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
        "File \u001B[0;32m<command-8398490772614388>, line 21\u001B[0m\n\u001B[1;32m     14\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[1;32m     15\u001B[0m         _correctness(inputs\u001B[38;5;241m=\u001B[39minputs, outputs\u001B[38;5;241m=\u001B[39moutputs, expectations\u001B[38;5;241m=\u001B[39mexpectations)\u001B[38;5;241m.\u001B[39mvalue\n\u001B[1;32m     16\u001B[0m         \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myes\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     17\u001B[0m     )\n\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m# Optimize the prompt\u001B[39;00m\n\u001B[0;32m---> 21\u001B[0m result \u001B[38;5;241m=\u001B[39m mlflow\u001B[38;5;241m.\u001B[39mgenai\u001B[38;5;241m.\u001B[39moptimize_prompt(\n\u001B[1;32m     22\u001B[0m     target_llm_params\u001B[38;5;241m=\u001B[39mLLMParams(\n\u001B[1;32m     23\u001B[0m         model_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mopenai/databricks-meta-llama-3-3-70b-instruct\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     24\u001B[0m         base_uri\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmlflow_creds\u001B[38;5;241m.\u001B[39mhost\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/serving-endpoints\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     25\u001B[0m     ),\n\u001B[1;32m     26\u001B[0m     prompt\u001B[38;5;241m=\u001B[39mtopic_prompt,\n\u001B[1;32m     27\u001B[0m     train_data\u001B[38;5;241m=\u001B[39mdataset,\n\u001B[1;32m     28\u001B[0m     scorers\u001B[38;5;241m=\u001B[39m[correctness],\n\u001B[1;32m     29\u001B[0m     optimizer_config\u001B[38;5;241m=\u001B[39mOptimizerConfig(\n\u001B[1;32m     30\u001B[0m         num_instruction_candidates\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m8\u001B[39m,\n\u001B[1;32m     31\u001B[0m         max_few_show_examples\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[1;32m     32\u001B[0m         verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m     33\u001B[0m     ),\n\u001B[1;32m     34\u001B[0m )\n\u001B[1;32m     36\u001B[0m \u001B[38;5;66;03m# The optimized prompt is automatically registered as a new version\u001B[39;00m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;66;03m# Open the prompt registry web site to check the new prompt\u001B[39;00m\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe new prompt URI: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;241m.\u001B[39mprompt\u001B[38;5;241m.\u001B[39muri\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages/mlflow/genai/optimize/base.py:133\u001B[0m, in \u001B[0;36moptimize_prompt\u001B[0;34m(target_llm_params, prompt, train_data, scorers, objective, eval_data, optimizer_config)\u001B[0m\n\u001B[1;32m    130\u001B[0m     prompt: PromptVersion \u001B[38;5;241m=\u001B[39m load_prompt(prompt)\n\u001B[1;32m    132\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _maybe_start_autolog(optimizer_config, train_data, eval_data, prompt, target_llm_params):\n\u001B[0;32m--> 133\u001B[0m     optimized_prompt \u001B[38;5;241m=\u001B[39m optimzer\u001B[38;5;241m.\u001B[39moptimize(\n\u001B[1;32m    134\u001B[0m         prompt\u001B[38;5;241m=\u001B[39mprompt,\n\u001B[1;32m    135\u001B[0m         target_llm_params\u001B[38;5;241m=\u001B[39mtarget_llm_params,\n\u001B[1;32m    136\u001B[0m         train_data\u001B[38;5;241m=\u001B[39mtrain_data,\n\u001B[1;32m    137\u001B[0m         scorers\u001B[38;5;241m=\u001B[39mscorers,\n\u001B[1;32m    138\u001B[0m         objective\u001B[38;5;241m=\u001B[39mobjective,\n\u001B[1;32m    139\u001B[0m         eval_data\u001B[38;5;241m=\u001B[39meval_data,\n\u001B[1;32m    140\u001B[0m     )\n\u001B[1;32m    142\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m PromptOptimizationResult(prompt\u001B[38;5;241m=\u001B[39moptimized_prompt)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages/mlflow/genai/optimize/optimizers/dspy_mipro_optimizer.py:100\u001B[0m, in \u001B[0;36m_DSPyMIPROv2Optimizer.optimize\u001B[0;34m(self, prompt, target_llm_params, train_data, scorers, objective, eval_data)\u001B[0m\n\u001B[1;32m     98\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m dspy\u001B[38;5;241m.\u001B[39mcontext(lm\u001B[38;5;241m=\u001B[39mlm, adapter\u001B[38;5;241m=\u001B[39madapter, callbacks\u001B[38;5;241m=\u001B[39mcallbacks):\n\u001B[1;32m     99\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_suppress_stdout_stderr():\n\u001B[0;32m--> 100\u001B[0m         optimized_program \u001B[38;5;241m=\u001B[39m optimizer\u001B[38;5;241m.\u001B[39mcompile(\n\u001B[1;32m    101\u001B[0m             program,\n\u001B[1;32m    102\u001B[0m             trainset\u001B[38;5;241m=\u001B[39mtrain_data,\n\u001B[1;32m    103\u001B[0m             valset\u001B[38;5;241m=\u001B[39meval_data,\n\u001B[1;32m    104\u001B[0m             num_trials\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_num_trials(num_candidates),\n\u001B[1;32m    105\u001B[0m             minibatch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_minibatch_size(train_data, eval_data),\n\u001B[1;32m    106\u001B[0m             requires_permission_to_run\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    107\u001B[0m         )\n\u001B[1;32m    109\u001B[0m     template \u001B[38;5;241m=\u001B[39m format_optimized_prompt(\n\u001B[1;32m    110\u001B[0m         program\u001B[38;5;241m=\u001B[39moptimized_program,\n\u001B[1;32m    111\u001B[0m         input_fields\u001B[38;5;241m=\u001B[39minput_fields,\n\u001B[1;32m    112\u001B[0m     )\n\u001B[1;32m    114\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_display_optimization_result(optimized_program)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages/dspy/teleprompt/mipro_optimizer_v2.py:188\u001B[0m, in \u001B[0;36mMIPROv2.compile\u001B[0;34m(self, student, trainset, teacher, valset, num_trials, max_bootstrapped_demos, max_labeled_demos, seed, minibatch, minibatch_size, minibatch_full_eval_steps, program_aware_proposer, data_aware_proposer, view_data_batch_size, tip_aware_proposer, fewshot_aware_proposer, requires_permission_to_run, provide_traceback)\u001B[0m\n\u001B[1;32m    185\u001B[0m demo_candidates \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bootstrap_fewshot_examples(program, trainset, seed, teacher)\n\u001B[1;32m    187\u001B[0m \u001B[38;5;66;03m# Step 2: Propose instruction candidates\u001B[39;00m\n\u001B[0;32m--> 188\u001B[0m instruction_candidates \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_propose_instructions(\n\u001B[1;32m    189\u001B[0m     program,\n\u001B[1;32m    190\u001B[0m     trainset,\n\u001B[1;32m    191\u001B[0m     demo_candidates,\n\u001B[1;32m    192\u001B[0m     view_data_batch_size,\n\u001B[1;32m    193\u001B[0m     program_aware_proposer,\n\u001B[1;32m    194\u001B[0m     data_aware_proposer,\n\u001B[1;32m    195\u001B[0m     tip_aware_proposer,\n\u001B[1;32m    196\u001B[0m     fewshot_aware_proposer,\n\u001B[1;32m    197\u001B[0m )\n\u001B[1;32m    199\u001B[0m \u001B[38;5;66;03m# If zero-shot, discard demos\u001B[39;00m\n\u001B[1;32m    200\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m zeroshot_opt:\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages/dspy/teleprompt/mipro_optimizer_v2.py:469\u001B[0m, in \u001B[0;36mMIPROv2._propose_instructions\u001B[0;34m(self, program, trainset, demo_candidates, view_data_batch_size, program_aware_proposer, data_aware_proposer, tip_aware_proposer, fewshot_aware_proposer)\u001B[0m\n\u001B[1;32m    451\u001B[0m proposer \u001B[38;5;241m=\u001B[39m GroundedProposer(\n\u001B[1;32m    452\u001B[0m     program\u001B[38;5;241m=\u001B[39mprogram,\n\u001B[1;32m    453\u001B[0m     trainset\u001B[38;5;241m=\u001B[39mtrainset,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    465\u001B[0m     rng\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrng,\n\u001B[1;32m    466\u001B[0m )\n\u001B[1;32m    468\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mProposing N=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_instruct_candidates\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m instructions...\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 469\u001B[0m instruction_candidates \u001B[38;5;241m=\u001B[39m proposer\u001B[38;5;241m.\u001B[39mpropose_instructions_for_program(\n\u001B[1;32m    470\u001B[0m     trainset\u001B[38;5;241m=\u001B[39mtrainset,\n\u001B[1;32m    471\u001B[0m     program\u001B[38;5;241m=\u001B[39mprogram,\n\u001B[1;32m    472\u001B[0m     demo_candidates\u001B[38;5;241m=\u001B[39mdemo_candidates,\n\u001B[1;32m    473\u001B[0m     N\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_instruct_candidates,\n\u001B[1;32m    474\u001B[0m     T\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minit_temperature,\n\u001B[1;32m    475\u001B[0m     trial_logs\u001B[38;5;241m=\u001B[39m{},\n\u001B[1;32m    476\u001B[0m )\n\u001B[1;32m    478\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, pred \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(program\u001B[38;5;241m.\u001B[39mpredictors()):\n\u001B[1;32m    479\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mProposed Instructions for Predictor \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages/dspy/propose/grounded_proposer.py:374\u001B[0m, in \u001B[0;36mGroundedProposer.propose_instructions_for_program\u001B[0;34m(self, trainset, program, demo_candidates, trial_logs, N, T)\u001B[0m\n\u001B[1;32m    370\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose:\n\u001B[1;32m    371\u001B[0m                 \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSelected tip: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mselected_tip_key\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    373\u001B[0m         proposed_instructions[pred_i]\u001B[38;5;241m.\u001B[39mappend(\n\u001B[0;32m--> 374\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpropose_instruction_for_predictor(\n\u001B[1;32m    375\u001B[0m                 program\u001B[38;5;241m=\u001B[39mprogram,\n\u001B[1;32m    376\u001B[0m                 predictor\u001B[38;5;241m=\u001B[39mpredictor,\n\u001B[1;32m    377\u001B[0m                 pred_i\u001B[38;5;241m=\u001B[39mpred_i,\n\u001B[1;32m    378\u001B[0m                 T\u001B[38;5;241m=\u001B[39mT,\n\u001B[1;32m    379\u001B[0m                 demo_candidates\u001B[38;5;241m=\u001B[39mdemo_candidates,\n\u001B[1;32m    380\u001B[0m                 demo_set_i\u001B[38;5;241m=\u001B[39mdemo_set_i,\n\u001B[1;32m    381\u001B[0m                 trial_logs\u001B[38;5;241m=\u001B[39mtrial_logs,\n\u001B[1;32m    382\u001B[0m                 tip\u001B[38;5;241m=\u001B[39mselected_tip,\n\u001B[1;32m    383\u001B[0m             ),\n\u001B[1;32m    384\u001B[0m         )\n\u001B[1;32m    386\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m proposed_instructions\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages/dspy/propose/grounded_proposer.py:425\u001B[0m, in \u001B[0;36mGroundedProposer.propose_instruction_for_predictor\u001B[0;34m(self, program, predictor, pred_i, T, demo_candidates, demo_set_i, trial_logs, tip)\u001B[0m\n\u001B[1;32m    423\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m dspy\u001B[38;5;241m.\u001B[39msettings\u001B[38;5;241m.\u001B[39mcontext(lm\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprompt_model):\n\u001B[1;32m    424\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprompt_model\u001B[38;5;241m.\u001B[39mkwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtemperature\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m modified_temp\n\u001B[0;32m--> 425\u001B[0m     proposed_instruction \u001B[38;5;241m=\u001B[39m instruction_generator\u001B[38;5;241m.\u001B[39mforward(\n\u001B[1;32m    426\u001B[0m         demo_candidates\u001B[38;5;241m=\u001B[39mdemo_candidates,\n\u001B[1;32m    427\u001B[0m         pred_i\u001B[38;5;241m=\u001B[39mpred_i,\n\u001B[1;32m    428\u001B[0m         demo_set_i\u001B[38;5;241m=\u001B[39mdemo_set_i,\n\u001B[1;32m    429\u001B[0m         program\u001B[38;5;241m=\u001B[39mprogram,\n\u001B[1;32m    430\u001B[0m         data_summary\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata_summary,\n\u001B[1;32m    431\u001B[0m         previous_instructions\u001B[38;5;241m=\u001B[39minstruction_history,\n\u001B[1;32m    432\u001B[0m         num_demos_in_context \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_demos_in_context,\n\u001B[1;32m    433\u001B[0m         tip\u001B[38;5;241m=\u001B[39mtip,\n\u001B[1;32m    434\u001B[0m     )\u001B[38;5;241m.\u001B[39mproposed_instruction\n\u001B[1;32m    435\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprompt_model\u001B[38;5;241m.\u001B[39mkwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtemperature\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m original_temp\n\u001B[1;32m    437\u001B[0m \u001B[38;5;66;03m# Log the trace used to generate the new instruction, along with the new instruction itself\u001B[39;00m\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages/dspy/propose/grounded_proposer.py:265\u001B[0m, in \u001B[0;36mGenerateModuleInstruction.forward\u001B[0;34m(self, demo_candidates, pred_i, demo_set_i, program, previous_instructions, data_summary, num_demos_in_context, tip)\u001B[0m\n\u001B[1;32m    251\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtask_demos \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtask_demos\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    253\u001B[0m instruct \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgenerate_module_instruction(\n\u001B[1;32m    254\u001B[0m     dataset_description\u001B[38;5;241m=\u001B[39mdata_summary,\n\u001B[1;32m    255\u001B[0m     program_code\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprogram_code_string,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    262\u001B[0m     previous_instructions\u001B[38;5;241m=\u001B[39mprevious_instructions,\n\u001B[1;32m    263\u001B[0m )\n\u001B[0;32m--> 265\u001B[0m proposed_instruction \u001B[38;5;241m=\u001B[39m strip_prefix(instruct\u001B[38;5;241m.\u001B[39mproposed_instruction)\n\u001B[1;32m    267\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m dspy\u001B[38;5;241m.\u001B[39mPrediction(proposed_instruction\u001B[38;5;241m=\u001B[39mproposed_instruction)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-5aca0c91-07e2-4c13-8e3e-635034b4a89e/lib/python3.11/site-packages/dspy/propose/utils.py:19\u001B[0m, in \u001B[0;36mstrip_prefix\u001B[0;34m(text)\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstrip_prefix\u001B[39m(text):\n\u001B[1;32m     18\u001B[0m     pattern \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m^[\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124m*\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124ms]*(([\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;130;01m\\'\u001B[39;00m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124m-]+\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124ms+)\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m0,4}[\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;130;01m\\'\u001B[39;00m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124m-]+):\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124ms*\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m---> 19\u001B[0m     modified_text \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(pattern, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m, text)\n\u001B[1;32m     20\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m modified_text\u001B[38;5;241m.\u001B[39mstrip(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
        "File \u001B[0;32m/usr/lib/python3.11/re/__init__.py:185\u001B[0m, in \u001B[0;36msub\u001B[0;34m(pattern, repl, string, count, flags)\u001B[0m\n\u001B[1;32m    178\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msub\u001B[39m(pattern, repl, string, count\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, flags\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m):\n\u001B[1;32m    179\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Return the string obtained by replacing the leftmost\u001B[39;00m\n\u001B[1;32m    180\u001B[0m \u001B[38;5;124;03m    non-overlapping occurrences of the pattern in string by the\u001B[39;00m\n\u001B[1;32m    181\u001B[0m \u001B[38;5;124;03m    replacement repl.  repl can be either a string or a callable;\u001B[39;00m\n\u001B[1;32m    182\u001B[0m \u001B[38;5;124;03m    if a string, backslash escapes in it are processed.  If it is\u001B[39;00m\n\u001B[1;32m    183\u001B[0m \u001B[38;5;124;03m    a callable, it's passed the Match object and must return\u001B[39;00m\n\u001B[1;32m    184\u001B[0m \u001B[38;5;124;03m    a replacement string to be used.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 185\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _compile(pattern, flags)\u001B[38;5;241m.\u001B[39msub(repl, string, count)\n",
        "\u001B[0;31mTypeError\u001B[0m: expected string or bytes-like object, got 'NoneType'"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from typing import Any\n",
    "import mlflow\n",
    "from mlflow.genai.scorers import Correctness\n",
    "from mlflow.genai.optimize import OptimizerConfig, LLMParams\n",
    "from mlflow.genai.scorers import scorer\n",
    "\n",
    "_correctness = Correctness()\n",
    "\n",
    "\n",
    "@scorer\n",
    "def correctness(inputs, outputs, expectations):\n",
    "    expectations = {\"expected_response\": expectations.get(\"topic\")}\n",
    "    return (\n",
    "        _correctness(inputs=inputs, outputs=outputs, expectations=expectations).value\n",
    "        == \"yes\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Optimize the prompt\n",
    "result = mlflow.genai.optimize_prompt(\n",
    "    target_llm_params=LLMParams(\n",
    "        model_name=\"openai/databricks-meta-llama-3-3-70b-instruct\",\n",
    "        base_uri=f\"{mlflow_creds.host}/serving-endpoints\",\n",
    "    ),\n",
    "    prompt=topic_prompt,\n",
    "    train_data=dataset,\n",
    "    scorers=[correctness],\n",
    "    optimizer_config=OptimizerConfig(\n",
    "        num_instruction_candidates=8,\n",
    "        max_few_show_examples=2,\n",
    "        verbose=True,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# The optimized prompt is automatically registered as a new version\n",
    "# Open the prompt registry web site to check the new prompt\n",
    "print(f\"The new prompt URI: {result.prompt.uri}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "004_prompt_optimization",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
