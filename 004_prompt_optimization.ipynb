{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "beecd6bf-71f4-4179-a6ea-ac65d198106a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# MLflow プロンプト最適化\n",
    "\n",
    "https://docs.databricks.com/aws/ja/mlflow3/genai/prompt-version-mgmt/prompt-registry/automatically-optimize-prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5bf08dab-81da-4414-bcfa-bca149b32ff3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> # プロンプト最適化（実験的機能）\n",
    "> MLflowでは、```mlflow.genai.optimize_prompt()```APIを使用したMLflowの統合インターフェースを通じて、プロンプトを高度なプロンプト最適化手法に組み込むことができます。この機能は、評価指標とラベル付きデータを活用して、プロンプトを自動的に改善するのに役立ちます。現在、このAPIはDSPyのMIPROv2アルゴリズムをサポートしています。\n",
    "> \n",
    "> ## 主なメリット\n",
    "> - **統合インターフェース:** 中立的なインターフェースを介して最先端のプロンプト最適化アルゴリズムにアクセスできます。\n",
    "> - **プロンプト管理:** MLflow プロンプト レジストリと統合して、再利用性、バージョン管理、系統を実現します。\n",
    "> - **評価:** MLflow の評価機能を使用してプロンプトのパフォーマンスを総合的に評価します。\n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d117d829-cbe0-4568-9520-fe46e74292e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 簡易チュートリアル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c573fc5c-7574-48e7-b190-8f45019e4088",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U \"mlflow[databricks]>=3.1.0\" databricks-langchain langgraph dspy databricks-agents\n",
    "\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "372cc1bf-9409-457b-a036-a1aecce8a984",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.entities import Prompt\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "CATALOG = \"workspace\"\n",
    "SCHEMA = \"default\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddb066e7-c24d-4c78-8f4b-4cdc205c30c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# First prompt for summarization.\n",
    "qa_prompt = mlflow.genai.register_prompt(\n",
    "    name=f\"{CATALOG}.{SCHEMA}.qa_prompt\",\n",
    "    template=\"次の質問に対して日本語で回答してください:{{question}}\",\n",
    ")\n",
    "\n",
    "qa_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ab5d4f1-f020-4599-beea-c55ea1d660eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 質問と回答のペアをリストとして定義\n",
    "train_data = [\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"Databricksとは何ですか？\"},\n",
    "        \"expectations\": {\n",
    "            \"answer\": \"Databricksは、データエンジニアリング、データサイエンス、機械学習のための統合データ分析プラットフォームです。\"\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"Databricksの主な機能は何ですか？\"},\n",
    "        \"expectations\": {\n",
    "            \"answer\": \"Databricksの主な機能には、データの統合、分析、機械学習モデルのトレーニングとデプロイがあります。\"\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"Databricksで使用できるプログラミング言語は何ですか？\"},\n",
    "        \"expectations\": {\n",
    "            \"answer\": \"Databricksでは、Python、SQL、R、Scalaなどのプログラミング言語を使用できます。\"\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"Databricksのノートブックとは何ですか？\"},\n",
    "        \"expectations\": {\n",
    "            \"answer\": \"Databricksのノートブックは、データ分析や機械学習のコードを記述、実行、共有するためのインタラクティブな環境です。\"\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"Databricksのクラスターとは何ですか？\"},\n",
    "        \"expectations\": {\n",
    "            \"answer\": \"Databricksのクラスターは、データ処理や分析のために使用されるコンピューティングリソースの集合です。\"\n",
    "        },\n",
    "    },\n",
    "]\n",
    "eval_data = [\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"DatabricksのDelta Lakeとは何ですか？\"},\n",
    "        \"expectations\": {\n",
    "            \"answer\": \"Delta Lakeは、Databricks上で提供される信頼性の高いデータレイクソリューションで、ACIDトランザクションやスキーマエンフォースメントをサポートします。\"\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"DatabricksのMLflowとは何ですか？\"},\n",
    "        \"expectations\": {\"answer\": \"MLflowは、機械学習モデルのライフサイクル管理を支援するオープンソースプラットフォームです。\"},\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"Databricksのジョブとは何ですか？\"},\n",
    "        \"expectations\": {\n",
    "            \"answer\": \"Databricksのジョブは、スケジュールされたデータ処理タスクやワークフローを自動化するための機能です。\"\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"Databricksのワークスペースとは何ですか？\"},\n",
    "        \"expectations\": {\n",
    "            \"answer\": \"Databricksのワークスペースは、データ分析や機械学習プロジェクトを管理するためのコラボレーション環境です。\"\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"DatabricksのUnity Catalogとは何ですか？\"},\n",
    "        \"expectations\": {\n",
    "            \"answer\": \"Unity Catalogは、Databricks上でデータガバナンスとセキュリティを提供するための統合データカタログです。\"\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "# pandasデータフレームに変換\n",
    "pdf = pd.DataFrame(train_data)\n",
    "\n",
    "# データフレームを表示\n",
    "display(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15eeb240-760f-48cb-9a91-92206b7c85ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from mlflow.genai.scorers import Correctness\n",
    "from mlflow.genai.optimize import OptimizerConfig, LLMParams\n",
    "from mlflow.genai.scorers import scorer\n",
    "import os\n",
    "\n",
    "# OpenAI Clientが利用できるように、現在のCredentialをOPENAI_API_KEYに登録\n",
    "mlflow_creds = mlflow.utils.databricks_utils.get_databricks_host_creds()\n",
    "os.environ[\"OPENAI_API_KEY\"] = mlflow_creds.token\n",
    "\n",
    "# Correctnessスコアを計算するbuilt-inオブジェクトを作成\n",
    "_correctness = Correctness()\n",
    "\n",
    "# プロンプト最適化のための評価関数（確からしさのテスト)\n",
    "@scorer\n",
    "def correctness(inputs, outputs, expectations):\n",
    "    expectations = {\"expected_response\": expectations.get(\"answer\")}\n",
    "    return (\n",
    "        _correctness(inputs=inputs, outputs=outputs, expectations=expectations).value\n",
    "        == \"yes\"\n",
    "    )\n",
    "\n",
    "# 最適化対象のプロンプト\n",
    "prompt = mlflow.genai.load_prompt(f\"prompts:/{CATALOG}.{SCHEMA}.qa_prompt/1\")\n",
    "\n",
    "# プロンプトを最適化\n",
    "result = mlflow.genai.optimize_prompt(\n",
    "    target_llm_params=LLMParams(\n",
    "        model_name=\"openai/databricks-llama-4-maverick\",\n",
    "        base_uri=f\"{mlflow_creds.host}/serving-endpoints\",\n",
    "    ),\n",
    "    prompt=prompt,\n",
    "    train_data=train_data,\n",
    "    eval_data=eval_data,\n",
    "    scorers=[correctness],\n",
    "    optimizer_config=OptimizerConfig(\n",
    "        num_instruction_candidates=8,\n",
    "        max_few_show_examples=2,\n",
    "        # verbose=True,\n",
    "        autolog=True,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# 最適化結果のプロンプトレジストリのURLを表示\n",
    "print(result.prompt.uri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3aa4d6f2-07a9-41f1-8893-be55fd1f35cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "prompt = mlflow.genai.load_prompt(result.prompt.uri)\n",
    "\n",
    "print(prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73df1a76-d8ba-46ee-9f36-f6c6ad49970c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from openai import OpenAI\n",
    "import codecs\n",
    "\n",
    "# MLflowの自動ロギングを有効にして、アプリケーションにトレースを追加\n",
    "mlflow.openai.autolog()\n",
    "\n",
    "# 実行ノートブックと同じ資格情報を使用してOpenAIクライアント経由でDatabricks LLMに接続\n",
    "mlflow_creds = mlflow.utils.databricks_utils.get_databricks_host_creds()\n",
    "client = OpenAI(\n",
    "    api_key=mlflow_creds.token, base_url=f\"{mlflow_creds.host}/serving-endpoints\"\n",
    ")\n",
    "\n",
    "# レジストリからプロンプトをロード\n",
    "first_prompt = mlflow.genai.load_prompt(f\"prompts:/{CATALOG}.{SCHEMA}.qa_prompt/1\")\n",
    "optimized_prompt = mlflow.genai.load_prompt(result.prompt.uri)\n",
    "endpoint = \"databricks-llama-4-maverick\"\n",
    "\n",
    "def predict(prompt):\n",
    "    formatted_prompt = prompt.format(question=\"Databricksとは何ですか?\")\n",
    "    \n",
    "    # LLMを呼び出す\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"databricks-llama-4-maverick\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": formatted_prompt,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "for p in [first_prompt, optimized_prompt]:\n",
    "    print(predict(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d7f10e1d-7469-4b0e-96ba-bded768162ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 公式Notebook\n",
    "\n",
    "https://docs.databricks.com/aws/ja/notebooks/source/mlflow/prompt-optimization.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e62558b4-45d3-4d83-abf1-426521961d23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U \"mlflow[databricks]>=3.1.0\" langchain-community langchain-openai beautifulsoup4 langgraph dspy databricks-agents\n",
    "\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "694490e2-d139-4664-ad9c-4a27d499c8ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO: If necessary, change the catalog and schema name here\n",
    "CATALOG = \"workspace\"\n",
    "SCHEMA = \"default\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d222037-47e7-4fc7-9ab8-81749b096765",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.entities import Prompt\n",
    "mlflow.set_registry_uri(\"databricks-uc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6840a9d5-2fe7-4083-811d-f9310619f8ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1000, chunk_overlap=0\n",
    ")\n",
    "\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "docs = loader.load()\n",
    "\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "print(f\"Generated {len(split_docs)} documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d70420b-d21a-47c2-ac94-7b5b22b14529",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "mlflow_creds = mlflow.utils.databricks_utils.get_databricks_host_creds()\n",
    "llm = init_chat_model(\n",
    "    # \"databricks-llama-4-maverick\",\n",
    "    \"databricks-meta-llama-3-1-405b-instruct\",\n",
    "    model_provider=\"openai\",\n",
    "    api_key=mlflow_creds.token,\n",
    "    base_url=f\"{mlflow_creds.host}/serving-endpoints\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "591d4053-7ac0-4f94-b9b1-2704107377b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# First prompt for summarization.\n",
    "summary_prompt = mlflow.genai.register_prompt(\n",
    "    name=f\"{CATALOG}.{SCHEMA}.summary_prompt\",\n",
    "    template=\"Write a concise summary of the following:{{content}}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1aa74d01-1254-4ec1-831a-3fccb99acad4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "summary_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d2ba550-47ae-42a2-adba-4ae46cb46e17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "summary_chain = llm | StrOutputParser()\n",
    "\n",
    "@mlflow.trace()\n",
    "def call_summary_chain(content):\n",
    "  return summary_chain.invoke([HumanMessage(summary_prompt.format(content=content))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a321841-48c2-43e6-842e-df0cfb900426",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Second prompt for topic extraction.\n",
    "topic_prompt = mlflow.genai.register_prompt(name=f\"{CATALOG}.{SCHEMA}.topic_prompt\",\n",
    "                       template=\"\"\"\n",
    "The following is the summary:\n",
    "{{summary}}\n",
    "Extract the main topic in a few words.\n",
    "Return the response in JSON format: {\"topic\": \"...\"}\n",
    "\"\"\")\n",
    "\n",
    "topic_chain = llm | JsonOutputParser()\n",
    "\n",
    "@mlflow.trace()\n",
    "def call_topic_chain(summary):\n",
    "  return topic_chain.invoke([HumanMessage(topic_prompt.format(summary=summary))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02f6b1d4-0fa6-45f3-8abb-1ddf044b1894",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "@mlflow.trace\n",
    "def agent(content):\n",
    "  summary = call_summary_chain(content=content)\n",
    "  return call_topic_chain(summary=summary)[\"topic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6deb4496-bbfd-47af-af9d-904a35f61f78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Enable Autologging\n",
    "mlflow.langchain.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3956c1d0-6d2a-4a61-b49e-bfb6bc778412",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Run the agent\n",
    "for doc in split_docs:\n",
    "  try:\n",
    "    print(agent(doc.page_content))\n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f52445e-1437-48df-977a-294ab88cb3b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c649ff2b-3394-4c36-9886-ce0d618fd318",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# Extract the inputs and outputs of the second LLM call\n",
    "traces = mlflow.search_traces(extract_fields=[\n",
    "  \"call_topic_chain.inputs\",\n",
    "  \"call_topic_chain.outputs\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7293cb4c-c81a-41e7-a92a-0604fc52c696",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "traces.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b359b24-648c-49a8-a25a-634cd94fccc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.genai import datasets\n",
    "\n",
    "EVAL_DATASET_NAME=f\"{CATALOG}.{SCHEMA}.data\"\n",
    "dataset = datasets.create_dataset(EVAL_DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0550bf8e-c2d5-41dc-9a07-28f3770e9cb3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f671d45-89bf-475f-98e7-f910a95fc329",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a dataset by treating the agent outputs as the default expectations.\n",
    "traces = traces.rename(\n",
    "    columns={\n",
    "      \"call_topic_chain.inputs\": \"inputs\",\n",
    "      \"call_topic_chain.outputs\": \"expectations\",\n",
    "    }\n",
    ")[[\"inputs\", \"expectations\"]]\n",
    "traces = traces.dropna()\n",
    "dataset.merge_records(traces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a9551dfb-ed60-4d0b-98dc-f364d7db7a66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b2cfbd0-00c9-4f67-ae27-0de25a5c4a40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dataset = datasets.get_dataset(EVAL_DATASET_NAME)\n",
    "dataset.merge_records([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d3c5319-fda0-446f-b3cf-7ffc66d06804",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dataset = dataset.to_df()\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b4b2a75-60dc-4952-9e33-ad1b94b3910f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0652ed95-20cd-4b11-b389-0c218c8a6064",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "from typing import Any\n",
    "from mlflow.genai.scorers import scorer\n",
    "from mlflow.genai.optimize import OptimizerConfig, LLMParams\n",
    "\n",
    "mlflow_creds = mlflow.utils.databricks_utils.get_databricks_host_creds()\n",
    "os.environ[\"OPENAI_API_KEY\"] = mlflow_creds.token\n",
    "\n",
    "\n",
    "@scorer\n",
    "def exact_match(expectations: dict[str, Any], outputs: dict[str, Any]) -> bool:\n",
    "    return expectations == outputs\n",
    "\n",
    "prompt = mlflow.genai.register_prompt(\n",
    "    name=f\"{CATALOG}.{SCHEMA}.qa\",\n",
    "    template=\"Answer the following question: {{question}}\",\n",
    ")\n",
    "\n",
    "result = mlflow.genai.optimize_prompt(\n",
    "    target_llm_params=LLMParams(\n",
    "        model_name=\"openai/databricks-meta-llama-3-1-405b-instruct\",\n",
    "        base_uri=f\"{mlflow_creds.host}/serving-endpoints\",\n",
    "    ),\n",
    "    train_data=[\n",
    "        {\"inputs\": {\"question\": f\"{i}+1\"}, \"expectations\": {\"answer\": f\"{i + 1}\"}}\n",
    "        for i in range(100)\n",
    "    ],\n",
    "    scorers=[exact_match],\n",
    "    prompt=prompt.uri,\n",
    "    optimizer_config=OptimizerConfig(num_instruction_candidates=5),\n",
    ")\n",
    "\n",
    "print(result.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2b9928b-d2a8-4745-a145-22f1ce69257e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result.prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91bca07e-4f77-4320-b706-15b76414468b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Any\n",
    "import mlflow\n",
    "from mlflow.genai.scorers import Correctness\n",
    "from mlflow.genai.optimize import OptimizerConfig, LLMParams\n",
    "from mlflow.genai.scorers import scorer\n",
    "\n",
    "_correctness = Correctness()\n",
    "\n",
    "\n",
    "@scorer\n",
    "def correctness(inputs, outputs, expectations):\n",
    "    expectations = {\"expected_response\": expectations.get(\"topic\")}\n",
    "    return (\n",
    "        _correctness(inputs=inputs, outputs=outputs, expectations=expectations).value\n",
    "        == \"yes\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Optimize the prompt\n",
    "result = mlflow.genai.optimize_prompt(\n",
    "    target_llm_params=LLMParams(\n",
    "        model_name=\"openai/databricks-meta-llama-3-3-70b-instruct\",\n",
    "        base_uri=f\"{mlflow_creds.host}/serving-endpoints\",\n",
    "    ),\n",
    "    prompt=topic_prompt,\n",
    "    train_data=dataset,\n",
    "    scorers=[correctness],\n",
    "    optimizer_config=OptimizerConfig(\n",
    "        num_instruction_candidates=8,\n",
    "        max_few_show_examples=2,\n",
    "        verbose=True,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# The optimized prompt is automatically registered as a new version\n",
    "# Open the prompt registry web site to check the new prompt\n",
    "print(f\"The new prompt URI: {result.prompt.uri}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "004_prompt_optimization",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
